{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eda_tools as et\n",
    "import impute_eval as ie\n",
    "import data_munging_tools as dmt\n",
    "import model_fitting_tools as mft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, SimpleFill, MICE, MatrixFactorization, IterativeSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#instantiate imputers:\n",
    "sf_median = SimpleFill(fill_method=\"median\")\n",
    "sf_mean = SimpleFill(fill_method=\"mean\")\n",
    "knn_imputer = KNN(k=10, verbose=0)\n",
    "mice_imputer = MICE(verbose=0)\n",
    "mf_imputer = MatrixFactorization(verbose=0)\n",
    "nnm_imputer = NuclearNormMinimization(verbose=0)\n",
    "soft_imputer = SoftImpute(verbose=0)\n",
    "itersvd_imputer = IterativeSVD(verbose=0)\n",
    "nonnormed_imputers_dict = {\"sf_median\" : sf_median, \"sf_mean\" : sf_mean, \"knn_imputer\" : knn_imputer}\n",
    "imputers_dict = {\"sf_median\" : sf_median, \"sf_mean\" : sf_mean, \"knn_imputer\" : knn_imputer, \"mice_imputer\" : mice_imputer, \"soft_imputer\": soft_imputer}\n",
    "all_imputers_dict = {\"sf_median\" : sf_median, \"sf_mean\" : sf_mean, \"knn_imputer\" : knn_imputer, \"mice_imputer\": mice_imputer, \"mf_imputer\": mf_imputer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_df = pd.read_csv('data/cleaned-input.test.tsv', sep='\\t', low_memory=False)\n",
    "training_df = pd.read_csv('data/cleaned-input.training.tsv', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([testing_df, training_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_blacklist_patterns = ['^recent_ipt_', '^production_', 'total_num_stages', 'bakken_isopach_ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8115, 53)\n",
      "(8115, 51)\n"
     ]
    }
   ],
   "source": [
    "df = merged_df.copy()\n",
    "print df.shape\n",
    "df.drop([\"FileNo\", \"Section\"], axis=1, inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'production_liquid_90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape before removals (8115, 51)\n",
      "Shape before blacklist removal: (8115, 51)\n",
      "Blacklisted columns: ['bakken_isopach_ft', 'production_liquid_120', 'production_liquid_150', 'production_liquid_180', 'production_liquid_1825', 'production_liquid_270', 'production_liquid_30', 'production_liquid_365', 'production_liquid_60', 'production_liquid_730', 'total_num_stages']\n",
      "Number of blacklisted columns: 11\n",
      "Shape after blacklist removal: (8115, 40)\n",
      "**************************************************\n",
      "Shape before cardinality removal: (8115, 40)\n",
      "Dropped CurrentWellName since it was categorical and had a high cardinality\n",
      "Dropped Footages since it was categorical and had a high cardinality\n",
      "Dropped LeaseName since it was categorical and had a high cardinality\n",
      "Dropped LeaseNumber since it was categorical and had a high cardinality\n",
      "Dropped OriginalWellName since it was categorical and had a high cardinality\n",
      "Dropped api since it was categorical and had a high cardinality\n",
      "Dropped spud_date since it was categorical and had a high cardinality\n",
      "Dropped well_status_date since it was categorical and had a high cardinality\n",
      "Shape after cardinality removal: (8115, 32)\n",
      "**************************************************\n",
      "Shape before high null removal: (8115, 32)\n",
      "Dropped DFElev since it had a high proportion of missing values. 0.999753542822\n",
      "Shape before high null removal: (8115, 31)\n",
      "df shape after removals (8115, 31)\n"
     ]
    }
   ],
   "source": [
    "df = dmt.munge_pipe(df, blacklist_patterns=my_blacklist_patterns, exceptions=set([target]), null_cutoff=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Test a single imputation method on a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removal: (8115, 31)\n",
      "Columns dropped: ['CountyName', 'CurrentOperator', 'FieldName', 'OriginalOperator', 'ProducedPools', 'QQ', 'Range', 'Township', 'WellStatus', 'WellType', 'Wellbore', 'choke_size', 'stimulated_formation', 'type_treatment']\n",
      "Shape after removal: (8115, 17)\n"
     ]
    }
   ],
   "source": [
    "impute_test_df = dmt.drop_nonnumeric_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_test_df.drop(target, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6113, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_test_df.shape\n",
    "impute_test_df.dropna(inplace=True)\n",
    "impute_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas fill_na(mean) mae, rmse:  1003134.60457 1955520.80819\n",
      "pandas fill_na(median) mae, rmse:  977474.503306 1954656.34914\n"
     ]
    }
   ],
   "source": [
    "ie.pandas_imputer_eval(impute_test_df, \"total_lbs_proppant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just proving that simple imputer is the same as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1003134.6045664609, 'rmse': 1955520.8081882647}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", sf_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 977474.50330578513, 'rmse': 1954656.3491413717}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", sf_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 621423.97947035055, 'rmse': 1622344.6518944211}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", knn_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using subset of columns\n",
    "knn_columns = [\"total_lbs_proppant\", \"total_volume_bbls\", \"tvd\", \"GRElev\", \"legs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 869433.76528520964, 'rmse': 1844774.9972242971}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not so hot\n",
    "ie.fancy_imputer_eval(impute_test_df[knn_columns], \"total_lbs_proppant\", knn_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MICE, Soft Impute, Iterative SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 905228.99666581035, 'rmse': 1875489.7876750953}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", mice_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 853836.30141906033, 'rmse': 1831365.0489999454}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", soft_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 984506.84450548701, 'rmse': 1952488.8428959888}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", itersvd_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1 of 1 mini-batches from (6113, 16)\n",
      "downhill: compiling evaluation function\n",
      "downhill: compiling Adam optimizer\n",
      "downhill: setting: rms_halflife = 14\n",
      "downhill: setting: rms_regularizer = 1e-08\n",
      "downhill: setting: patience = 5\n",
      "downhill: setting: validate_every = 10\n",
      "downhill: setting: min_improvement = 0.005\n",
      "downhill: setting: max_gradient_norm = 5\n",
      "downhill: setting: max_gradient_elem = 0\n",
      "downhill: setting: learning_rate = TensorConstant{0.001}\n",
      "downhill: setting: momentum = 0\n",
      "downhill: setting: nesterov = False\n",
      "downhill: validation 0 loss=10.585778 error=10.498290 *\n",
      "downhill: Adam 1 loss=10.585778 error=10.498290\n",
      "downhill: Adam 2 loss=10.550742 error=10.463365\n",
      "downhill: Adam 3 loss=10.503588 error=10.416360\n",
      "downhill: Adam 4 loss=10.448639 error=10.361585\n",
      "downhill: Adam 5 loss=10.388262 error=10.301401\n",
      "downhill: Adam 6 loss=10.324013 error=10.237356\n",
      "downhill: Adam 7 loss=10.257000 error=10.170558\n",
      "downhill: Adam 8 loss=10.188053 error=10.101833\n",
      "downhill: Adam 9 loss=10.117810 error=10.031816\n",
      "downhill: Adam 10 loss=10.046769 error=9.961005\n",
      "downhill: validation 1 loss=9.975325 error=9.889794 *\n",
      "downhill: Adam 11 loss=9.975325 error=9.889794\n",
      "downhill: Adam 12 loss=9.903794 error=9.818497\n",
      "downhill: Adam 13 loss=9.832429 error=9.747365\n",
      "downhill: Adam 14 loss=9.761430 error=9.676601\n",
      "downhill: Adam 15 loss=9.690961 error=9.606365\n",
      "downhill: Adam 16 loss=9.621149 error=9.536784\n",
      "downhill: Adam 17 loss=9.552096 error=9.467962\n",
      "downhill: Adam 18 loss=9.483881 error=9.399975\n",
      "downhill: Adam 19 loss=9.416566 error=9.332886\n",
      "downhill: Adam 20 loss=9.350196 error=9.266740\n",
      "downhill: validation 2 loss=9.284804 error=9.201570 *\n",
      "downhill: Adam 21 loss=9.284804 error=9.201570\n",
      "downhill: Adam 22 loss=9.220414 error=9.137400\n",
      "downhill: Adam 23 loss=9.157040 error=9.074242\n",
      "downhill: Adam 24 loss=9.094688 error=9.012104\n",
      "downhill: Adam 25 loss=9.033360 error=8.950987\n",
      "downhill: Adam 26 loss=8.973053 error=8.890888\n",
      "downhill: Adam 27 loss=8.913758 error=8.831798\n",
      "downhill: Adam 28 loss=8.855464 error=8.773707\n",
      "downhill: Adam 29 loss=8.798159 error=8.716602\n",
      "downhill: Adam 30 loss=8.741826 error=8.660467\n",
      "downhill: validation 3 loss=8.686449 error=8.605284 *\n",
      "downhill: Adam 31 loss=8.686449 error=8.605284\n",
      "downhill: Adam 32 loss=8.632008 error=8.551035\n",
      "downhill: Adam 33 loss=8.578484 error=8.497702\n",
      "downhill: Adam 34 loss=8.525858 error=8.445262\n",
      "downhill: Adam 35 loss=8.474108 error=8.393697\n",
      "downhill: Adam 36 loss=8.423214 error=8.342985\n",
      "downhill: Adam 37 loss=8.373155 error=8.293105\n",
      "downhill: Adam 38 loss=8.323909 error=8.244036\n",
      "downhill: Adam 39 loss=8.275456 error=8.195758\n",
      "downhill: Adam 40 loss=8.227774 error=8.148249\n",
      "downhill: validation 4 loss=8.180844 error=8.101489 *\n",
      "downhill: Adam 41 loss=8.180844 error=8.101489\n",
      "downhill: Adam 42 loss=8.134645 error=8.055459\n",
      "downhill: Adam 43 loss=8.089158 error=8.010137\n",
      "downhill: Adam 44 loss=8.044362 error=7.965506\n",
      "downhill: Adam 45 loss=8.000240 error=7.921546\n",
      "downhill: Adam 46 loss=7.956772 error=7.878239\n",
      "downhill: Adam 47 loss=7.913942 error=7.835566\n",
      "downhill: Adam 48 loss=7.871730 error=7.793511\n",
      "downhill: Adam 49 loss=7.830121 error=7.752056\n",
      "downhill: Adam 50 loss=7.789098 error=7.711186\n",
      "downhill: validation 5 loss=7.748644 error=7.670883 *\n",
      "downhill: Adam 51 loss=7.748644 error=7.670883\n",
      "downhill: Adam 52 loss=7.708744 error=7.631133\n",
      "downhill: Adam 53 loss=7.669384 error=7.591921\n",
      "downhill: Adam 54 loss=7.630549 error=7.553231\n",
      "downhill: Adam 55 loss=7.592224 error=7.515051\n",
      "downhill: Adam 56 loss=7.554396 error=7.477366\n",
      "downhill: Adam 57 loss=7.517052 error=7.440164\n",
      "downhill: Adam 58 loss=7.480179 error=7.403431\n",
      "downhill: Adam 59 loss=7.443765 error=7.367156\n",
      "downhill: Adam 60 loss=7.407798 error=7.331326\n",
      "downhill: validation 6 loss=7.372266 error=7.295931 *\n",
      "downhill: Adam 61 loss=7.372266 error=7.295931\n",
      "downhill: Adam 62 loss=7.337159 error=7.260958\n",
      "downhill: Adam 63 loss=7.302466 error=7.226398\n",
      "downhill: Adam 64 loss=7.268175 error=7.192240\n",
      "downhill: Adam 65 loss=7.234279 error=7.158474\n",
      "downhill: Adam 66 loss=7.200766 error=7.125091\n",
      "downhill: Adam 67 loss=7.167627 error=7.092081\n",
      "downhill: Adam 68 loss=7.134853 error=7.059435\n",
      "downhill: Adam 69 loss=7.102437 error=7.027144\n",
      "downhill: Adam 70 loss=7.070368 error=6.995201\n",
      "downhill: validation 7 loss=7.038640 error=6.963597 *\n",
      "downhill: Adam 71 loss=7.038640 error=6.963597\n",
      "downhill: Adam 72 loss=7.007244 error=6.932323\n",
      "downhill: Adam 73 loss=6.976172 error=6.901374\n",
      "downhill: Adam 74 loss=6.945418 error=6.870741\n",
      "downhill: Adam 75 loss=6.914974 error=6.840417\n",
      "downhill: Adam 76 loss=6.884833 error=6.810396\n",
      "downhill: Adam 77 loss=6.854990 error=6.780670\n",
      "downhill: Adam 78 loss=6.825436 error=6.751234\n",
      "downhill: Adam 79 loss=6.796166 error=6.722080\n",
      "downhill: Adam 80 loss=6.767175 error=6.693204\n",
      "downhill: validation 8 loss=6.738455 error=6.664600 *\n",
      "downhill: Adam 81 loss=6.738455 error=6.664600\n",
      "downhill: Adam 82 loss=6.710003 error=6.636261\n",
      "downhill: Adam 83 loss=6.681811 error=6.608182\n",
      "downhill: Adam 84 loss=6.653875 error=6.580358\n",
      "downhill: Adam 85 loss=6.626190 error=6.552784\n",
      "downhill: Adam 86 loss=6.598750 error=6.525455\n",
      "downhill: Adam 87 loss=6.571552 error=6.498366\n",
      "downhill: Adam 88 loss=6.544589 error=6.471513\n",
      "downhill: Adam 89 loss=6.517858 error=6.444890\n",
      "downhill: Adam 90 loss=6.491354 error=6.418494\n",
      "downhill: validation 9 loss=6.465074 error=6.392320 *\n",
      "downhill: Adam 91 loss=6.465074 error=6.392320\n",
      "downhill: Adam 92 loss=6.439012 error=6.366364\n",
      "downhill: Adam 93 loss=6.413165 error=6.340622\n",
      "downhill: Adam 94 loss=6.387528 error=6.315091\n",
      "downhill: Adam 95 loss=6.362099 error=6.289766\n",
      "downhill: Adam 96 loss=6.336873 error=6.264643\n",
      "downhill: Adam 97 loss=6.311847 error=6.239720\n",
      "downhill: Adam 98 loss=6.287017 error=6.214992\n",
      "downhill: Adam 99 loss=6.262380 error=6.190457\n",
      "downhill: Adam 100 loss=6.237933 error=6.166110\n",
      "downhill: validation 10 loss=6.213672 error=6.141950 *\n",
      "downhill: Adam 101 loss=6.213672 error=6.141950\n",
      "downhill: Adam 102 loss=6.189594 error=6.117972\n",
      "downhill: Adam 103 loss=6.165697 error=6.094173\n",
      "downhill: Adam 104 loss=6.141977 error=6.070551\n",
      "downhill: Adam 105 loss=6.118431 error=6.047103\n",
      "downhill: Adam 106 loss=6.095056 error=6.023827\n",
      "downhill: Adam 107 loss=6.071851 error=6.000718\n",
      "downhill: Adam 108 loss=6.048811 error=5.977775\n",
      "downhill: Adam 109 loss=6.025935 error=5.954995\n",
      "downhill: Adam 110 loss=6.003220 error=5.932375\n",
      "downhill: validation 11 loss=5.980664 error=5.909913 *\n",
      "downhill: Adam 111 loss=5.980664 error=5.909913\n",
      "downhill: Adam 112 loss=5.958264 error=5.887607\n",
      "downhill: Adam 113 loss=5.936017 error=5.865455\n",
      "downhill: Adam 114 loss=5.913922 error=5.843453\n",
      "downhill: Adam 115 loss=5.891977 error=5.821600\n",
      "downhill: Adam 116 loss=5.870178 error=5.799894\n",
      "downhill: Adam 117 loss=5.848524 error=5.778332\n",
      "downhill: Adam 118 loss=5.827013 error=5.756912\n",
      "downhill: Adam 119 loss=5.805643 error=5.735633\n",
      "downhill: Adam 120 loss=5.784412 error=5.714493\n",
      "downhill: validation 12 loss=5.763318 error=5.693488 *\n",
      "downhill: Adam 121 loss=5.763318 error=5.693488\n",
      "downhill: Adam 122 loss=5.742359 error=5.672618\n",
      "downhill: Adam 123 loss=5.721533 error=5.651881\n",
      "downhill: Adam 124 loss=5.700838 error=5.631275\n",
      "downhill: Adam 125 loss=5.680273 error=5.610798\n",
      "downhill: Adam 126 loss=5.659835 error=5.590449\n",
      "downhill: Adam 127 loss=5.639524 error=5.570225\n",
      "downhill: Adam 128 loss=5.619337 error=5.550125\n",
      "downhill: Adam 129 loss=5.599274 error=5.530148\n",
      "downhill: Adam 130 loss=5.579331 error=5.510291\n",
      "downhill: validation 13 loss=5.559508 error=5.490554 *\n",
      "downhill: Adam 131 loss=5.559508 error=5.490554\n",
      "downhill: Adam 132 loss=5.539804 error=5.470935\n",
      "downhill: Adam 133 loss=5.520216 error=5.451432\n",
      "downhill: Adam 134 loss=5.500743 error=5.432044\n",
      "downhill: Adam 135 loss=5.481384 error=5.412769\n",
      "downhill: Adam 136 loss=5.462138 error=5.393606\n",
      "downhill: Adam 137 loss=5.443002 error=5.374554\n",
      "downhill: Adam 138 loss=5.423977 error=5.355612\n",
      "downhill: Adam 139 loss=5.405060 error=5.336777\n",
      "downhill: Adam 140 loss=5.386250 error=5.318050\n",
      "downhill: validation 14 loss=5.367545 error=5.299427 *\n",
      "downhill: Adam 141 loss=5.367545 error=5.299427\n",
      "downhill: Adam 142 loss=5.348946 error=5.280909\n",
      "downhill: Adam 143 loss=5.330450 error=5.262494\n",
      "downhill: Adam 144 loss=5.312056 error=5.244181\n",
      "downhill: Adam 145 loss=5.293763 error=5.225969\n",
      "downhill: Adam 146 loss=5.275570 error=5.207856\n",
      "downhill: Adam 147 loss=5.257476 error=5.189842\n",
      "downhill: Adam 148 loss=5.239479 error=5.171925\n",
      "downhill: Adam 149 loss=5.221579 error=5.154104\n",
      "downhill: Adam 150 loss=5.203775 error=5.136378\n",
      "downhill: validation 15 loss=5.186065 error=5.118747 *\n",
      "downhill: Adam 151 loss=5.186065 error=5.118747\n",
      "downhill: Adam 152 loss=5.168449 error=5.101209\n",
      "downhill: Adam 153 loss=5.150925 error=5.083763\n",
      "downhill: Adam 154 loss=5.133492 error=5.066408\n",
      "downhill: Adam 155 loss=5.116150 error=5.049143\n",
      "downhill: Adam 156 loss=5.098898 error=5.031968\n",
      "downhill: Adam 157 loss=5.081734 error=5.014881\n",
      "downhill: Adam 158 loss=5.064658 error=4.997881\n",
      "downhill: Adam 159 loss=5.047669 error=4.980968\n",
      "downhill: Adam 160 loss=5.030765 error=4.964140\n",
      "downhill: validation 16 loss=5.013947 error=4.947397 *\n",
      "downhill: Adam 161 loss=5.013947 error=4.947397\n",
      "downhill: Adam 162 loss=4.997213 error=4.930738\n",
      "downhill: Adam 163 loss=4.980562 error=4.914162\n",
      "downhill: Adam 164 loss=4.963994 error=4.897669\n",
      "downhill: Adam 165 loss=4.947508 error=4.881257\n",
      "downhill: Adam 166 loss=4.931102 error=4.864925\n",
      "downhill: Adam 167 loss=4.914777 error=4.848673\n",
      "downhill: Adam 168 loss=4.898531 error=4.832501\n",
      "downhill: Adam 169 loss=4.882363 error=4.816407\n",
      "downhill: Adam 170 loss=4.866274 error=4.800390\n",
      "downhill: validation 17 loss=4.850261 error=4.784450 *\n",
      "downhill: Adam 171 loss=4.850261 error=4.784450\n",
      "downhill: Adam 172 loss=4.834325 error=4.768586\n",
      "downhill: Adam 173 loss=4.818465 error=4.752798\n",
      "downhill: Adam 174 loss=4.802679 error=4.737084\n",
      "downhill: Adam 175 loss=4.786968 error=4.721445\n",
      "downhill: Adam 176 loss=4.771331 error=4.705879\n",
      "downhill: Adam 177 loss=4.755766 error=4.690385\n",
      "downhill: Adam 178 loss=4.740274 error=4.674964\n",
      "downhill: Adam 179 loss=4.724853 error=4.659614\n",
      "downhill: Adam 180 loss=4.709504 error=4.644334\n",
      "downhill: validation 18 loss=4.694225 error=4.629125 *\n",
      "downhill: Adam 181 loss=4.694225 error=4.629125\n",
      "downhill: Adam 182 loss=4.679015 error=4.613985\n",
      "downhill: Adam 183 loss=4.663875 error=4.598915\n",
      "downhill: Adam 184 loss=4.648803 error=4.583912\n",
      "downhill: Adam 185 loss=4.633800 error=4.568977\n",
      "downhill: Adam 186 loss=4.618863 error=4.554110\n",
      "downhill: Adam 187 loss=4.603994 error=4.539309\n",
      "downhill: Adam 188 loss=4.589190 error=4.524574\n",
      "downhill: Adam 189 loss=4.574453 error=4.509904\n",
      "downhill: Adam 190 loss=4.559780 error=4.495300\n",
      "downhill: validation 19 loss=4.545173 error=4.480759 *\n",
      "downhill: Adam 191 loss=4.545173 error=4.480759\n",
      "downhill: Adam 192 loss=4.530629 error=4.466283\n",
      "downhill: Adam 193 loss=4.516149 error=4.451870\n",
      "downhill: Adam 194 loss=4.501732 error=4.437519\n",
      "downhill: Adam 195 loss=4.487377 error=4.423231\n",
      "downhill: Adam 196 loss=4.473084 error=4.409005\n",
      "downhill: Adam 197 loss=4.458853 error=4.394840\n",
      "downhill: Adam 198 loss=4.444683 error=4.380736\n",
      "downhill: Adam 199 loss=4.430574 error=4.366693\n",
      "downhill: Adam 200 loss=4.416524 error=4.352709\n",
      "downhill: validation 20 loss=4.402535 error=4.338784 *\n",
      "downhill: Adam 201 loss=4.402535 error=4.338784\n",
      "downhill: Adam 202 loss=4.388604 error=4.324919\n",
      "downhill: Adam 203 loss=4.374732 error=4.311112\n",
      "downhill: Adam 204 loss=4.360918 error=4.297363\n",
      "downhill: Adam 205 loss=4.347163 error=4.283671\n",
      "downhill: Adam 206 loss=4.333464 error=4.270037\n",
      "downhill: Adam 207 loss=4.319823 error=4.256460\n",
      "downhill: Adam 208 loss=4.306238 error=4.242938\n",
      "downhill: Adam 209 loss=4.292709 error=4.229473\n",
      "downhill: Adam 210 loss=4.279236 error=4.216063\n",
      "downhill: validation 21 loss=4.265818 error=4.202708 *\n",
      "downhill: Adam 211 loss=4.265818 error=4.202708\n",
      "downhill: Adam 212 loss=4.252455 error=4.189408\n",
      "downhill: Adam 213 loss=4.239146 error=4.176162\n",
      "downhill: Adam 214 loss=4.225892 error=4.162970\n",
      "downhill: Adam 215 loss=4.212691 error=4.149832\n",
      "downhill: Adam 216 loss=4.199543 error=4.136747\n",
      "downhill: Adam 217 loss=4.186449 error=4.123714\n",
      "downhill: Adam 218 loss=4.173407 error=4.110734\n",
      "downhill: Adam 219 loss=4.160417 error=4.097806\n",
      "downhill: Adam 220 loss=4.147479 error=4.084929\n",
      "downhill: validation 22 loss=4.134593 error=4.072104 *\n",
      "downhill: Adam 221 loss=4.134593 error=4.072104\n",
      "downhill: Adam 222 loss=4.121757 error=4.059329\n",
      "downhill: Adam 223 loss=4.108973 error=4.046605\n",
      "downhill: Adam 224 loss=4.096238 error=4.033932\n",
      "downhill: Adam 225 loss=4.083554 error=4.021308\n",
      "downhill: Adam 226 loss=4.070920 error=4.008734\n",
      "downhill: Adam 227 loss=4.058335 error=3.996209\n",
      "downhill: Adam 228 loss=4.045799 error=3.983732\n",
      "downhill: Adam 229 loss=4.033312 error=3.971305\n",
      "downhill: Adam 230 loss=4.020873 error=3.958926\n",
      "downhill: validation 23 loss=4.008482 error=3.946594 *\n",
      "downhill: Adam 231 loss=4.008482 error=3.946594\n",
      "downhill: Adam 232 loss=3.996139 error=3.934310\n",
      "downhill: Adam 233 loss=3.983844 error=3.922074\n",
      "downhill: Adam 234 loss=3.971596 error=3.909884\n",
      "downhill: Adam 235 loss=3.959394 error=3.897742\n",
      "downhill: Adam 236 loss=3.947240 error=3.885645\n",
      "downhill: Adam 237 loss=3.935131 error=3.873595\n",
      "downhill: Adam 238 loss=3.923069 error=3.861590\n",
      "downhill: Adam 239 loss=3.911052 error=3.849631\n",
      "downhill: Adam 240 loss=3.899081 error=3.837718\n",
      "downhill: validation 24 loss=3.887155 error=3.825849 *\n",
      "downhill: Adam 241 loss=3.887155 error=3.825849\n",
      "downhill: Adam 242 loss=3.875273 error=3.814025\n",
      "downhill: Adam 243 loss=3.863437 error=3.802245\n",
      "downhill: Adam 244 loss=3.851644 error=3.790509\n",
      "downhill: Adam 245 loss=3.839896 error=3.778818\n",
      "downhill: Adam 246 loss=3.828191 error=3.767169\n",
      "downhill: Adam 247 loss=3.816530 error=3.755565\n",
      "downhill: Adam 248 loss=3.804912 error=3.744003\n",
      "downhill: Adam 249 loss=3.793337 error=3.732484\n",
      "downhill: Adam 250 loss=3.781805 error=3.721007\n",
      "downhill: validation 25 loss=3.770315 error=3.709573 *\n",
      "downhill: Adam 251 loss=3.770315 error=3.709573\n",
      "downhill: Adam 252 loss=3.758868 error=3.698181\n",
      "downhill: Adam 253 loss=3.747462 error=3.686831\n",
      "downhill: Adam 254 loss=3.736098 error=3.675522\n",
      "downhill: Adam 255 loss=3.724776 error=3.664255\n",
      "downhill: Adam 256 loss=3.713495 error=3.653028\n",
      "downhill: Adam 257 loss=3.702255 error=3.641843\n",
      "downhill: Adam 258 loss=3.691056 error=3.630698\n",
      "downhill: Adam 259 loss=3.679897 error=3.619594\n",
      "downhill: Adam 260 loss=3.668778 error=3.608529\n",
      "downhill: validation 26 loss=3.657700 error=3.597505 *\n",
      "downhill: Adam 261 loss=3.657700 error=3.597505\n",
      "downhill: Adam 262 loss=3.646662 error=3.586520\n",
      "downhill: Adam 263 loss=3.635663 error=3.575575\n",
      "downhill: Adam 264 loss=3.624703 error=3.564669\n",
      "downhill: Adam 265 loss=3.613783 error=3.553802\n",
      "downhill: Adam 266 loss=3.602902 error=3.542974\n",
      "downhill: Adam 267 loss=3.592059 error=3.532184\n",
      "downhill: Adam 268 loss=3.581255 error=3.521433\n",
      "downhill: Adam 269 loss=3.570490 error=3.510720\n",
      "downhill: Adam 270 loss=3.559762 error=3.500045\n",
      "downhill: validation 27 loss=3.549072 error=3.489407 *\n",
      "downhill: Adam 271 loss=3.549072 error=3.489407\n",
      "downhill: Adam 272 loss=3.538421 error=3.478808\n",
      "downhill: Adam 273 loss=3.527806 error=3.468245\n",
      "downhill: Adam 274 loss=3.517229 error=3.457720\n",
      "downhill: Adam 275 loss=3.506689 error=3.447232\n",
      "downhill: Adam 276 loss=3.496186 error=3.436781\n",
      "downhill: Adam 277 loss=3.485720 error=3.426366\n",
      "downhill: Adam 278 loss=3.475290 error=3.415987\n",
      "downhill: Adam 279 loss=3.464897 error=3.405645\n",
      "downhill: Adam 280 loss=3.454540 error=3.395339\n",
      "downhill: validation 28 loss=3.444219 error=3.385068 *\n",
      "downhill: Adam 281 loss=3.444219 error=3.385068\n",
      "downhill: Adam 282 loss=3.433933 error=3.374833\n",
      "downhill: Adam 283 loss=3.423683 error=3.364634\n",
      "downhill: Adam 284 loss=3.413469 error=3.354470\n",
      "downhill: Adam 285 loss=3.403290 error=3.344341\n",
      "downhill: Adam 286 loss=3.393146 error=3.334247\n",
      "downhill: Adam 287 loss=3.383037 error=3.324187\n",
      "downhill: Adam 288 loss=3.372962 error=3.314163\n",
      "downhill: Adam 289 loss=3.362922 error=3.304172\n",
      "downhill: Adam 290 loss=3.352917 error=3.294216\n",
      "downhill: validation 29 loss=3.342945 error=3.284294 *\n",
      "downhill: Adam 291 loss=3.342945 error=3.284294\n",
      "downhill: Adam 292 loss=3.333008 error=3.274406\n",
      "downhill: Adam 293 loss=3.323105 error=3.264551\n",
      "downhill: Adam 294 loss=3.313235 error=3.254730\n",
      "downhill: Adam 295 loss=3.303399 error=3.244943\n",
      "downhill: Adam 296 loss=3.293596 error=3.235188\n",
      "downhill: Adam 297 loss=3.283826 error=3.225467\n",
      "downhill: Adam 298 loss=3.274090 error=3.215779\n",
      "downhill: Adam 299 loss=3.264386 error=3.206123\n",
      "downhill: Adam 300 loss=3.254715 error=3.196500\n",
      "downhill: validation 30 loss=3.245077 error=3.186909 *\n",
      "downhill: Adam 301 loss=3.245077 error=3.186909\n",
      "downhill: Adam 302 loss=3.235471 error=3.177351\n",
      "downhill: Adam 303 loss=3.225897 error=3.167825\n",
      "downhill: Adam 304 loss=3.216356 error=3.158330\n",
      "downhill: Adam 305 loss=3.206846 error=3.148868\n",
      "downhill: Adam 306 loss=3.197368 error=3.139437\n",
      "downhill: Adam 307 loss=3.187922 error=3.130038\n",
      "downhill: Adam 308 loss=3.178508 error=3.120670\n",
      "downhill: Adam 309 loss=3.169125 error=3.111333\n",
      "downhill: Adam 310 loss=3.159773 error=3.102028\n",
      "downhill: validation 31 loss=3.150452 error=3.092753 *\n",
      "downhill: Adam 311 loss=3.150452 error=3.092753\n",
      "downhill: Adam 312 loss=3.141162 error=3.083509\n",
      "downhill: Adam 313 loss=3.131903 error=3.074296\n",
      "downhill: Adam 314 loss=3.122674 error=3.065113\n",
      "downhill: Adam 315 loss=3.113476 error=3.055961\n",
      "downhill: Adam 316 loss=3.104309 error=3.046839\n",
      "downhill: Adam 317 loss=3.095171 error=3.037747\n",
      "downhill: Adam 318 loss=3.086064 error=3.028685\n",
      "downhill: Adam 319 loss=3.076987 error=3.019653\n",
      "downhill: Adam 320 loss=3.067939 error=3.010650\n",
      "downhill: validation 32 loss=3.058922 error=3.001677 *\n",
      "downhill: Adam 321 loss=3.058922 error=3.001677\n",
      "downhill: Adam 322 loss=3.049933 error=2.992734\n",
      "downhill: Adam 323 loss=3.040975 error=2.983820\n",
      "downhill: Adam 324 loss=3.032045 error=2.974935\n",
      "downhill: Adam 325 loss=3.023145 error=2.966079\n",
      "downhill: Adam 326 loss=3.014274 error=2.957252\n",
      "downhill: Adam 327 loss=3.005432 error=2.948453\n",
      "downhill: Adam 328 loss=2.996618 error=2.939684\n",
      "downhill: Adam 329 loss=2.987834 error=2.930943\n",
      "downhill: Adam 330 loss=2.979077 error=2.922230\n",
      "downhill: validation 33 loss=2.970350 error=2.913546 *\n",
      "downhill: Adam 331 loss=2.970350 error=2.913546\n",
      "downhill: Adam 332 loss=2.961650 error=2.904890\n",
      "downhill: Adam 333 loss=2.952979 error=2.896261\n",
      "downhill: Adam 334 loss=2.944336 error=2.887661\n",
      "downhill: Adam 335 loss=2.935720 error=2.879089\n",
      "downhill: Adam 336 loss=2.927133 error=2.870544\n",
      "downhill: Adam 337 loss=2.918573 error=2.862027\n",
      "downhill: Adam 338 loss=2.910041 error=2.853537\n",
      "downhill: Adam 339 loss=2.901536 error=2.845075\n",
      "downhill: Adam 340 loss=2.893059 error=2.836640\n",
      "downhill: validation 34 loss=2.884609 error=2.828232 *\n",
      "downhill: Adam 341 loss=2.884609 error=2.828232\n",
      "downhill: Adam 342 loss=2.876186 error=2.819851\n",
      "downhill: Adam 343 loss=2.867790 error=2.811497\n",
      "downhill: Adam 344 loss=2.859421 error=2.803169\n",
      "downhill: Adam 345 loss=2.851078 error=2.794869\n",
      "downhill: Adam 346 loss=2.842763 error=2.786594\n",
      "downhill: Adam 347 loss=2.834474 error=2.778347\n",
      "downhill: Adam 348 loss=2.826211 error=2.770125\n",
      "downhill: Adam 349 loss=2.817975 error=2.761930\n",
      "downhill: Adam 350 loss=2.809765 error=2.753761\n",
      "downhill: validation 35 loss=2.801581 error=2.745618 *\n",
      "downhill: Adam 351 loss=2.801581 error=2.745618\n",
      "downhill: Adam 352 loss=2.793423 error=2.737501\n",
      "downhill: Adam 353 loss=2.785291 error=2.729409\n",
      "downhill: Adam 354 loss=2.777185 error=2.721344\n",
      "downhill: Adam 355 loss=2.769105 error=2.713304\n",
      "downhill: Adam 356 loss=2.761050 error=2.705289\n",
      "downhill: Adam 357 loss=2.753021 error=2.697300\n",
      "downhill: Adam 358 loss=2.745017 error=2.689336\n",
      "downhill: Adam 359 loss=2.737038 error=2.681397\n",
      "downhill: Adam 360 loss=2.729085 error=2.673483\n",
      "downhill: validation 36 loss=2.721157 error=2.665594 *\n",
      "downhill: Adam 361 loss=2.721157 error=2.665594\n",
      "downhill: Adam 362 loss=2.713253 error=2.657730\n",
      "downhill: Adam 363 loss=2.705375 error=2.649891\n",
      "downhill: Adam 364 loss=2.697521 error=2.642077\n",
      "downhill: Adam 365 loss=2.689692 error=2.634287\n",
      "downhill: Adam 366 loss=2.681888 error=2.626521\n",
      "downhill: Adam 367 loss=2.674108 error=2.618780\n",
      "downhill: Adam 368 loss=2.666353 error=2.611064\n",
      "downhill: Adam 369 loss=2.658622 error=2.603371\n",
      "downhill: Adam 370 loss=2.650915 error=2.595702\n",
      "downhill: validation 37 loss=2.643232 error=2.588058 *\n",
      "downhill: Adam 371 loss=2.643232 error=2.588058\n",
      "downhill: Adam 372 loss=2.635574 error=2.580437\n",
      "downhill: Adam 373 loss=2.627939 error=2.572841\n",
      "downhill: Adam 374 loss=2.620328 error=2.565268\n",
      "downhill: Adam 375 loss=2.612741 error=2.557718\n",
      "downhill: Adam 376 loss=2.605177 error=2.550192\n",
      "downhill: Adam 377 loss=2.597638 error=2.542690\n",
      "downhill: Adam 378 loss=2.590121 error=2.535211\n",
      "downhill: Adam 379 loss=2.582628 error=2.527755\n",
      "downhill: Adam 380 loss=2.575159 error=2.520322\n",
      "downhill: validation 38 loss=2.567712 error=2.512913 *\n",
      "downhill: Adam 381 loss=2.567712 error=2.512913\n",
      "downhill: Adam 382 loss=2.560289 error=2.505526\n",
      "downhill: Adam 383 loss=2.552888 error=2.498163\n",
      "downhill: Adam 384 loss=2.545511 error=2.490822\n",
      "downhill: Adam 385 loss=2.538156 error=2.483504\n",
      "downhill: Adam 386 loss=2.530825 error=2.476209\n",
      "downhill: Adam 387 loss=2.523516 error=2.468936\n",
      "downhill: Adam 388 loss=2.516229 error=2.461685\n",
      "downhill: Adam 389 loss=2.508965 error=2.454457\n",
      "downhill: Adam 390 loss=2.501724 error=2.447252\n",
      "downhill: validation 39 loss=2.494505 error=2.440068 *\n",
      "downhill: Adam 391 loss=2.494505 error=2.440068\n",
      "downhill: Adam 392 loss=2.487308 error=2.432907\n",
      "downhill: Adam 393 loss=2.480133 error=2.425768\n",
      "downhill: Adam 394 loss=2.472981 error=2.418651\n",
      "downhill: Adam 395 loss=2.465850 error=2.411555\n",
      "downhill: Adam 396 loss=2.458741 error=2.404482\n",
      "downhill: Adam 397 loss=2.451655 error=2.397430\n",
      "downhill: Adam 398 loss=2.444590 error=2.390400\n",
      "downhill: Adam 399 loss=2.437546 error=2.383392\n",
      "downhill: Adam 400 loss=2.430525 error=2.376405\n",
      "downhill: validation 40 loss=2.423525 error=2.369439 *\n",
      "downhill: Adam 401 loss=2.423525 error=2.369439\n",
      "downhill: Adam 402 loss=2.416546 error=2.362495\n",
      "downhill: Adam 403 loss=2.409589 error=2.355572\n",
      "downhill: Adam 404 loss=2.402653 error=2.348670\n",
      "downhill: Adam 405 loss=2.395738 error=2.341789\n",
      "downhill: Adam 406 loss=2.388844 error=2.334929\n",
      "downhill: Adam 407 loss=2.381972 error=2.328091\n",
      "downhill: Adam 408 loss=2.375120 error=2.321273\n",
      "downhill: Adam 409 loss=2.368290 error=2.314476\n",
      "downhill: Adam 410 loss=2.361480 error=2.307699\n",
      "downhill: validation 41 loss=2.354691 error=2.300944 *\n",
      "downhill: Adam 411 loss=2.354691 error=2.300944\n",
      "downhill: Adam 412 loss=2.347922 error=2.294208\n",
      "downhill: Adam 413 loss=2.341175 error=2.287494\n",
      "downhill: Adam 414 loss=2.334447 error=2.280799\n",
      "downhill: Adam 415 loss=2.327741 error=2.274126\n",
      "downhill: Adam 416 loss=2.321054 error=2.267472\n",
      "downhill: Adam 417 loss=2.314388 error=2.260839\n",
      "downhill: Adam 418 loss=2.307743 error=2.254225\n",
      "downhill: Adam 419 loss=2.301117 error=2.247632\n",
      "downhill: Adam 420 loss=2.294511 error=2.241059\n",
      "downhill: validation 42 loss=2.287926 error=2.234506 *\n",
      "downhill: Adam 421 loss=2.287926 error=2.234506\n",
      "downhill: Adam 422 loss=2.281360 error=2.227972\n",
      "downhill: Adam 423 loss=2.274815 error=2.221458\n",
      "downhill: Adam 424 loss=2.268289 error=2.214964\n",
      "downhill: Adam 425 loss=2.261783 error=2.208490\n",
      "downhill: Adam 426 loss=2.255297 error=2.202035\n",
      "downhill: Adam 427 loss=2.248830 error=2.195600\n",
      "downhill: Adam 428 loss=2.242383 error=2.189184\n",
      "downhill: Adam 429 loss=2.235955 error=2.182788\n",
      "downhill: Adam 430 loss=2.229546 error=2.176410\n",
      "downhill: validation 43 loss=2.223157 error=2.170052 *\n",
      "downhill: Adam 431 loss=2.223157 error=2.170052\n",
      "downhill: Adam 432 loss=2.216788 error=2.163713\n",
      "downhill: Adam 433 loss=2.210437 error=2.157394\n",
      "downhill: Adam 434 loss=2.204106 error=2.151093\n",
      "downhill: Adam 435 loss=2.197793 error=2.144811\n",
      "downhill: Adam 436 loss=2.191500 error=2.138548\n",
      "downhill: Adam 437 loss=2.185225 error=2.132304\n",
      "downhill: Adam 438 loss=2.178970 error=2.126079\n",
      "downhill: Adam 439 loss=2.172733 error=2.119872\n",
      "downhill: Adam 440 loss=2.166515 error=2.113684\n",
      "downhill: validation 44 loss=2.160316 error=2.107515 *\n",
      "downhill: Adam 441 loss=2.160316 error=2.107515\n",
      "downhill: Adam 442 loss=2.154135 error=2.101364\n",
      "downhill: Adam 443 loss=2.147973 error=2.095231\n",
      "downhill: Adam 444 loss=2.141829 error=2.089117\n",
      "downhill: Adam 445 loss=2.135704 error=2.083021\n",
      "downhill: Adam 446 loss=2.129597 error=2.076943\n",
      "downhill: Adam 447 loss=2.123508 error=2.070884\n",
      "downhill: Adam 448 loss=2.117438 error=2.064842\n",
      "downhill: Adam 449 loss=2.111386 error=2.058819\n",
      "downhill: Adam 450 loss=2.105352 error=2.052814\n",
      "downhill: validation 45 loss=2.099335 error=2.046827 *\n",
      "downhill: Adam 451 loss=2.099335 error=2.046827\n",
      "downhill: Adam 452 loss=2.093337 error=2.040857\n",
      "downhill: Adam 453 loss=2.087357 error=2.034905\n",
      "downhill: Adam 454 loss=2.081395 error=2.028971\n",
      "downhill: Adam 455 loss=2.075450 error=2.023055\n",
      "downhill: Adam 456 loss=2.069523 error=2.017156\n",
      "downhill: Adam 457 loss=2.063614 error=2.011275\n",
      "downhill: Adam 458 loss=2.057723 error=2.005412\n",
      "downhill: Adam 459 loss=2.051849 error=1.999566\n",
      "downhill: Adam 460 loss=2.045992 error=1.993737\n",
      "downhill: validation 46 loss=2.040153 error=1.987925 *\n",
      "downhill: Adam 461 loss=2.040153 error=1.987925\n",
      "downhill: Adam 462 loss=2.034332 error=1.982131\n",
      "downhill: Adam 463 loss=2.028527 error=1.976354\n",
      "downhill: Adam 464 loss=2.022740 error=1.970595\n",
      "downhill: Adam 465 loss=2.016970 error=1.964852\n",
      "downhill: Adam 466 loss=2.011217 error=1.959126\n",
      "downhill: Adam 467 loss=2.005482 error=1.953417\n",
      "downhill: Adam 468 loss=1.999763 error=1.947726\n",
      "downhill: Adam 469 loss=1.994062 error=1.942051\n",
      "downhill: Adam 470 loss=1.988377 error=1.936393\n",
      "downhill: validation 47 loss=1.982709 error=1.930751 *\n",
      "downhill: Adam 471 loss=1.982709 error=1.930751\n",
      "downhill: Adam 472 loss=1.977058 error=1.925127\n",
      "downhill: Adam 473 loss=1.971423 error=1.919519\n",
      "downhill: Adam 474 loss=1.965806 error=1.913927\n",
      "downhill: Adam 475 loss=1.960205 error=1.908352\n",
      "downhill: Adam 476 loss=1.954620 error=1.902794\n",
      "downhill: Adam 477 loss=1.949052 error=1.897252\n",
      "downhill: Adam 478 loss=1.943501 error=1.891726\n",
      "downhill: Adam 479 loss=1.937966 error=1.886216\n",
      "downhill: Adam 480 loss=1.932447 error=1.880723\n",
      "downhill: validation 48 loss=1.926944 error=1.875246 *\n",
      "downhill: Adam 481 loss=1.926944 error=1.875246\n",
      "downhill: Adam 482 loss=1.921458 error=1.869786\n",
      "downhill: Adam 483 loss=1.915988 error=1.864341\n",
      "downhill: Adam 484 loss=1.910534 error=1.858912\n",
      "downhill: Adam 485 loss=1.905096 error=1.853499\n",
      "downhill: Adam 486 loss=1.899675 error=1.848103\n",
      "downhill: Adam 487 loss=1.894269 error=1.842722\n",
      "downhill: Adam 488 loss=1.888879 error=1.837357\n",
      "downhill: Adam 489 loss=1.883505 error=1.832007\n",
      "downhill: Adam 490 loss=1.878147 error=1.826674\n",
      "downhill: validation 49 loss=1.872804 error=1.821356 *\n",
      "downhill: Adam 491 loss=1.872804 error=1.821356\n",
      "downhill: Adam 492 loss=1.867478 error=1.816053\n",
      "downhill: Adam 493 loss=1.862166 error=1.810767\n",
      "downhill: Adam 494 loss=1.856871 error=1.805495\n",
      "downhill: Adam 495 loss=1.851591 error=1.800240\n",
      "downhill: Adam 496 loss=1.846327 error=1.794999\n",
      "downhill: Adam 497 loss=1.841078 error=1.789774\n",
      "downhill: Adam 498 loss=1.835844 error=1.784564\n",
      "downhill: Adam 499 loss=1.830626 error=1.779370\n",
      "downhill: Adam 500 loss=1.825423 error=1.774191\n",
      "downhill: validation 50 loss=1.820236 error=1.769027 *\n",
      "downhill: Adam 501 loss=1.820236 error=1.769027\n",
      "downhill: Adam 502 loss=1.815063 error=1.763878\n",
      "downhill: Adam 503 loss=1.809906 error=1.758744\n",
      "downhill: Adam 504 loss=1.804764 error=1.753625\n",
      "downhill: Adam 505 loss=1.799637 error=1.748521\n",
      "downhill: Adam 506 loss=1.794525 error=1.743432\n",
      "downhill: Adam 507 loss=1.789428 error=1.738358\n",
      "downhill: Adam 508 loss=1.784346 error=1.733298\n",
      "downhill: Adam 509 loss=1.779278 error=1.728254\n",
      "downhill: Adam 510 loss=1.774226 error=1.723224\n",
      "downhill: validation 51 loss=1.769188 error=1.718209 *\n",
      "downhill: Adam 511 loss=1.769188 error=1.718209\n",
      "downhill: Adam 512 loss=1.764165 error=1.713208\n",
      "downhill: Adam 513 loss=1.759157 error=1.708222\n",
      "downhill: Adam 514 loss=1.754163 error=1.703251\n",
      "downhill: Adam 515 loss=1.749184 error=1.698294\n",
      "downhill: Adam 516 loss=1.744220 error=1.693351\n",
      "downhill: Adam 517 loss=1.739270 error=1.688423\n",
      "downhill: Adam 518 loss=1.734334 error=1.683510\n",
      "downhill: Adam 519 loss=1.729413 error=1.678610\n",
      "downhill: Adam 520 loss=1.724507 error=1.673725\n",
      "downhill: validation 52 loss=1.719614 error=1.668854 *\n",
      "downhill: Adam 521 loss=1.719614 error=1.668854\n",
      "downhill: Adam 522 loss=1.714736 error=1.663997\n",
      "downhill: Adam 523 loss=1.709872 error=1.659155\n",
      "downhill: Adam 524 loss=1.705022 error=1.654326\n",
      "downhill: Adam 525 loss=1.700187 error=1.649511\n",
      "downhill: Adam 526 loss=1.695365 error=1.644711\n",
      "downhill: Adam 527 loss=1.690557 error=1.639924\n",
      "downhill: Adam 528 loss=1.685764 error=1.635151\n",
      "downhill: Adam 529 loss=1.680984 error=1.630393\n",
      "downhill: Adam 530 loss=1.676219 error=1.625648\n",
      "downhill: validation 53 loss=1.671467 error=1.620916 *\n",
      "downhill: Adam 531 loss=1.671467 error=1.620916\n",
      "downhill: Adam 532 loss=1.666729 error=1.616199\n",
      "downhill: Adam 533 loss=1.662005 error=1.611495\n",
      "downhill: Adam 534 loss=1.657295 error=1.606805\n",
      "downhill: Adam 535 loss=1.652598 error=1.602128\n",
      "downhill: Adam 536 loss=1.647915 error=1.597465\n",
      "downhill: Adam 537 loss=1.643245 error=1.592815\n",
      "downhill: Adam 538 loss=1.638590 error=1.588179\n",
      "downhill: Adam 539 loss=1.633947 error=1.583557\n",
      "downhill: Adam 540 loss=1.629318 error=1.578948\n",
      "downhill: validation 54 loss=1.624703 error=1.574352 *\n",
      "downhill: Adam 541 loss=1.624703 error=1.574352\n",
      "downhill: Adam 542 loss=1.620101 error=1.569769\n",
      "downhill: Adam 543 loss=1.615512 error=1.565200\n",
      "downhill: Adam 544 loss=1.610937 error=1.560644\n",
      "downhill: Adam 545 loss=1.606375 error=1.556101\n",
      "downhill: Adam 546 loss=1.601826 error=1.551571\n",
      "downhill: Adam 547 loss=1.597290 error=1.547054\n",
      "downhill: Adam 548 loss=1.592768 error=1.542550\n",
      "downhill: Adam 549 loss=1.588258 error=1.538060\n",
      "downhill: Adam 550 loss=1.583762 error=1.533582\n",
      "downhill: validation 55 loss=1.579279 error=1.529117 *\n",
      "downhill: Adam 551 loss=1.579279 error=1.529117\n",
      "downhill: Adam 552 loss=1.574808 error=1.524666\n",
      "downhill: Adam 553 loss=1.570351 error=1.520227\n",
      "downhill: Adam 554 loss=1.565907 error=1.515800\n",
      "downhill: Adam 555 loss=1.561475 error=1.511387\n",
      "downhill: Adam 556 loss=1.557056 error=1.506986\n",
      "downhill: Adam 557 loss=1.552651 error=1.502599\n",
      "downhill: Adam 558 loss=1.548257 error=1.498223\n",
      "downhill: Adam 559 loss=1.543877 error=1.493861\n",
      "downhill: Adam 560 loss=1.539509 error=1.489511\n",
      "downhill: validation 56 loss=1.535154 error=1.485173 *\n",
      "downhill: Adam 561 loss=1.535154 error=1.485173\n",
      "downhill: Adam 562 loss=1.530812 error=1.480848\n",
      "downhill: Adam 563 loss=1.526482 error=1.476536\n",
      "downhill: Adam 564 loss=1.522164 error=1.472235\n",
      "downhill: Adam 565 loss=1.517859 error=1.467948\n",
      "downhill: Adam 566 loss=1.513567 error=1.463672\n",
      "downhill: Adam 567 loss=1.509287 error=1.459409\n",
      "downhill: Adam 568 loss=1.505019 error=1.455159\n",
      "downhill: Adam 569 loss=1.500764 error=1.450920\n",
      "downhill: Adam 570 loss=1.496521 error=1.446694\n",
      "downhill: validation 57 loss=1.492290 error=1.442480 *\n",
      "downhill: Adam 571 loss=1.492290 error=1.442480\n",
      "downhill: Adam 572 loss=1.488071 error=1.438278\n",
      "downhill: Adam 573 loss=1.483865 error=1.434088\n",
      "downhill: Adam 574 loss=1.479671 error=1.429910\n",
      "downhill: Adam 575 loss=1.475489 error=1.425744\n",
      "downhill: Adam 576 loss=1.471319 error=1.421591\n",
      "downhill: Adam 577 loss=1.467161 error=1.417449\n",
      "downhill: Adam 578 loss=1.463015 error=1.413319\n",
      "downhill: Adam 579 loss=1.458881 error=1.409201\n",
      "downhill: Adam 580 loss=1.454759 error=1.405095\n",
      "downhill: validation 58 loss=1.450649 error=1.401000 *\n",
      "downhill: Adam 581 loss=1.450649 error=1.401000\n",
      "downhill: Adam 582 loss=1.446550 error=1.396918\n",
      "downhill: Adam 583 loss=1.442464 error=1.392847\n",
      "downhill: Adam 584 loss=1.438389 error=1.388788\n",
      "downhill: Adam 585 loss=1.434326 error=1.384741\n",
      "downhill: Adam 586 loss=1.430275 error=1.380705\n",
      "downhill: Adam 587 loss=1.426236 error=1.376681\n",
      "downhill: Adam 588 loss=1.422208 error=1.372668\n",
      "downhill: Adam 589 loss=1.418192 error=1.368667\n",
      "downhill: Adam 590 loss=1.414187 error=1.364677\n",
      "downhill: validation 59 loss=1.410194 error=1.360699 *\n",
      "downhill: Adam 591 loss=1.410194 error=1.360699\n",
      "downhill: Adam 592 loss=1.406213 error=1.356733\n",
      "downhill: Adam 593 loss=1.402243 error=1.352777\n",
      "downhill: Adam 594 loss=1.398284 error=1.348834\n",
      "downhill: Adam 595 loss=1.394337 error=1.344901\n",
      "downhill: Adam 596 loss=1.390402 error=1.340980\n",
      "downhill: Adam 597 loss=1.386477 error=1.337070\n",
      "downhill: Adam 598 loss=1.382564 error=1.333171\n",
      "downhill: Adam 599 loss=1.378663 error=1.329284\n",
      "downhill: Adam 600 loss=1.374772 error=1.325408\n",
      "downhill: validation 60 loss=1.370893 error=1.321542 *\n",
      "downhill: Adam 601 loss=1.370893 error=1.321542\n",
      "downhill: Adam 602 loss=1.367025 error=1.317688\n",
      "downhill: Adam 603 loss=1.363169 error=1.313846\n",
      "downhill: Adam 604 loss=1.359323 error=1.310014\n",
      "downhill: Adam 605 loss=1.355488 error=1.306193\n",
      "downhill: Adam 606 loss=1.351665 error=1.302383\n",
      "downhill: Adam 607 loss=1.347852 error=1.298584\n",
      "downhill: Adam 608 loss=1.344051 error=1.294796\n",
      "downhill: Adam 609 loss=1.340261 error=1.291019\n",
      "downhill: Adam 610 loss=1.336481 error=1.287253\n",
      "downhill: validation 61 loss=1.332713 error=1.283498 *\n",
      "downhill: Adam 611 loss=1.332713 error=1.283498\n",
      "downhill: Adam 612 loss=1.328955 error=1.279753\n",
      "downhill: Adam 613 loss=1.325208 error=1.276019\n",
      "downhill: Adam 614 loss=1.321472 error=1.272296\n",
      "downhill: Adam 615 loss=1.317747 error=1.268584\n",
      "downhill: Adam 616 loss=1.314033 error=1.264882\n",
      "downhill: Adam 617 loss=1.310329 error=1.261191\n",
      "downhill: Adam 618 loss=1.306636 error=1.257511\n",
      "downhill: Adam 619 loss=1.302954 error=1.253841\n",
      "downhill: Adam 620 loss=1.299283 error=1.250182\n",
      "downhill: validation 62 loss=1.295622 error=1.246534 *\n",
      "downhill: Adam 621 loss=1.295622 error=1.246534\n",
      "downhill: Adam 622 loss=1.291971 error=1.242896\n",
      "downhill: Adam 623 loss=1.288332 error=1.239268\n",
      "downhill: Adam 624 loss=1.284703 error=1.235651\n",
      "downhill: Adam 625 loss=1.281084 error=1.232044\n",
      "downhill: Adam 626 loss=1.277476 error=1.228448\n",
      "downhill: Adam 627 loss=1.273878 error=1.224862\n",
      "downhill: Adam 628 loss=1.270291 error=1.221287\n",
      "downhill: Adam 629 loss=1.266714 error=1.217721\n",
      "downhill: Adam 630 loss=1.263147 error=1.214167\n",
      "downhill: validation 63 loss=1.259591 error=1.210622 *\n",
      "downhill: Adam 631 loss=1.259591 error=1.210622\n",
      "downhill: Adam 632 loss=1.256045 error=1.207087\n",
      "downhill: Adam 633 loss=1.252510 error=1.203563\n",
      "downhill: Adam 634 loss=1.248984 error=1.200049\n",
      "downhill: Adam 635 loss=1.245469 error=1.196545\n",
      "downhill: Adam 636 loss=1.241964 error=1.193052\n",
      "downhill: Adam 637 loss=1.238470 error=1.189568\n",
      "downhill: Adam 638 loss=1.234985 error=1.186094\n",
      "downhill: Adam 639 loss=1.231510 error=1.182631\n",
      "downhill: Adam 640 loss=1.228046 error=1.179177\n",
      "downhill: validation 64 loss=1.224592 error=1.175734 *\n",
      "downhill: Adam 641 loss=1.224592 error=1.175734\n",
      "downhill: Adam 642 loss=1.221148 error=1.172300\n",
      "downhill: Adam 643 loss=1.217713 error=1.168877\n",
      "downhill: Adam 644 loss=1.214289 error=1.165463\n",
      "downhill: Adam 645 loss=1.210875 error=1.162059\n",
      "downhill: Adam 646 loss=1.207471 error=1.158665\n",
      "downhill: Adam 647 loss=1.204076 error=1.155281\n",
      "downhill: Adam 648 loss=1.200692 error=1.151907\n",
      "downhill: Adam 649 loss=1.197317 error=1.148542\n",
      "downhill: Adam 650 loss=1.193952 error=1.145188\n",
      "downhill: validation 65 loss=1.190597 error=1.141843 *\n",
      "downhill: Adam 651 loss=1.190597 error=1.141843\n",
      "downhill: Adam 652 loss=1.187252 error=1.138508\n",
      "downhill: Adam 653 loss=1.183917 error=1.135182\n",
      "downhill: Adam 654 loss=1.180591 error=1.131866\n",
      "downhill: Adam 655 loss=1.177275 error=1.128560\n",
      "downhill: Adam 656 loss=1.173969 error=1.125263\n",
      "downhill: Adam 657 loss=1.170672 error=1.121976\n",
      "downhill: Adam 658 loss=1.167385 error=1.118699\n",
      "downhill: Adam 659 loss=1.164108 error=1.115431\n",
      "downhill: Adam 660 loss=1.160840 error=1.112172\n",
      "downhill: validation 66 loss=1.157582 error=1.108924 *\n",
      "downhill: Adam 661 loss=1.157582 error=1.108924\n",
      "downhill: Adam 662 loss=1.154333 error=1.105684\n",
      "downhill: Adam 663 loss=1.151094 error=1.102454\n",
      "downhill: Adam 664 loss=1.147865 error=1.099234\n",
      "downhill: Adam 665 loss=1.144645 error=1.096023\n",
      "downhill: Adam 666 loss=1.141434 error=1.092821\n",
      "downhill: Adam 667 loss=1.138233 error=1.089629\n",
      "downhill: Adam 668 loss=1.135041 error=1.086446\n",
      "downhill: Adam 669 loss=1.131859 error=1.083272\n",
      "downhill: Adam 670 loss=1.128686 error=1.080108\n",
      "downhill: validation 67 loss=1.125522 error=1.076952 *\n",
      "downhill: Adam 671 loss=1.125522 error=1.076952\n",
      "downhill: Adam 672 loss=1.122368 error=1.073807\n",
      "downhill: Adam 673 loss=1.119223 error=1.070670\n",
      "downhill: Adam 674 loss=1.116087 error=1.067543\n",
      "downhill: Adam 675 loss=1.112960 error=1.064424\n",
      "downhill: Adam 676 loss=1.109843 error=1.061315\n",
      "downhill: Adam 677 loss=1.106735 error=1.058215\n",
      "downhill: Adam 678 loss=1.103636 error=1.055125\n",
      "downhill: Adam 679 loss=1.100546 error=1.052043\n",
      "downhill: Adam 680 loss=1.097466 error=1.048970\n",
      "downhill: validation 68 loss=1.094394 error=1.045907 *\n",
      "downhill: Adam 681 loss=1.094394 error=1.045907\n",
      "downhill: Adam 682 loss=1.091332 error=1.042852\n",
      "downhill: Adam 683 loss=1.088279 error=1.039807\n",
      "downhill: Adam 684 loss=1.085234 error=1.036770\n",
      "downhill: Adam 685 loss=1.082199 error=1.033743\n",
      "downhill: Adam 686 loss=1.079173 error=1.030724\n",
      "downhill: Adam 687 loss=1.076156 error=1.027714\n",
      "downhill: Adam 688 loss=1.073148 error=1.024713\n",
      "downhill: Adam 689 loss=1.070149 error=1.021722\n",
      "downhill: Adam 690 loss=1.067158 error=1.018739\n",
      "downhill: validation 69 loss=1.064177 error=1.015764 *\n",
      "downhill: Adam 691 loss=1.064177 error=1.015764\n",
      "downhill: Adam 692 loss=1.061205 error=1.012799\n",
      "downhill: Adam 693 loss=1.058241 error=1.009843\n",
      "downhill: Adam 694 loss=1.055286 error=1.006895\n",
      "downhill: Adam 695 loss=1.052340 error=1.003956\n",
      "downhill: Adam 696 loss=1.049403 error=1.001026\n",
      "downhill: Adam 697 loss=1.046475 error=0.998104\n",
      "downhill: Adam 698 loss=1.043555 error=0.995192\n",
      "downhill: Adam 699 loss=1.040645 error=0.992288\n",
      "downhill: Adam 700 loss=1.037743 error=0.989392\n",
      "downhill: validation 70 loss=1.034849 error=0.986505 *\n",
      "downhill: Adam 701 loss=1.034849 error=0.986505\n",
      "downhill: Adam 702 loss=1.031965 error=0.983627\n",
      "downhill: Adam 703 loss=1.029089 error=0.980758\n",
      "downhill: Adam 704 loss=1.026221 error=0.977897\n",
      "downhill: Adam 705 loss=1.023363 error=0.975045\n",
      "downhill: Adam 706 loss=1.020513 error=0.972201\n",
      "downhill: Adam 707 loss=1.017671 error=0.969366\n",
      "downhill: Adam 708 loss=1.014839 error=0.966539\n",
      "downhill: Adam 709 loss=1.012014 error=0.963721\n",
      "downhill: Adam 710 loss=1.009199 error=0.960911\n",
      "downhill: validation 71 loss=1.006391 error=0.958110 *\n",
      "downhill: Adam 711 loss=1.006391 error=0.958110\n",
      "downhill: Adam 712 loss=1.003593 error=0.955317\n",
      "downhill: Adam 713 loss=1.000802 error=0.952533\n",
      "downhill: Adam 714 loss=0.998021 error=0.949757\n",
      "downhill: Adam 715 loss=0.995247 error=0.946989\n",
      "downhill: Adam 716 loss=0.992483 error=0.944230\n",
      "downhill: Adam 717 loss=0.989726 error=0.941479\n",
      "downhill: Adam 718 loss=0.986978 error=0.938737\n",
      "downhill: Adam 719 loss=0.984238 error=0.936002\n",
      "downhill: Adam 720 loss=0.981507 error=0.933276\n",
      "downhill: validation 72 loss=0.978784 error=0.930559 *\n",
      "downhill: Adam 721 loss=0.978784 error=0.930559\n",
      "downhill: Adam 722 loss=0.976069 error=0.927850\n",
      "downhill: Adam 723 loss=0.973363 error=0.925148\n",
      "downhill: Adam 724 loss=0.970665 error=0.922456\n",
      "downhill: Adam 725 loss=0.967975 error=0.919771\n",
      "downhill: Adam 726 loss=0.965294 error=0.917094\n",
      "downhill: Adam 727 loss=0.962620 error=0.914426\n",
      "downhill: Adam 728 loss=0.959955 error=0.911766\n",
      "downhill: Adam 729 loss=0.957298 error=0.909114\n",
      "downhill: Adam 730 loss=0.954650 error=0.906470\n",
      "downhill: validation 73 loss=0.952009 error=0.903834 *\n",
      "downhill: Adam 731 loss=0.952009 error=0.903834\n",
      "downhill: Adam 732 loss=0.949377 error=0.901207\n",
      "downhill: Adam 733 loss=0.946752 error=0.898587\n",
      "downhill: Adam 734 loss=0.944136 error=0.895976\n",
      "downhill: Adam 735 loss=0.941528 error=0.893372\n",
      "downhill: Adam 736 loss=0.938928 error=0.890777\n",
      "downhill: Adam 737 loss=0.936336 error=0.888189\n",
      "downhill: Adam 738 loss=0.933752 error=0.885610\n",
      "downhill: Adam 739 loss=0.931176 error=0.883038\n",
      "downhill: Adam 740 loss=0.928608 error=0.880475\n",
      "downhill: validation 74 loss=0.926048 error=0.877919 *\n",
      "downhill: Adam 741 loss=0.926048 error=0.877919\n",
      "downhill: Adam 742 loss=0.923496 error=0.875371\n",
      "downhill: Adam 743 loss=0.920952 error=0.872832\n",
      "downhill: Adam 744 loss=0.918416 error=0.870300\n",
      "downhill: Adam 745 loss=0.915888 error=0.867776\n",
      "downhill: Adam 746 loss=0.913368 error=0.865259\n",
      "downhill: Adam 747 loss=0.910855 error=0.862751\n",
      "downhill: Adam 748 loss=0.908351 error=0.860251\n",
      "downhill: Adam 749 loss=0.905854 error=0.857758\n",
      "downhill: Adam 750 loss=0.903365 error=0.855273\n",
      "downhill: validation 75 loss=0.900884 error=0.852796 *\n",
      "downhill: Adam 751 loss=0.900884 error=0.852796\n",
      "downhill: Adam 752 loss=0.898411 error=0.850326\n",
      "downhill: Adam 753 loss=0.895946 error=0.847865\n",
      "downhill: Adam 754 loss=0.893488 error=0.845411\n",
      "downhill: Adam 755 loss=0.891038 error=0.842964\n",
      "downhill: Adam 756 loss=0.888596 error=0.840526\n",
      "downhill: Adam 757 loss=0.886162 error=0.838095\n",
      "downhill: Adam 758 loss=0.883735 error=0.835672\n",
      "downhill: Adam 759 loss=0.881316 error=0.833256\n",
      "downhill: Adam 760 loss=0.878905 error=0.830848\n",
      "downhill: validation 76 loss=0.876501 error=0.828448 *\n",
      "downhill: Adam 761 loss=0.876501 error=0.828448\n",
      "downhill: Adam 762 loss=0.874105 error=0.826055\n",
      "downhill: Adam 763 loss=0.871716 error=0.823670\n",
      "downhill: Adam 764 loss=0.869336 error=0.821292\n",
      "downhill: Adam 765 loss=0.866962 error=0.818922\n",
      "downhill: Adam 766 loss=0.864597 error=0.816559\n",
      "downhill: Adam 767 loss=0.862238 error=0.814204\n",
      "downhill: Adam 768 loss=0.859888 error=0.811857\n",
      "downhill: Adam 769 loss=0.857545 error=0.809517\n",
      "downhill: Adam 770 loss=0.855209 error=0.807184\n",
      "downhill: validation 77 loss=0.852881 error=0.804859 *\n",
      "downhill: Adam 771 loss=0.852881 error=0.804859\n",
      "downhill: Adam 772 loss=0.850560 error=0.802541\n",
      "downhill: Adam 773 loss=0.848247 error=0.800231\n",
      "downhill: Adam 774 loss=0.845941 error=0.797928\n",
      "downhill: Adam 775 loss=0.843643 error=0.795632\n",
      "downhill: Adam 776 loss=0.841352 error=0.793344\n",
      "downhill: Adam 777 loss=0.839068 error=0.791063\n",
      "downhill: Adam 778 loss=0.836792 error=0.788790\n",
      "downhill: Adam 779 loss=0.834523 error=0.786523\n",
      "downhill: Adam 780 loss=0.832261 error=0.784264\n",
      "downhill: validation 78 loss=0.830007 error=0.782013 *\n",
      "downhill: Adam 781 loss=0.830007 error=0.782013\n",
      "downhill: Adam 782 loss=0.827760 error=0.779768\n",
      "downhill: Adam 783 loss=0.825520 error=0.777531\n",
      "downhill: Adam 784 loss=0.823288 error=0.775301\n",
      "downhill: Adam 785 loss=0.821063 error=0.773079\n",
      "downhill: Adam 786 loss=0.818845 error=0.770863\n",
      "downhill: Adam 787 loss=0.816635 error=0.768655\n",
      "downhill: Adam 788 loss=0.814431 error=0.766454\n",
      "downhill: Adam 789 loss=0.812235 error=0.764260\n",
      "downhill: Adam 790 loss=0.810046 error=0.762073\n",
      "downhill: validation 79 loss=0.807864 error=0.759893 *\n",
      "downhill: Adam 791 loss=0.807864 error=0.759893\n",
      "downhill: Adam 792 loss=0.805689 error=0.757721\n",
      "downhill: Adam 793 loss=0.803522 error=0.755555\n",
      "downhill: Adam 794 loss=0.801361 error=0.753397\n",
      "downhill: Adam 795 loss=0.799208 error=0.751246\n",
      "downhill: Adam 796 loss=0.797062 error=0.749101\n",
      "downhill: Adam 797 loss=0.794922 error=0.746964\n",
      "downhill: Adam 798 loss=0.792790 error=0.744834\n",
      "downhill: Adam 799 loss=0.790665 error=0.742711\n",
      "downhill: Adam 800 loss=0.788547 error=0.740594\n",
      "downhill: validation 80 loss=0.786436 error=0.738485 *\n",
      "downhill: Adam 801 loss=0.786436 error=0.738485\n",
      "downhill: Adam 802 loss=0.784331 error=0.736383\n",
      "downhill: Adam 803 loss=0.782234 error=0.734287\n",
      "downhill: Adam 804 loss=0.780144 error=0.732199\n",
      "downhill: Adam 805 loss=0.778060 error=0.730117\n",
      "downhill: Adam 806 loss=0.775984 error=0.728042\n",
      "downhill: Adam 807 loss=0.773914 error=0.725975\n",
      "downhill: Adam 808 loss=0.771852 error=0.723913\n",
      "downhill: Adam 809 loss=0.769796 error=0.721859\n",
      "downhill: Adam 810 loss=0.767747 error=0.719812\n",
      "downhill: validation 81 loss=0.765705 error=0.717771 *\n",
      "downhill: Adam 811 loss=0.765705 error=0.717771\n",
      "downhill: Adam 812 loss=0.763669 error=0.715737\n",
      "downhill: Adam 813 loss=0.761641 error=0.713710\n",
      "downhill: Adam 814 loss=0.759619 error=0.711690\n",
      "downhill: Adam 815 loss=0.757604 error=0.709677\n",
      "downhill: Adam 816 loss=0.755596 error=0.707670\n",
      "downhill: Adam 817 loss=0.753594 error=0.705670\n",
      "downhill: Adam 818 loss=0.751600 error=0.703676\n",
      "downhill: Adam 819 loss=0.749611 error=0.701689\n",
      "downhill: Adam 820 loss=0.747630 error=0.699709\n",
      "downhill: validation 82 loss=0.745655 error=0.697736 *\n",
      "downhill: Adam 821 loss=0.745655 error=0.697736\n",
      "downhill: Adam 822 loss=0.743687 error=0.695769\n",
      "downhill: Adam 823 loss=0.741725 error=0.693808\n",
      "downhill: Adam 824 loss=0.739770 error=0.691855\n",
      "downhill: Adam 825 loss=0.737822 error=0.689908\n",
      "downhill: Adam 826 loss=0.735880 error=0.687967\n",
      "downhill: Adam 827 loss=0.733945 error=0.686033\n",
      "downhill: Adam 828 loss=0.732016 error=0.684105\n",
      "downhill: Adam 829 loss=0.730094 error=0.682184\n",
      "downhill: Adam 830 loss=0.728179 error=0.680270\n",
      "downhill: validation 83 loss=0.726269 error=0.678362 *\n",
      "downhill: Adam 831 loss=0.726269 error=0.678362\n",
      "downhill: Adam 832 loss=0.724367 error=0.676460\n",
      "downhill: Adam 833 loss=0.722470 error=0.674565\n",
      "downhill: Adam 834 loss=0.720581 error=0.672676\n",
      "downhill: Adam 835 loss=0.718697 error=0.670793\n",
      "downhill: Adam 836 loss=0.716820 error=0.668917\n",
      "downhill: Adam 837 loss=0.714950 error=0.667048\n",
      "downhill: Adam 838 loss=0.713085 error=0.665184\n",
      "downhill: Adam 839 loss=0.711227 error=0.663327\n",
      "downhill: Adam 840 loss=0.709376 error=0.661476\n",
      "downhill: validation 84 loss=0.707531 error=0.659632 *\n",
      "downhill: Adam 841 loss=0.707531 error=0.659632\n",
      "downhill: Adam 842 loss=0.705692 error=0.657794\n",
      "downhill: Adam 843 loss=0.703859 error=0.655962\n",
      "downhill: Adam 844 loss=0.702032 error=0.654136\n",
      "downhill: Adam 845 loss=0.700212 error=0.652317\n",
      "downhill: Adam 846 loss=0.698398 error=0.650504\n",
      "downhill: Adam 847 loss=0.696591 error=0.648697\n",
      "downhill: Adam 848 loss=0.694789 error=0.646896\n",
      "downhill: Adam 849 loss=0.692994 error=0.645101\n",
      "downhill: Adam 850 loss=0.691204 error=0.643312\n",
      "downhill: validation 85 loss=0.689421 error=0.641530 *\n",
      "downhill: Adam 851 loss=0.689421 error=0.641530\n",
      "downhill: Adam 852 loss=0.687644 error=0.639753\n",
      "downhill: Adam 853 loss=0.685874 error=0.637983\n",
      "downhill: Adam 854 loss=0.684109 error=0.636219\n",
      "downhill: Adam 855 loss=0.682350 error=0.634461\n",
      "downhill: Adam 856 loss=0.680598 error=0.632709\n",
      "downhill: Adam 857 loss=0.678851 error=0.630963\n",
      "downhill: Adam 858 loss=0.677110 error=0.629222\n",
      "downhill: Adam 859 loss=0.675376 error=0.627488\n",
      "downhill: Adam 860 loss=0.673647 error=0.625760\n",
      "downhill: validation 86 loss=0.671925 error=0.624038 *\n",
      "downhill: Adam 861 loss=0.671925 error=0.624038\n",
      "downhill: Adam 862 loss=0.670208 error=0.622322\n",
      "downhill: Adam 863 loss=0.668497 error=0.620611\n",
      "downhill: Adam 864 loss=0.666792 error=0.618907\n",
      "downhill: Adam 865 loss=0.665093 error=0.617208\n",
      "downhill: Adam 866 loss=0.663400 error=0.615515\n",
      "downhill: Adam 867 loss=0.661713 error=0.613828\n",
      "downhill: Adam 868 loss=0.660032 error=0.612147\n",
      "downhill: Adam 869 loss=0.658356 error=0.610472\n",
      "downhill: Adam 870 loss=0.656686 error=0.608803\n",
      "downhill: validation 87 loss=0.655023 error=0.607139 *\n",
      "downhill: Adam 871 loss=0.655023 error=0.607139\n",
      "downhill: Adam 872 loss=0.653364 error=0.605481\n",
      "downhill: Adam 873 loss=0.651712 error=0.603829\n",
      "downhill: Adam 874 loss=0.650065 error=0.602182\n",
      "downhill: Adam 875 loss=0.648424 error=0.600541\n",
      "downhill: Adam 876 loss=0.646789 error=0.598906\n",
      "downhill: Adam 877 loss=0.645159 error=0.597276\n",
      "downhill: Adam 878 loss=0.643535 error=0.595652\n",
      "downhill: Adam 879 loss=0.641917 error=0.594034\n",
      "downhill: Adam 880 loss=0.640304 error=0.592422\n",
      "downhill: validation 88 loss=0.638697 error=0.590814 *\n",
      "downhill: Adam 881 loss=0.638697 error=0.590814\n",
      "downhill: Adam 882 loss=0.637096 error=0.589213\n",
      "downhill: Adam 883 loss=0.635500 error=0.587617\n",
      "downhill: Adam 884 loss=0.633909 error=0.586027\n",
      "downhill: Adam 885 loss=0.632324 error=0.584442\n",
      "downhill: Adam 886 loss=0.630745 error=0.582862\n",
      "downhill: Adam 887 loss=0.629171 error=0.581288\n",
      "downhill: Adam 888 loss=0.627603 error=0.579720\n",
      "downhill: Adam 889 loss=0.626040 error=0.578157\n",
      "downhill: Adam 890 loss=0.624482 error=0.576599\n",
      "downhill: validation 89 loss=0.622930 error=0.575047 *\n",
      "downhill: Adam 891 loss=0.622930 error=0.575047\n",
      "downhill: Adam 892 loss=0.621383 error=0.573500\n",
      "downhill: Adam 893 loss=0.619842 error=0.571959\n",
      "downhill: Adam 894 loss=0.618306 error=0.570423\n",
      "downhill: Adam 895 loss=0.616775 error=0.568892\n",
      "downhill: Adam 896 loss=0.615250 error=0.567366\n",
      "downhill: Adam 897 loss=0.613730 error=0.565846\n",
      "downhill: Adam 898 loss=0.612215 error=0.564331\n",
      "downhill: Adam 899 loss=0.610706 error=0.562822\n",
      "downhill: Adam 900 loss=0.609201 error=0.561317\n",
      "downhill: validation 90 loss=0.607703 error=0.559818 *\n",
      "downhill: Adam 901 loss=0.607703 error=0.559818\n",
      "downhill: Adam 902 loss=0.606209 error=0.558324\n",
      "downhill: Adam 903 loss=0.604720 error=0.556835\n",
      "downhill: Adam 904 loss=0.603237 error=0.555352\n",
      "downhill: Adam 905 loss=0.601759 error=0.553873\n",
      "downhill: Adam 906 loss=0.600285 error=0.552400\n",
      "downhill: Adam 907 loss=0.598817 error=0.550931\n",
      "downhill: Adam 908 loss=0.597355 error=0.549468\n",
      "downhill: Adam 909 loss=0.595897 error=0.548010\n",
      "downhill: Adam 910 loss=0.594444 error=0.546557\n",
      "downhill: validation 91 loss=0.592996 error=0.545109 *\n",
      "downhill: Adam 911 loss=0.592996 error=0.545109\n",
      "downhill: Adam 912 loss=0.591554 error=0.543666\n",
      "downhill: Adam 913 loss=0.590116 error=0.542228\n",
      "downhill: Adam 914 loss=0.588683 error=0.540795\n",
      "downhill: Adam 915 loss=0.587256 error=0.539367\n",
      "downhill: Adam 916 loss=0.585833 error=0.537944\n",
      "downhill: Adam 917 loss=0.584415 error=0.536526\n",
      "downhill: Adam 918 loss=0.583002 error=0.535113\n",
      "downhill: Adam 919 loss=0.581594 error=0.533705\n",
      "downhill: Adam 920 loss=0.580191 error=0.532301\n",
      "downhill: validation 92 loss=0.578793 error=0.530903 *\n",
      "downhill: Adam 921 loss=0.578793 error=0.530903\n",
      "downhill: Adam 922 loss=0.577400 error=0.529509\n",
      "downhill: Adam 923 loss=0.576011 error=0.528120\n",
      "downhill: Adam 924 loss=0.574627 error=0.526736\n",
      "downhill: Adam 925 loss=0.573249 error=0.525356\n",
      "downhill: Adam 926 loss=0.571874 error=0.523982\n",
      "downhill: Adam 927 loss=0.570505 error=0.522612\n",
      "downhill: Adam 928 loss=0.569140 error=0.521247\n",
      "downhill: Adam 929 loss=0.567780 error=0.519887\n",
      "downhill: Adam 930 loss=0.566425 error=0.518531\n",
      "downhill: validation 93 loss=0.565075 error=0.517180 *\n",
      "downhill: Adam 931 loss=0.565075 error=0.517180\n",
      "downhill: Adam 932 loss=0.563729 error=0.515833\n",
      "downhill: Adam 933 loss=0.562388 error=0.514492\n",
      "downhill: Adam 934 loss=0.561051 error=0.513155\n",
      "downhill: Adam 935 loss=0.559719 error=0.511822\n",
      "downhill: Adam 936 loss=0.558392 error=0.510494\n",
      "downhill: Adam 937 loss=0.557069 error=0.509171\n",
      "downhill: Adam 938 loss=0.555751 error=0.507852\n",
      "downhill: Adam 939 loss=0.554437 error=0.506538\n",
      "downhill: Adam 940 loss=0.553128 error=0.505228\n",
      "downhill: validation 94 loss=0.551823 error=0.503923 *\n",
      "downhill: Adam 941 loss=0.551823 error=0.503923\n",
      "downhill: Adam 942 loss=0.550523 error=0.502622\n",
      "downhill: Adam 943 loss=0.549227 error=0.501326\n",
      "downhill: Adam 944 loss=0.547936 error=0.500034\n",
      "downhill: Adam 945 loss=0.546649 error=0.498747\n",
      "downhill: Adam 946 loss=0.545367 error=0.497464\n",
      "downhill: Adam 947 loss=0.544089 error=0.496185\n",
      "downhill: Adam 948 loss=0.542815 error=0.494911\n",
      "downhill: Adam 949 loss=0.541546 error=0.493641\n",
      "downhill: Adam 950 loss=0.540281 error=0.492375\n",
      "downhill: validation 95 loss=0.539020 error=0.491114 *\n",
      "downhill: Adam 951 loss=0.539020 error=0.491114\n",
      "downhill: Adam 952 loss=0.537764 error=0.489857\n",
      "downhill: Adam 953 loss=0.536512 error=0.488604\n",
      "downhill: Adam 954 loss=0.535264 error=0.487356\n",
      "downhill: Adam 955 loss=0.534021 error=0.486112\n",
      "downhill: Adam 956 loss=0.532782 error=0.484872\n",
      "downhill: Adam 957 loss=0.531547 error=0.483636\n",
      "downhill: Adam 958 loss=0.530316 error=0.482405\n",
      "downhill: Adam 959 loss=0.529089 error=0.481177\n",
      "downhill: Adam 960 loss=0.527867 error=0.479954\n",
      "downhill: validation 96 loss=0.526649 error=0.478735 *\n",
      "downhill: Adam 961 loss=0.526649 error=0.478735\n",
      "downhill: Adam 962 loss=0.525434 error=0.477520\n",
      "downhill: Adam 963 loss=0.524224 error=0.476309\n",
      "downhill: Adam 964 loss=0.523019 error=0.475103\n",
      "downhill: Adam 965 loss=0.521817 error=0.473900\n",
      "downhill: Adam 966 loss=0.520619 error=0.472702\n",
      "downhill: Adam 967 loss=0.519425 error=0.471507\n",
      "downhill: Adam 968 loss=0.518235 error=0.470317\n",
      "downhill: Adam 969 loss=0.517050 error=0.469130\n",
      "downhill: Adam 970 loss=0.515868 error=0.467948\n",
      "downhill: validation 97 loss=0.514690 error=0.466769 *\n",
      "downhill: Adam 971 loss=0.514690 error=0.466769\n",
      "downhill: Adam 972 loss=0.513516 error=0.465594\n",
      "downhill: Adam 973 loss=0.512347 error=0.464424\n",
      "downhill: Adam 974 loss=0.511181 error=0.463257\n",
      "downhill: Adam 975 loss=0.510019 error=0.462094\n",
      "downhill: Adam 976 loss=0.508861 error=0.460935\n",
      "downhill: Adam 977 loss=0.507706 error=0.459780\n",
      "downhill: Adam 978 loss=0.506556 error=0.458629\n",
      "downhill: Adam 979 loss=0.505409 error=0.457481\n",
      "downhill: Adam 980 loss=0.504267 error=0.456338\n",
      "downhill: validation 98 loss=0.503128 error=0.455198 *\n",
      "downhill: Adam 981 loss=0.503128 error=0.455198\n",
      "downhill: Adam 982 loss=0.501993 error=0.454062\n",
      "downhill: Adam 983 loss=0.500861 error=0.452930\n",
      "downhill: Adam 984 loss=0.499734 error=0.451801\n",
      "downhill: Adam 985 loss=0.498610 error=0.450677\n",
      "downhill: Adam 986 loss=0.497490 error=0.449555\n",
      "downhill: Adam 987 loss=0.496373 error=0.448438\n",
      "downhill: Adam 988 loss=0.495261 error=0.447324\n",
      "downhill: Adam 989 loss=0.494151 error=0.446214\n",
      "downhill: Adam 990 loss=0.493046 error=0.445108\n",
      "downhill: validation 99 loss=0.491944 error=0.444005 *\n",
      "downhill: Adam 991 loss=0.491944 error=0.444005\n",
      "downhill: Adam 992 loss=0.490846 error=0.442906\n",
      "downhill: Adam 993 loss=0.489752 error=0.441811\n",
      "downhill: Adam 994 loss=0.488661 error=0.440719\n",
      "downhill: Adam 995 loss=0.487573 error=0.439630\n",
      "downhill: Adam 996 loss=0.486489 error=0.438545\n",
      "downhill: Adam 997 loss=0.485409 error=0.437464\n",
      "downhill: Adam 998 loss=0.484332 error=0.436386\n",
      "downhill: Adam 999 loss=0.483259 error=0.435312\n",
      "downhill: Adam 1000 loss=0.482189 error=0.434241\n",
      "downhill: validation 100 loss=0.481123 error=0.433174 *\n",
      "downhill: Adam 1001 loss=0.481123 error=0.433174\n",
      "downhill: Adam 1002 loss=0.480060 error=0.432110\n",
      "downhill: Adam 1003 loss=0.479001 error=0.431050\n",
      "downhill: Adam 1004 loss=0.477945 error=0.429993\n",
      "downhill: Adam 1005 loss=0.476892 error=0.428939\n",
      "downhill: Adam 1006 loss=0.475843 error=0.427889\n",
      "downhill: Adam 1007 loss=0.474797 error=0.426842\n",
      "downhill: Adam 1008 loss=0.473755 error=0.425798\n",
      "downhill: Adam 1009 loss=0.472715 error=0.424758\n",
      "downhill: Adam 1010 loss=0.471680 error=0.423721\n",
      "downhill: validation 101 loss=0.470647 error=0.422688 *\n",
      "downhill: Adam 1011 loss=0.470647 error=0.422688\n",
      "downhill: Adam 1012 loss=0.469618 error=0.421658\n",
      "downhill: Adam 1013 loss=0.468592 error=0.420631\n",
      "downhill: Adam 1014 loss=0.467569 error=0.419607\n",
      "downhill: Adam 1015 loss=0.466550 error=0.418586\n",
      "downhill: Adam 1016 loss=0.465534 error=0.417569\n",
      "downhill: Adam 1017 loss=0.464521 error=0.416555\n",
      "downhill: Adam 1018 loss=0.463511 error=0.415544\n",
      "downhill: Adam 1019 loss=0.462505 error=0.414537\n",
      "downhill: Adam 1020 loss=0.461501 error=0.413532\n",
      "downhill: validation 102 loss=0.460501 error=0.412531 *\n",
      "downhill: Adam 1021 loss=0.460501 error=0.412531\n",
      "downhill: Adam 1022 loss=0.459504 error=0.411533\n",
      "downhill: Adam 1023 loss=0.458510 error=0.410538\n",
      "downhill: Adam 1024 loss=0.457519 error=0.409546\n",
      "downhill: Adam 1025 loss=0.456531 error=0.408557\n",
      "downhill: Adam 1026 loss=0.455547 error=0.407571\n",
      "downhill: Adam 1027 loss=0.454565 error=0.406588\n",
      "downhill: Adam 1028 loss=0.453587 error=0.405609\n",
      "downhill: Adam 1029 loss=0.452611 error=0.404632\n",
      "downhill: Adam 1030 loss=0.451639 error=0.403658\n",
      "downhill: validation 103 loss=0.450669 error=0.402688 *\n",
      "downhill: Adam 1031 loss=0.450669 error=0.402688\n",
      "downhill: Adam 1032 loss=0.449703 error=0.401720\n",
      "downhill: Adam 1033 loss=0.448740 error=0.400756\n",
      "downhill: Adam 1034 loss=0.447779 error=0.399794\n",
      "downhill: Adam 1035 loss=0.446822 error=0.398835\n",
      "downhill: Adam 1036 loss=0.445867 error=0.397880\n",
      "downhill: Adam 1037 loss=0.444915 error=0.396927\n",
      "downhill: Adam 1038 loss=0.443967 error=0.395977\n",
      "downhill: Adam 1039 loss=0.443021 error=0.395030\n",
      "downhill: Adam 1040 loss=0.442078 error=0.394086\n",
      "downhill: validation 104 loss=0.441138 error=0.393144 *\n",
      "downhill: Adam 1041 loss=0.441138 error=0.393144\n",
      "downhill: Adam 1042 loss=0.440201 error=0.392206\n",
      "downhill: Adam 1043 loss=0.439266 error=0.391270\n",
      "downhill: Adam 1044 loss=0.438335 error=0.390338\n",
      "downhill: Adam 1045 loss=0.437406 error=0.389408\n",
      "downhill: Adam 1046 loss=0.436480 error=0.388480\n",
      "downhill: Adam 1047 loss=0.435557 error=0.387556\n",
      "downhill: Adam 1048 loss=0.434637 error=0.386634\n",
      "downhill: Adam 1049 loss=0.433719 error=0.385716\n",
      "downhill: Adam 1050 loss=0.432804 error=0.384800\n",
      "downhill: validation 105 loss=0.431892 error=0.383886 *\n",
      "downhill: Adam 1051 loss=0.431892 error=0.383886\n",
      "downhill: Adam 1052 loss=0.430983 error=0.382976\n",
      "downhill: Adam 1053 loss=0.430076 error=0.382068\n",
      "downhill: Adam 1054 loss=0.429173 error=0.381162\n",
      "downhill: Adam 1055 loss=0.428271 error=0.380260\n",
      "downhill: Adam 1056 loss=0.427373 error=0.379360\n",
      "downhill: Adam 1057 loss=0.426477 error=0.378463\n",
      "downhill: Adam 1058 loss=0.425584 error=0.377568\n",
      "downhill: Adam 1059 loss=0.424693 error=0.376676\n",
      "downhill: Adam 1060 loss=0.423805 error=0.375787\n",
      "downhill: validation 106 loss=0.422920 error=0.374900 *\n",
      "downhill: Adam 1061 loss=0.422920 error=0.374900\n",
      "downhill: Adam 1062 loss=0.422037 error=0.374016\n",
      "downhill: Adam 1063 loss=0.421157 error=0.373134\n",
      "downhill: Adam 1064 loss=0.420279 error=0.372255\n",
      "downhill: Adam 1065 loss=0.419404 error=0.371379\n",
      "downhill: Adam 1066 loss=0.418531 error=0.370505\n",
      "downhill: Adam 1067 loss=0.417661 error=0.369633\n",
      "downhill: Adam 1068 loss=0.416794 error=0.368765\n",
      "downhill: Adam 1069 loss=0.415929 error=0.367898\n",
      "downhill: Adam 1070 loss=0.415066 error=0.367034\n",
      "downhill: validation 107 loss=0.414206 error=0.366173 *\n",
      "downhill: Adam 1071 loss=0.414206 error=0.366173\n",
      "downhill: Adam 1072 loss=0.413349 error=0.365314\n",
      "downhill: Adam 1073 loss=0.412494 error=0.364458\n",
      "downhill: Adam 1074 loss=0.411641 error=0.363604\n",
      "downhill: Adam 1075 loss=0.410791 error=0.362752\n",
      "downhill: Adam 1076 loss=0.409944 error=0.361903\n",
      "downhill: Adam 1077 loss=0.409098 error=0.361056\n",
      "downhill: Adam 1078 loss=0.408256 error=0.360212\n",
      "downhill: Adam 1079 loss=0.407415 error=0.359370\n",
      "downhill: Adam 1080 loss=0.406577 error=0.358531\n",
      "downhill: validation 108 loss=0.405741 error=0.357694 *\n",
      "downhill: Adam 1081 loss=0.405741 error=0.357694\n",
      "downhill: Adam 1082 loss=0.404908 error=0.356859\n",
      "downhill: Adam 1083 loss=0.404077 error=0.356027\n",
      "downhill: Adam 1084 loss=0.403249 error=0.355196\n",
      "downhill: Adam 1085 loss=0.402422 error=0.354369\n",
      "downhill: Adam 1086 loss=0.401599 error=0.353543\n",
      "downhill: Adam 1087 loss=0.400777 error=0.352720\n",
      "downhill: Adam 1088 loss=0.399958 error=0.351900\n",
      "downhill: Adam 1089 loss=0.399141 error=0.351081\n",
      "downhill: Adam 1090 loss=0.398326 error=0.350265\n",
      "downhill: validation 109 loss=0.397514 error=0.349451 *\n",
      "downhill: Adam 1091 loss=0.397514 error=0.349451\n",
      "downhill: Adam 1092 loss=0.396704 error=0.348639\n",
      "downhill: Adam 1093 loss=0.395896 error=0.347830\n",
      "downhill: Adam 1094 loss=0.395090 error=0.347023\n",
      "downhill: Adam 1095 loss=0.394287 error=0.346218\n",
      "downhill: Adam 1096 loss=0.393486 error=0.345415\n",
      "downhill: Adam 1097 loss=0.392687 error=0.344615\n",
      "downhill: Adam 1098 loss=0.391890 error=0.343816\n",
      "downhill: Adam 1099 loss=0.391096 error=0.343020\n",
      "downhill: Adam 1100 loss=0.390303 error=0.342227\n",
      "downhill: validation 110 loss=0.389513 error=0.341435 *\n",
      "downhill: Adam 1101 loss=0.389513 error=0.341435\n",
      "downhill: Adam 1102 loss=0.388725 error=0.340645\n",
      "downhill: Adam 1103 loss=0.387940 error=0.339858\n",
      "downhill: Adam 1104 loss=0.387156 error=0.339073\n",
      "downhill: Adam 1105 loss=0.386374 error=0.338290\n",
      "downhill: Adam 1106 loss=0.385595 error=0.337509\n",
      "downhill: Adam 1107 loss=0.384818 error=0.336730\n",
      "downhill: Adam 1108 loss=0.384043 error=0.335954\n",
      "downhill: Adam 1109 loss=0.383270 error=0.335179\n",
      "downhill: Adam 1110 loss=0.382499 error=0.334407\n",
      "downhill: validation 111 loss=0.381731 error=0.333636 *\n",
      "downhill: Adam 1111 loss=0.381731 error=0.333636\n",
      "downhill: Adam 1112 loss=0.380964 error=0.332868\n",
      "downhill: Adam 1113 loss=0.380199 error=0.332102\n",
      "downhill: Adam 1114 loss=0.379437 error=0.331338\n",
      "downhill: Adam 1115 loss=0.378677 error=0.330576\n",
      "downhill: Adam 1116 loss=0.377918 error=0.329816\n",
      "downhill: Adam 1117 loss=0.377162 error=0.329058\n",
      "downhill: Adam 1118 loss=0.376408 error=0.328302\n",
      "downhill: Adam 1119 loss=0.375656 error=0.327548\n",
      "downhill: Adam 1120 loss=0.374905 error=0.326796\n",
      "downhill: validation 112 loss=0.374157 error=0.326047 *\n",
      "downhill: Adam 1121 loss=0.374157 error=0.326047\n",
      "downhill: Adam 1122 loss=0.373411 error=0.325299\n",
      "downhill: Adam 1123 loss=0.372667 error=0.324553\n",
      "downhill: Adam 1124 loss=0.371925 error=0.323809\n",
      "downhill: Adam 1125 loss=0.371185 error=0.323068\n",
      "downhill: Adam 1126 loss=0.370447 error=0.322328\n",
      "downhill: Adam 1127 loss=0.369711 error=0.321590\n",
      "downhill: Adam 1128 loss=0.368977 error=0.320854\n",
      "downhill: Adam 1129 loss=0.368244 error=0.320120\n",
      "downhill: Adam 1130 loss=0.367514 error=0.319389\n",
      "downhill: validation 113 loss=0.366786 error=0.318659 *\n",
      "downhill: Adam 1131 loss=0.366786 error=0.318659\n",
      "downhill: Adam 1132 loss=0.366060 error=0.317931\n",
      "downhill: Adam 1133 loss=0.365335 error=0.317205\n",
      "downhill: Adam 1134 loss=0.364613 error=0.316481\n",
      "downhill: Adam 1135 loss=0.363892 error=0.315758\n",
      "downhill: Adam 1136 loss=0.363174 error=0.315038\n",
      "downhill: Adam 1137 loss=0.362457 error=0.314320\n",
      "downhill: Adam 1138 loss=0.361742 error=0.313603\n",
      "downhill: Adam 1139 loss=0.361029 error=0.312889\n",
      "downhill: Adam 1140 loss=0.360319 error=0.312176\n",
      "downhill: validation 114 loss=0.359610 error=0.311466 *\n",
      "downhill: Adam 1141 loss=0.359610 error=0.311466\n",
      "downhill: Adam 1142 loss=0.358902 error=0.310757\n",
      "downhill: Adam 1143 loss=0.358197 error=0.310050\n",
      "downhill: Adam 1144 loss=0.357494 error=0.309345\n",
      "downhill: Adam 1145 loss=0.356792 error=0.308642\n",
      "downhill: Adam 1146 loss=0.356093 error=0.307940\n",
      "downhill: Adam 1147 loss=0.355395 error=0.307241\n",
      "downhill: Adam 1148 loss=0.354699 error=0.306543\n",
      "downhill: Adam 1149 loss=0.354005 error=0.305847\n",
      "downhill: Adam 1150 loss=0.353313 error=0.305153\n",
      "downhill: validation 115 loss=0.352623 error=0.304461 *\n",
      "downhill: Adam 1151 loss=0.352623 error=0.304461\n",
      "downhill: Adam 1152 loss=0.351934 error=0.303771\n",
      "downhill: Adam 1153 loss=0.351247 error=0.303083\n",
      "downhill: Adam 1154 loss=0.350562 error=0.302396\n",
      "downhill: Adam 1155 loss=0.349879 error=0.301711\n",
      "downhill: Adam 1156 loss=0.349198 error=0.301029\n",
      "downhill: Adam 1157 loss=0.348519 error=0.300347\n",
      "downhill: Adam 1158 loss=0.347841 error=0.299668\n",
      "downhill: Adam 1159 loss=0.347165 error=0.298991\n",
      "downhill: Adam 1160 loss=0.346491 error=0.298315\n",
      "downhill: validation 116 loss=0.345819 error=0.297641 *\n",
      "downhill: Adam 1161 loss=0.345819 error=0.297641\n",
      "downhill: Adam 1162 loss=0.345149 error=0.296969\n",
      "downhill: Adam 1163 loss=0.344480 error=0.296298\n",
      "downhill: Adam 1164 loss=0.343813 error=0.295630\n",
      "downhill: Adam 1165 loss=0.343148 error=0.294963\n",
      "downhill: Adam 1166 loss=0.342485 error=0.294298\n",
      "downhill: Adam 1167 loss=0.341823 error=0.293635\n",
      "downhill: Adam 1168 loss=0.341164 error=0.292973\n",
      "downhill: Adam 1169 loss=0.340506 error=0.292313\n",
      "downhill: Adam 1170 loss=0.339849 error=0.291655\n",
      "downhill: validation 117 loss=0.339195 error=0.290999 *\n",
      "downhill: Adam 1171 loss=0.339195 error=0.290999\n",
      "downhill: Adam 1172 loss=0.338542 error=0.290345\n",
      "downhill: Adam 1173 loss=0.337891 error=0.289692\n",
      "downhill: Adam 1174 loss=0.337242 error=0.289041\n",
      "downhill: Adam 1175 loss=0.336594 error=0.288392\n",
      "downhill: Adam 1176 loss=0.335948 error=0.287744\n",
      "downhill: Adam 1177 loss=0.335304 error=0.287098\n",
      "downhill: Adam 1178 loss=0.334662 error=0.286454\n",
      "downhill: Adam 1179 loss=0.334021 error=0.285812\n",
      "downhill: Adam 1180 loss=0.333382 error=0.285171\n",
      "downhill: validation 118 loss=0.332745 error=0.284532 *\n",
      "downhill: Adam 1181 loss=0.332745 error=0.284532\n",
      "downhill: Adam 1182 loss=0.332109 error=0.283895\n",
      "downhill: Adam 1183 loss=0.331475 error=0.283259\n",
      "downhill: Adam 1184 loss=0.330843 error=0.282626\n",
      "downhill: Adam 1185 loss=0.330213 error=0.281994\n",
      "downhill: Adam 1186 loss=0.329584 error=0.281363\n",
      "downhill: Adam 1187 loss=0.328957 error=0.280734\n",
      "downhill: Adam 1188 loss=0.328332 error=0.280107\n",
      "downhill: Adam 1189 loss=0.327708 error=0.279482\n",
      "downhill: Adam 1190 loss=0.327086 error=0.278858\n",
      "downhill: validation 119 loss=0.326465 error=0.278236 *\n",
      "downhill: Adam 1191 loss=0.326465 error=0.278236\n",
      "downhill: Adam 1192 loss=0.325847 error=0.277616\n",
      "downhill: Adam 1193 loss=0.325229 error=0.276997\n",
      "downhill: Adam 1194 loss=0.324614 error=0.276380\n",
      "downhill: Adam 1195 loss=0.324000 error=0.275765\n",
      "downhill: Adam 1196 loss=0.323388 error=0.275151\n",
      "downhill: Adam 1197 loss=0.322778 error=0.274539\n",
      "downhill: Adam 1198 loss=0.322169 error=0.273928\n",
      "downhill: Adam 1199 loss=0.321562 error=0.273320\n",
      "downhill: Adam 1200 loss=0.320956 error=0.272712\n",
      "downhill: validation 120 loss=0.320352 error=0.272107 *\n",
      "downhill: Adam 1201 loss=0.320352 error=0.272107\n",
      "downhill: Adam 1202 loss=0.319750 error=0.271503\n",
      "downhill: Adam 1203 loss=0.319149 error=0.270901\n",
      "downhill: Adam 1204 loss=0.318550 error=0.270300\n",
      "downhill: Adam 1205 loss=0.317953 error=0.269701\n",
      "downhill: Adam 1206 loss=0.317357 error=0.269104\n",
      "downhill: Adam 1207 loss=0.316763 error=0.268508\n",
      "downhill: Adam 1208 loss=0.316170 error=0.267914\n",
      "downhill: Adam 1209 loss=0.315579 error=0.267322\n",
      "downhill: Adam 1210 loss=0.314990 error=0.266731\n",
      "downhill: validation 121 loss=0.314402 error=0.266142 *\n",
      "downhill: Adam 1211 loss=0.314402 error=0.266142\n",
      "downhill: Adam 1212 loss=0.313816 error=0.265554\n",
      "downhill: Adam 1213 loss=0.313232 error=0.264968\n",
      "downhill: Adam 1214 loss=0.312649 error=0.264384\n",
      "downhill: Adam 1215 loss=0.312067 error=0.263801\n",
      "downhill: Adam 1216 loss=0.311488 error=0.263220\n",
      "downhill: Adam 1217 loss=0.310910 error=0.262640\n",
      "downhill: Adam 1218 loss=0.310333 error=0.262062\n",
      "downhill: Adam 1219 loss=0.309758 error=0.261486\n",
      "downhill: Adam 1220 loss=0.309185 error=0.260911\n",
      "downhill: validation 122 loss=0.308613 error=0.260338 *\n",
      "downhill: Adam 1221 loss=0.308613 error=0.260338\n",
      "downhill: Adam 1222 loss=0.308042 error=0.259766\n",
      "downhill: Adam 1223 loss=0.307474 error=0.259196\n",
      "downhill: Adam 1224 loss=0.306906 error=0.258627\n",
      "downhill: Adam 1225 loss=0.306341 error=0.258061\n",
      "downhill: Adam 1226 loss=0.305777 error=0.257495\n",
      "downhill: Adam 1227 loss=0.305214 error=0.256931\n",
      "downhill: Adam 1228 loss=0.304653 error=0.256369\n",
      "downhill: Adam 1229 loss=0.304094 error=0.255808\n",
      "downhill: Adam 1230 loss=0.303536 error=0.255249\n",
      "downhill: validation 123 loss=0.302980 error=0.254692 *\n",
      "downhill: Adam 1231 loss=0.302980 error=0.254692\n",
      "downhill: Adam 1232 loss=0.302425 error=0.254136\n",
      "downhill: Adam 1233 loss=0.301871 error=0.253581\n",
      "downhill: Adam 1234 loss=0.301320 error=0.253028\n",
      "downhill: Adam 1235 loss=0.300769 error=0.252477\n",
      "downhill: Adam 1236 loss=0.300221 error=0.251927\n",
      "downhill: Adam 1237 loss=0.299674 error=0.251378\n",
      "downhill: Adam 1238 loss=0.299128 error=0.250832\n",
      "downhill: Adam 1239 loss=0.298584 error=0.250286\n",
      "downhill: Adam 1240 loss=0.298041 error=0.249742\n",
      "downhill: validation 124 loss=0.297500 error=0.249200 *\n",
      "downhill: Adam 1241 loss=0.297500 error=0.249200\n",
      "downhill: Adam 1242 loss=0.296960 error=0.248659\n",
      "downhill: Adam 1243 loss=0.296422 error=0.248120\n",
      "downhill: Adam 1244 loss=0.295885 error=0.247582\n",
      "downhill: Adam 1245 loss=0.295350 error=0.247046\n",
      "downhill: Adam 1246 loss=0.294816 error=0.246512\n",
      "downhill: Adam 1247 loss=0.294284 error=0.245978\n",
      "downhill: Adam 1248 loss=0.293754 error=0.245447\n",
      "downhill: Adam 1249 loss=0.293224 error=0.244916\n",
      "downhill: Adam 1250 loss=0.292697 error=0.244388\n",
      "downhill: validation 125 loss=0.292170 error=0.243861 *\n",
      "downhill: Adam 1251 loss=0.292170 error=0.243861\n",
      "downhill: Adam 1252 loss=0.291645 error=0.243335\n",
      "downhill: Adam 1253 loss=0.291122 error=0.242811\n",
      "downhill: Adam 1254 loss=0.290600 error=0.242288\n",
      "downhill: Adam 1255 loss=0.290080 error=0.241766\n",
      "downhill: Adam 1256 loss=0.289561 error=0.241247\n",
      "downhill: Adam 1257 loss=0.289043 error=0.240728\n",
      "downhill: Adam 1258 loss=0.288527 error=0.240211\n",
      "downhill: Adam 1259 loss=0.288012 error=0.239696\n",
      "downhill: Adam 1260 loss=0.287499 error=0.239182\n",
      "downhill: validation 126 loss=0.286987 error=0.238670 *\n",
      "downhill: Adam 1261 loss=0.286987 error=0.238670\n",
      "downhill: Adam 1262 loss=0.286477 error=0.238158\n",
      "downhill: Adam 1263 loss=0.285968 error=0.237649\n",
      "downhill: Adam 1264 loss=0.285461 error=0.237141\n",
      "downhill: Adam 1265 loss=0.284954 error=0.236634\n",
      "downhill: Adam 1266 loss=0.284450 error=0.236129\n",
      "downhill: Adam 1267 loss=0.283947 error=0.235625\n",
      "downhill: Adam 1268 loss=0.283445 error=0.235122\n",
      "downhill: Adam 1269 loss=0.282944 error=0.234622\n",
      "downhill: Adam 1270 loss=0.282445 error=0.234122\n",
      "downhill: validation 127 loss=0.281948 error=0.233624 *\n",
      "downhill: Adam 1271 loss=0.281948 error=0.233624\n",
      "downhill: Adam 1272 loss=0.281451 error=0.233127\n",
      "downhill: Adam 1273 loss=0.280956 error=0.232632\n",
      "downhill: Adam 1274 loss=0.280463 error=0.232138\n",
      "downhill: Adam 1275 loss=0.279971 error=0.231646\n",
      "downhill: Adam 1276 loss=0.279480 error=0.231155\n",
      "downhill: Adam 1277 loss=0.278991 error=0.230665\n",
      "downhill: Adam 1278 loss=0.278503 error=0.230177\n",
      "downhill: Adam 1279 loss=0.278016 error=0.229690\n",
      "downhill: Adam 1280 loss=0.277531 error=0.229204\n",
      "downhill: validation 128 loss=0.277047 error=0.228720 *\n",
      "downhill: Adam 1281 loss=0.277047 error=0.228720\n",
      "downhill: Adam 1282 loss=0.276565 error=0.228237\n",
      "downhill: Adam 1283 loss=0.276083 error=0.227756\n",
      "downhill: Adam 1284 loss=0.275604 error=0.227276\n",
      "downhill: Adam 1285 loss=0.275125 error=0.226798\n",
      "downhill: Adam 1286 loss=0.274648 error=0.226320\n",
      "downhill: Adam 1287 loss=0.274172 error=0.225845\n",
      "downhill: Adam 1288 loss=0.273698 error=0.225370\n",
      "downhill: Adam 1289 loss=0.273225 error=0.224897\n",
      "downhill: Adam 1290 loss=0.272753 error=0.224425\n",
      "downhill: validation 129 loss=0.272282 error=0.223955 *\n",
      "downhill: Adam 1291 loss=0.272282 error=0.223955\n",
      "downhill: Adam 1292 loss=0.271813 error=0.223486\n",
      "downhill: Adam 1293 loss=0.271345 error=0.223018\n",
      "downhill: Adam 1294 loss=0.270879 error=0.222552\n",
      "downhill: Adam 1295 loss=0.270413 error=0.222087\n",
      "downhill: Adam 1296 loss=0.269949 error=0.221623\n",
      "downhill: Adam 1297 loss=0.269487 error=0.221161\n",
      "downhill: Adam 1298 loss=0.269025 error=0.220699\n",
      "downhill: Adam 1299 loss=0.268565 error=0.220240\n",
      "downhill: Adam 1300 loss=0.268107 error=0.219781\n",
      "downhill: validation 130 loss=0.267649 error=0.219324 *\n",
      "downhill: Adam 1301 loss=0.267649 error=0.219324\n",
      "downhill: Adam 1302 loss=0.267193 error=0.218868\n",
      "downhill: Adam 1303 loss=0.266738 error=0.218414\n",
      "downhill: Adam 1304 loss=0.266284 error=0.217961\n",
      "downhill: Adam 1305 loss=0.265832 error=0.217509\n",
      "downhill: Adam 1306 loss=0.265381 error=0.217058\n",
      "downhill: Adam 1307 loss=0.264931 error=0.216609\n",
      "downhill: Adam 1308 loss=0.264482 error=0.216161\n",
      "downhill: Adam 1309 loss=0.264035 error=0.215714\n",
      "downhill: Adam 1310 loss=0.263589 error=0.215269\n",
      "downhill: validation 131 loss=0.263144 error=0.214824 *\n",
      "downhill: Adam 1311 loss=0.263144 error=0.214824\n",
      "downhill: Adam 1312 loss=0.262700 error=0.214382\n",
      "downhill: Adam 1313 loss=0.262257 error=0.213940\n",
      "downhill: Adam 1314 loss=0.261816 error=0.213499\n",
      "downhill: Adam 1315 loss=0.261376 error=0.213060\n",
      "downhill: Adam 1316 loss=0.260937 error=0.212622\n",
      "downhill: Adam 1317 loss=0.260500 error=0.212186\n",
      "downhill: Adam 1318 loss=0.260063 error=0.211750\n",
      "downhill: Adam 1319 loss=0.259628 error=0.211316\n",
      "downhill: Adam 1320 loss=0.259194 error=0.210883\n",
      "downhill: validation 132 loss=0.258761 error=0.210452 *\n",
      "downhill: Adam 1321 loss=0.258761 error=0.210452\n",
      "downhill: Adam 1322 loss=0.258330 error=0.210021\n",
      "downhill: Adam 1323 loss=0.257899 error=0.209592\n",
      "downhill: Adam 1324 loss=0.257470 error=0.209164\n",
      "downhill: Adam 1325 loss=0.257042 error=0.208737\n",
      "downhill: Adam 1326 loss=0.256615 error=0.208311\n",
      "downhill: Adam 1327 loss=0.256190 error=0.207887\n",
      "downhill: Adam 1328 loss=0.255765 error=0.207464\n",
      "downhill: Adam 1329 loss=0.255342 error=0.207042\n",
      "downhill: Adam 1330 loss=0.254919 error=0.206621\n",
      "downhill: validation 133 loss=0.254498 error=0.206201 *\n",
      "downhill: Adam 1331 loss=0.254498 error=0.206201\n",
      "downhill: Adam 1332 loss=0.254078 error=0.205783\n",
      "downhill: Adam 1333 loss=0.253660 error=0.205366\n",
      "downhill: Adam 1334 loss=0.253242 error=0.204950\n",
      "downhill: Adam 1335 loss=0.252826 error=0.204535\n",
      "downhill: Adam 1336 loss=0.252410 error=0.204121\n",
      "downhill: Adam 1337 loss=0.251996 error=0.203708\n",
      "downhill: Adam 1338 loss=0.251583 error=0.203297\n",
      "downhill: Adam 1339 loss=0.251171 error=0.202887\n",
      "downhill: Adam 1340 loss=0.250760 error=0.202478\n",
      "downhill: validation 134 loss=0.250350 error=0.202070 *\n",
      "downhill: Adam 1341 loss=0.250350 error=0.202070\n",
      "downhill: Adam 1342 loss=0.249942 error=0.201663\n",
      "downhill: Adam 1343 loss=0.249534 error=0.201257\n",
      "downhill: Adam 1344 loss=0.249128 error=0.200853\n",
      "downhill: Adam 1345 loss=0.248722 error=0.200449\n",
      "downhill: Adam 1346 loss=0.248318 error=0.200047\n",
      "downhill: Adam 1347 loss=0.247915 error=0.199646\n",
      "downhill: Adam 1348 loss=0.247513 error=0.199246\n",
      "downhill: Adam 1349 loss=0.247112 error=0.198847\n",
      "downhill: Adam 1350 loss=0.246712 error=0.198449\n",
      "downhill: validation 135 loss=0.246313 error=0.198052 *\n",
      "downhill: Adam 1351 loss=0.246313 error=0.198052\n",
      "downhill: Adam 1352 loss=0.245915 error=0.197657\n",
      "downhill: Adam 1353 loss=0.245518 error=0.197262\n",
      "downhill: Adam 1354 loss=0.245122 error=0.196869\n",
      "downhill: Adam 1355 loss=0.244727 error=0.196476\n",
      "downhill: Adam 1356 loss=0.244334 error=0.196085\n",
      "downhill: Adam 1357 loss=0.243941 error=0.195695\n",
      "downhill: Adam 1358 loss=0.243550 error=0.195306\n",
      "downhill: Adam 1359 loss=0.243159 error=0.194918\n",
      "downhill: Adam 1360 loss=0.242770 error=0.194531\n",
      "downhill: validation 136 loss=0.242381 error=0.194145 *\n",
      "downhill: Adam 1361 loss=0.242381 error=0.194145\n",
      "downhill: Adam 1362 loss=0.241994 error=0.193760\n",
      "downhill: Adam 1363 loss=0.241607 error=0.193376\n",
      "downhill: Adam 1364 loss=0.241222 error=0.192993\n",
      "downhill: Adam 1365 loss=0.240837 error=0.192612\n",
      "downhill: Adam 1366 loss=0.240454 error=0.192231\n",
      "downhill: Adam 1367 loss=0.240071 error=0.191851\n",
      "downhill: Adam 1368 loss=0.239690 error=0.191473\n",
      "downhill: Adam 1369 loss=0.239309 error=0.191095\n",
      "downhill: Adam 1370 loss=0.238930 error=0.190719\n",
      "downhill: validation 137 loss=0.238552 error=0.190343 *\n",
      "downhill: Adam 1371 loss=0.238552 error=0.190343\n",
      "downhill: Adam 1372 loss=0.238174 error=0.189969\n",
      "downhill: Adam 1373 loss=0.237798 error=0.189595\n",
      "downhill: Adam 1374 loss=0.237422 error=0.189223\n",
      "downhill: Adam 1375 loss=0.237047 error=0.188851\n",
      "downhill: Adam 1376 loss=0.236674 error=0.188481\n",
      "downhill: Adam 1377 loss=0.236301 error=0.188111\n",
      "downhill: Adam 1378 loss=0.235929 error=0.187743\n",
      "downhill: Adam 1379 loss=0.235559 error=0.187375\n",
      "downhill: Adam 1380 loss=0.235189 error=0.187009\n",
      "downhill: validation 138 loss=0.234820 error=0.186643 *\n",
      "downhill: Adam 1381 loss=0.234820 error=0.186643\n",
      "downhill: Adam 1382 loss=0.234452 error=0.186278\n",
      "downhill: Adam 1383 loss=0.234085 error=0.185915\n",
      "downhill: Adam 1384 loss=0.233719 error=0.185552\n",
      "downhill: Adam 1385 loss=0.233354 error=0.185191\n",
      "downhill: Adam 1386 loss=0.232990 error=0.184830\n",
      "downhill: Adam 1387 loss=0.232627 error=0.184470\n",
      "downhill: Adam 1388 loss=0.232264 error=0.184111\n",
      "downhill: Adam 1389 loss=0.231903 error=0.183753\n",
      "downhill: Adam 1390 loss=0.231542 error=0.183397\n",
      "downhill: validation 139 loss=0.231183 error=0.183041 *\n",
      "downhill: Adam 1391 loss=0.231183 error=0.183041\n",
      "downhill: Adam 1392 loss=0.230824 error=0.182686\n",
      "downhill: Adam 1393 loss=0.230466 error=0.182331\n",
      "downhill: Adam 1394 loss=0.230109 error=0.181978\n",
      "downhill: Adam 1395 loss=0.229753 error=0.181626\n",
      "downhill: Adam 1396 loss=0.229398 error=0.181275\n",
      "downhill: Adam 1397 loss=0.229043 error=0.180924\n",
      "downhill: Adam 1398 loss=0.228690 error=0.180575\n",
      "downhill: Adam 1399 loss=0.228337 error=0.180226\n",
      "downhill: Adam 1400 loss=0.227986 error=0.179878\n",
      "downhill: validation 140 loss=0.227635 error=0.179532 *\n",
      "downhill: Adam 1401 loss=0.227635 error=0.179532\n",
      "downhill: Adam 1402 loss=0.227285 error=0.179186\n",
      "downhill: Adam 1403 loss=0.226936 error=0.178841\n",
      "downhill: Adam 1404 loss=0.226587 error=0.178496\n",
      "downhill: Adam 1405 loss=0.226240 error=0.178153\n",
      "downhill: Adam 1406 loss=0.225893 error=0.177811\n",
      "downhill: Adam 1407 loss=0.225547 error=0.177469\n",
      "downhill: Adam 1408 loss=0.225203 error=0.177129\n",
      "downhill: Adam 1409 loss=0.224858 error=0.176789\n",
      "downhill: Adam 1410 loss=0.224515 error=0.176450\n",
      "downhill: validation 141 loss=0.224173 error=0.176112 *\n",
      "downhill: Adam 1411 loss=0.224173 error=0.176112\n",
      "downhill: Adam 1412 loss=0.223831 error=0.175775\n",
      "downhill: Adam 1413 loss=0.223490 error=0.175438\n",
      "downhill: Adam 1414 loss=0.223150 error=0.175103\n",
      "downhill: Adam 1415 loss=0.222811 error=0.174768\n",
      "downhill: Adam 1416 loss=0.222473 error=0.174434\n",
      "downhill: Adam 1417 loss=0.222135 error=0.174101\n",
      "downhill: Adam 1418 loss=0.221799 error=0.173769\n",
      "downhill: Adam 1419 loss=0.221463 error=0.173438\n",
      "downhill: Adam 1420 loss=0.221127 error=0.173108\n",
      "downhill: validation 142 loss=0.220793 error=0.172778 *\n",
      "downhill: Adam 1421 loss=0.220793 error=0.172778\n",
      "downhill: Adam 1422 loss=0.220460 error=0.172449\n",
      "downhill: Adam 1423 loss=0.220127 error=0.172121\n",
      "downhill: Adam 1424 loss=0.219795 error=0.171794\n",
      "downhill: Adam 1425 loss=0.219463 error=0.171468\n",
      "downhill: Adam 1426 loss=0.219133 error=0.171142\n",
      "downhill: Adam 1427 loss=0.218803 error=0.170817\n",
      "downhill: Adam 1428 loss=0.218474 error=0.170493\n",
      "downhill: Adam 1429 loss=0.218146 error=0.170170\n",
      "downhill: Adam 1430 loss=0.217819 error=0.169848\n",
      "downhill: validation 143 loss=0.217492 error=0.169526 *\n",
      "downhill: Adam 1431 loss=0.217492 error=0.169526\n",
      "downhill: Adam 1432 loss=0.217166 error=0.169205\n",
      "downhill: Adam 1433 loss=0.216841 error=0.168885\n",
      "downhill: Adam 1434 loss=0.216517 error=0.168566\n",
      "downhill: Adam 1435 loss=0.216193 error=0.168248\n",
      "downhill: Adam 1436 loss=0.215870 error=0.167930\n",
      "downhill: Adam 1437 loss=0.215548 error=0.167613\n",
      "downhill: Adam 1438 loss=0.215227 error=0.167297\n",
      "downhill: Adam 1439 loss=0.214906 error=0.166981\n",
      "downhill: Adam 1440 loss=0.214586 error=0.166667\n",
      "downhill: validation 144 loss=0.214266 error=0.166353 *\n",
      "downhill: Adam 1441 loss=0.214266 error=0.166353\n",
      "downhill: Adam 1442 loss=0.213948 error=0.166039\n",
      "downhill: Adam 1443 loss=0.213630 error=0.165727\n",
      "downhill: Adam 1444 loss=0.213313 error=0.165415\n",
      "downhill: Adam 1445 loss=0.212996 error=0.165104\n",
      "downhill: Adam 1446 loss=0.212681 error=0.164794\n",
      "downhill: Adam 1447 loss=0.212366 error=0.164485\n",
      "downhill: Adam 1448 loss=0.212051 error=0.164176\n",
      "downhill: Adam 1449 loss=0.211738 error=0.163868\n",
      "downhill: Adam 1450 loss=0.211425 error=0.163560\n",
      "downhill: validation 145 loss=0.211112 error=0.163254 *\n",
      "downhill: Adam 1451 loss=0.211112 error=0.163254\n",
      "downhill: Adam 1452 loss=0.210801 error=0.162948\n",
      "downhill: Adam 1453 loss=0.210490 error=0.162643\n",
      "downhill: Adam 1454 loss=0.210180 error=0.162338\n",
      "downhill: Adam 1455 loss=0.209870 error=0.162034\n",
      "downhill: Adam 1456 loss=0.209561 error=0.161731\n",
      "downhill: Adam 1457 loss=0.209253 error=0.161429\n",
      "downhill: Adam 1458 loss=0.208945 error=0.161127\n",
      "downhill: Adam 1459 loss=0.208638 error=0.160826\n",
      "downhill: Adam 1460 loss=0.208332 error=0.160526\n",
      "downhill: validation 146 loss=0.208027 error=0.160226 *\n",
      "downhill: Adam 1461 loss=0.208027 error=0.160226\n",
      "downhill: Adam 1462 loss=0.207722 error=0.159927\n",
      "downhill: Adam 1463 loss=0.207417 error=0.159629\n",
      "downhill: Adam 1464 loss=0.207114 error=0.159331\n",
      "downhill: Adam 1465 loss=0.206811 error=0.159034\n",
      "downhill: Adam 1466 loss=0.206508 error=0.158738\n",
      "downhill: Adam 1467 loss=0.206207 error=0.158442\n",
      "downhill: Adam 1468 loss=0.205906 error=0.158148\n",
      "downhill: Adam 1469 loss=0.205605 error=0.157853\n",
      "downhill: Adam 1470 loss=0.205305 error=0.157560\n",
      "downhill: validation 147 loss=0.205006 error=0.157267 *\n",
      "downhill: Adam 1471 loss=0.205006 error=0.157267\n",
      "downhill: Adam 1472 loss=0.204707 error=0.156974\n",
      "downhill: Adam 1473 loss=0.204409 error=0.156683\n",
      "downhill: Adam 1474 loss=0.204112 error=0.156392\n",
      "downhill: Adam 1475 loss=0.203815 error=0.156101\n",
      "downhill: Adam 1476 loss=0.203519 error=0.155811\n",
      "downhill: Adam 1477 loss=0.203224 error=0.155522\n",
      "downhill: Adam 1478 loss=0.202929 error=0.155234\n",
      "downhill: Adam 1479 loss=0.202634 error=0.154946\n",
      "downhill: Adam 1480 loss=0.202340 error=0.154658\n",
      "downhill: validation 148 loss=0.202047 error=0.154372 *\n",
      "downhill: Adam 1481 loss=0.202047 error=0.154372\n",
      "downhill: Adam 1482 loss=0.201755 error=0.154086\n",
      "downhill: Adam 1483 loss=0.201463 error=0.153800\n",
      "downhill: Adam 1484 loss=0.201171 error=0.153515\n",
      "downhill: Adam 1485 loss=0.200880 error=0.153231\n",
      "downhill: Adam 1486 loss=0.200590 error=0.152948\n",
      "downhill: Adam 1487 loss=0.200300 error=0.152665\n",
      "downhill: Adam 1488 loss=0.200011 error=0.152382\n",
      "downhill: Adam 1489 loss=0.199722 error=0.152100\n",
      "downhill: Adam 1490 loss=0.199434 error=0.151819\n",
      "downhill: validation 149 loss=0.199147 error=0.151538 *\n",
      "downhill: Adam 1491 loss=0.199147 error=0.151538\n",
      "downhill: Adam 1492 loss=0.198860 error=0.151258\n",
      "downhill: Adam 1493 loss=0.198574 error=0.150979\n",
      "downhill: Adam 1494 loss=0.198288 error=0.150700\n",
      "downhill: Adam 1495 loss=0.198002 error=0.150422\n",
      "downhill: Adam 1496 loss=0.197718 error=0.150144\n",
      "downhill: Adam 1497 loss=0.197433 error=0.149867\n",
      "downhill: Adam 1498 loss=0.197150 error=0.149590\n",
      "downhill: Adam 1499 loss=0.196867 error=0.149314\n",
      "downhill: Adam 1500 loss=0.196584 error=0.149038\n",
      "downhill: validation 150 loss=0.196302 error=0.148763 *\n",
      "downhill: Adam 1501 loss=0.196302 error=0.148763\n",
      "downhill: Adam 1502 loss=0.196020 error=0.148489\n",
      "downhill: Adam 1503 loss=0.195739 error=0.148215\n",
      "downhill: Adam 1504 loss=0.195459 error=0.147942\n",
      "downhill: Adam 1505 loss=0.195179 error=0.147669\n",
      "downhill: Adam 1506 loss=0.194899 error=0.147397\n",
      "downhill: Adam 1507 loss=0.194620 error=0.147125\n",
      "downhill: Adam 1508 loss=0.194342 error=0.146854\n",
      "downhill: Adam 1509 loss=0.194064 error=0.146583\n",
      "downhill: Adam 1510 loss=0.193786 error=0.146313\n",
      "downhill: validation 151 loss=0.193509 error=0.146043 *\n",
      "downhill: Adam 1511 loss=0.193509 error=0.146043\n",
      "downhill: Adam 1512 loss=0.193233 error=0.145774\n",
      "downhill: Adam 1513 loss=0.192957 error=0.145506\n",
      "downhill: Adam 1514 loss=0.192681 error=0.145238\n",
      "downhill: Adam 1515 loss=0.192406 error=0.144970\n",
      "downhill: Adam 1516 loss=0.192132 error=0.144703\n",
      "downhill: Adam 1517 loss=0.191857 error=0.144436\n",
      "downhill: Adam 1518 loss=0.191584 error=0.144170\n",
      "downhill: Adam 1519 loss=0.191311 error=0.143905\n",
      "downhill: Adam 1520 loss=0.191038 error=0.143640\n",
      "downhill: validation 152 loss=0.190766 error=0.143375 *\n",
      "downhill: Adam 1521 loss=0.190766 error=0.143375\n",
      "downhill: Adam 1522 loss=0.190494 error=0.143111\n",
      "downhill: Adam 1523 loss=0.190223 error=0.142848\n",
      "downhill: Adam 1524 loss=0.189952 error=0.142584\n",
      "downhill: Adam 1525 loss=0.189681 error=0.142322\n",
      "downhill: Adam 1526 loss=0.189411 error=0.142060\n",
      "downhill: Adam 1527 loss=0.189142 error=0.141798\n",
      "downhill: Adam 1528 loss=0.188873 error=0.141537\n",
      "downhill: Adam 1529 loss=0.188604 error=0.141276\n",
      "downhill: Adam 1530 loss=0.188336 error=0.141016\n",
      "downhill: validation 153 loss=0.188069 error=0.140756 *\n",
      "downhill: Adam 1531 loss=0.188069 error=0.140756\n",
      "downhill: Adam 1532 loss=0.187801 error=0.140497\n",
      "downhill: Adam 1533 loss=0.187535 error=0.140238\n",
      "downhill: Adam 1534 loss=0.187268 error=0.139980\n",
      "downhill: Adam 1535 loss=0.187002 error=0.139722\n",
      "downhill: Adam 1536 loss=0.186737 error=0.139464\n",
      "downhill: Adam 1537 loss=0.186472 error=0.139207\n",
      "downhill: Adam 1538 loss=0.186207 error=0.138951\n",
      "downhill: Adam 1539 loss=0.185943 error=0.138694\n",
      "downhill: Adam 1540 loss=0.185679 error=0.138439\n",
      "downhill: validation 154 loss=0.185416 error=0.138184 *\n",
      "downhill: Adam 1541 loss=0.185416 error=0.138184\n",
      "downhill: Adam 1542 loss=0.185153 error=0.137929\n",
      "downhill: Adam 1543 loss=0.184891 error=0.137674\n",
      "downhill: Adam 1544 loss=0.184629 error=0.137421\n",
      "downhill: Adam 1545 loss=0.184367 error=0.137167\n",
      "downhill: Adam 1546 loss=0.184106 error=0.136914\n",
      "downhill: Adam 1547 loss=0.183845 error=0.136662\n",
      "downhill: Adam 1548 loss=0.183585 error=0.136409\n",
      "downhill: Adam 1549 loss=0.183325 error=0.136158\n",
      "downhill: Adam 1550 loss=0.183065 error=0.135906\n",
      "downhill: validation 155 loss=0.182806 error=0.135656 *\n",
      "downhill: Adam 1551 loss=0.182806 error=0.135656\n",
      "downhill: Adam 1552 loss=0.182547 error=0.135405\n",
      "downhill: Adam 1553 loss=0.182289 error=0.135155\n",
      "downhill: Adam 1554 loss=0.182031 error=0.134905\n",
      "downhill: Adam 1555 loss=0.181773 error=0.134656\n",
      "downhill: Adam 1556 loss=0.181516 error=0.134407\n",
      "downhill: Adam 1557 loss=0.181259 error=0.134159\n",
      "downhill: Adam 1558 loss=0.181003 error=0.133911\n",
      "downhill: Adam 1559 loss=0.180747 error=0.133664\n",
      "downhill: Adam 1560 loss=0.180491 error=0.133416\n",
      "downhill: validation 156 loss=0.180236 error=0.133170 *\n",
      "downhill: Adam 1561 loss=0.180236 error=0.133170\n",
      "downhill: Adam 1562 loss=0.179981 error=0.132923\n",
      "downhill: Adam 1563 loss=0.179727 error=0.132678\n",
      "downhill: Adam 1564 loss=0.179473 error=0.132432\n",
      "downhill: Adam 1565 loss=0.179219 error=0.132187\n",
      "downhill: Adam 1566 loss=0.178966 error=0.131942\n",
      "downhill: Adam 1567 loss=0.178713 error=0.131698\n",
      "downhill: Adam 1568 loss=0.178460 error=0.131454\n",
      "downhill: Adam 1569 loss=0.178208 error=0.131210\n",
      "downhill: Adam 1570 loss=0.177956 error=0.130967\n",
      "downhill: validation 157 loss=0.177705 error=0.130724 *\n",
      "downhill: Adam 1571 loss=0.177705 error=0.130724\n",
      "downhill: Adam 1572 loss=0.177454 error=0.130482\n",
      "downhill: Adam 1573 loss=0.177203 error=0.130240\n",
      "downhill: Adam 1574 loss=0.176953 error=0.129999\n",
      "downhill: Adam 1575 loss=0.176703 error=0.129757\n",
      "downhill: Adam 1576 loss=0.176453 error=0.129517\n",
      "downhill: Adam 1577 loss=0.176204 error=0.129276\n",
      "downhill: Adam 1578 loss=0.175955 error=0.129036\n",
      "downhill: Adam 1579 loss=0.175706 error=0.128797\n",
      "downhill: Adam 1580 loss=0.175458 error=0.128557\n",
      "downhill: validation 158 loss=0.175210 error=0.128318 *\n",
      "downhill: Adam 1581 loss=0.175210 error=0.128318\n",
      "downhill: Adam 1582 loss=0.174963 error=0.128080\n",
      "downhill: Adam 1583 loss=0.174716 error=0.127842\n",
      "downhill: Adam 1584 loss=0.174469 error=0.127604\n",
      "downhill: Adam 1585 loss=0.174222 error=0.127367\n",
      "downhill: Adam 1586 loss=0.173976 error=0.127130\n",
      "downhill: Adam 1587 loss=0.173731 error=0.126893\n",
      "downhill: Adam 1588 loss=0.173485 error=0.126657\n",
      "downhill: Adam 1589 loss=0.173240 error=0.126421\n",
      "downhill: Adam 1590 loss=0.172996 error=0.126186\n",
      "downhill: validation 159 loss=0.172752 error=0.125950 *\n",
      "downhill: Adam 1591 loss=0.172752 error=0.125950\n",
      "downhill: Adam 1592 loss=0.172508 error=0.125716\n",
      "downhill: Adam 1593 loss=0.172264 error=0.125481\n",
      "downhill: Adam 1594 loss=0.172021 error=0.125247\n",
      "downhill: Adam 1595 loss=0.171778 error=0.125014\n",
      "downhill: Adam 1596 loss=0.171535 error=0.124780\n",
      "downhill: Adam 1597 loss=0.171293 error=0.124548\n",
      "downhill: Adam 1598 loss=0.171051 error=0.124315\n",
      "downhill: Adam 1599 loss=0.170810 error=0.124083\n",
      "downhill: Adam 1600 loss=0.170569 error=0.123851\n",
      "downhill: validation 160 loss=0.170328 error=0.123620 *\n",
      "downhill: Adam 1601 loss=0.170328 error=0.123620\n",
      "downhill: Adam 1602 loss=0.170087 error=0.123389\n",
      "downhill: Adam 1603 loss=0.169847 error=0.123158\n",
      "downhill: Adam 1604 loss=0.169607 error=0.122928\n",
      "downhill: Adam 1605 loss=0.169368 error=0.122698\n",
      "downhill: Adam 1606 loss=0.169129 error=0.122468\n",
      "downhill: Adam 1607 loss=0.168890 error=0.122239\n",
      "downhill: Adam 1608 loss=0.168651 error=0.122010\n",
      "downhill: Adam 1609 loss=0.168413 error=0.121782\n",
      "downhill: Adam 1610 loss=0.168175 error=0.121553\n",
      "downhill: validation 161 loss=0.167938 error=0.121326 *\n",
      "downhill: Adam 1611 loss=0.167938 error=0.121326\n",
      "downhill: Adam 1612 loss=0.167701 error=0.121098\n",
      "downhill: Adam 1613 loss=0.167464 error=0.120871\n",
      "downhill: Adam 1614 loss=0.167227 error=0.120644\n",
      "downhill: Adam 1615 loss=0.166991 error=0.120418\n",
      "downhill: Adam 1616 loss=0.166756 error=0.120192\n",
      "downhill: Adam 1617 loss=0.166520 error=0.119967\n",
      "downhill: Adam 1618 loss=0.166285 error=0.119741\n",
      "downhill: Adam 1619 loss=0.166050 error=0.119516\n",
      "downhill: Adam 1620 loss=0.165816 error=0.119292\n",
      "downhill: validation 162 loss=0.165582 error=0.119068 *\n",
      "downhill: Adam 1621 loss=0.165582 error=0.119068\n",
      "downhill: Adam 1622 loss=0.165348 error=0.118844\n",
      "downhill: Adam 1623 loss=0.165114 error=0.118621\n",
      "downhill: Adam 1624 loss=0.164881 error=0.118398\n",
      "downhill: Adam 1625 loss=0.164649 error=0.118175\n",
      "downhill: Adam 1626 loss=0.164416 error=0.117952\n",
      "downhill: Adam 1627 loss=0.164184 error=0.117730\n",
      "downhill: Adam 1628 loss=0.163953 error=0.117509\n",
      "downhill: Adam 1629 loss=0.163721 error=0.117288\n",
      "downhill: Adam 1630 loss=0.163490 error=0.117067\n",
      "downhill: validation 163 loss=0.163259 error=0.116846 *\n",
      "downhill: Adam 1631 loss=0.163259 error=0.116846\n",
      "downhill: Adam 1632 loss=0.163029 error=0.116626\n",
      "downhill: Adam 1633 loss=0.162799 error=0.116406\n",
      "downhill: Adam 1634 loss=0.162569 error=0.116187\n",
      "downhill: Adam 1635 loss=0.162340 error=0.115968\n",
      "downhill: Adam 1636 loss=0.162111 error=0.115749\n",
      "downhill: Adam 1637 loss=0.161883 error=0.115531\n",
      "downhill: Adam 1638 loss=0.161654 error=0.115313\n",
      "downhill: Adam 1639 loss=0.161426 error=0.115095\n",
      "downhill: Adam 1640 loss=0.161199 error=0.114878\n",
      "downhill: validation 164 loss=0.160971 error=0.114661 *\n",
      "downhill: Adam 1641 loss=0.160971 error=0.114661\n",
      "downhill: Adam 1642 loss=0.160745 error=0.114445\n",
      "downhill: Adam 1643 loss=0.160518 error=0.114229\n",
      "downhill: Adam 1644 loss=0.160292 error=0.114013\n",
      "downhill: Adam 1645 loss=0.160066 error=0.113797\n",
      "downhill: Adam 1646 loss=0.159840 error=0.113582\n",
      "downhill: Adam 1647 loss=0.159615 error=0.113368\n",
      "downhill: Adam 1648 loss=0.159390 error=0.113153\n",
      "downhill: Adam 1649 loss=0.159166 error=0.112940\n",
      "downhill: Adam 1650 loss=0.158941 error=0.112726\n",
      "downhill: validation 165 loss=0.158717 error=0.112513 *\n",
      "downhill: Adam 1651 loss=0.158717 error=0.112513\n",
      "downhill: Adam 1652 loss=0.158494 error=0.112300\n",
      "downhill: Adam 1653 loss=0.158271 error=0.112087\n",
      "downhill: Adam 1654 loss=0.158048 error=0.111875\n",
      "downhill: Adam 1655 loss=0.157825 error=0.111664\n",
      "downhill: Adam 1656 loss=0.157603 error=0.111452\n",
      "downhill: Adam 1657 loss=0.157381 error=0.111241\n",
      "downhill: Adam 1658 loss=0.157160 error=0.111031\n",
      "downhill: Adam 1659 loss=0.156939 error=0.110821\n",
      "downhill: Adam 1660 loss=0.156718 error=0.110611\n",
      "downhill: validation 166 loss=0.156498 error=0.110401 *\n",
      "downhill: Adam 1661 loss=0.156498 error=0.110401\n",
      "downhill: Adam 1662 loss=0.156277 error=0.110192\n",
      "downhill: Adam 1663 loss=0.156058 error=0.109983\n",
      "downhill: Adam 1664 loss=0.155838 error=0.109775\n",
      "downhill: Adam 1665 loss=0.155619 error=0.109567\n",
      "downhill: Adam 1666 loss=0.155400 error=0.109359\n",
      "downhill: Adam 1667 loss=0.155182 error=0.109152\n",
      "downhill: Adam 1668 loss=0.154964 error=0.108945\n",
      "downhill: Adam 1669 loss=0.154746 error=0.108738\n",
      "downhill: Adam 1670 loss=0.154529 error=0.108532\n",
      "downhill: validation 167 loss=0.154312 error=0.108326 *\n",
      "downhill: Adam 1671 loss=0.154312 error=0.108326\n",
      "downhill: Adam 1672 loss=0.154095 error=0.108121\n",
      "downhill: Adam 1673 loss=0.153878 error=0.107915\n",
      "downhill: Adam 1674 loss=0.153662 error=0.107711\n",
      "downhill: Adam 1675 loss=0.153447 error=0.107506\n",
      "downhill: Adam 1676 loss=0.153231 error=0.107302\n",
      "downhill: Adam 1677 loss=0.153016 error=0.107099\n",
      "downhill: Adam 1678 loss=0.152802 error=0.106895\n",
      "downhill: Adam 1679 loss=0.152587 error=0.106692\n",
      "downhill: Adam 1680 loss=0.152373 error=0.106490\n",
      "downhill: validation 168 loss=0.152160 error=0.106288 *\n",
      "downhill: Adam 1681 loss=0.152160 error=0.106288\n",
      "downhill: Adam 1682 loss=0.151946 error=0.106086\n",
      "downhill: Adam 1683 loss=0.151733 error=0.105884\n",
      "downhill: Adam 1684 loss=0.151521 error=0.105683\n",
      "downhill: Adam 1685 loss=0.151308 error=0.105482\n",
      "downhill: Adam 1686 loss=0.151096 error=0.105282\n",
      "downhill: Adam 1687 loss=0.150885 error=0.105082\n",
      "downhill: Adam 1688 loss=0.150673 error=0.104883\n",
      "downhill: Adam 1689 loss=0.150462 error=0.104683\n",
      "downhill: Adam 1690 loss=0.150252 error=0.104484\n",
      "downhill: validation 169 loss=0.150042 error=0.104286 *\n",
      "downhill: Adam 1691 loss=0.150042 error=0.104286\n",
      "downhill: Adam 1692 loss=0.149832 error=0.104088\n",
      "downhill: Adam 1693 loss=0.149622 error=0.103890\n",
      "downhill: Adam 1694 loss=0.149413 error=0.103693\n",
      "downhill: Adam 1695 loss=0.149204 error=0.103496\n",
      "downhill: Adam 1696 loss=0.148996 error=0.103299\n",
      "downhill: Adam 1697 loss=0.148787 error=0.103103\n",
      "downhill: Adam 1698 loss=0.148579 error=0.102907\n",
      "downhill: Adam 1699 loss=0.148372 error=0.102711\n",
      "downhill: Adam 1700 loss=0.148165 error=0.102516\n",
      "downhill: validation 170 loss=0.147958 error=0.102321 *\n",
      "downhill: Adam 1701 loss=0.147958 error=0.102321\n",
      "downhill: Adam 1702 loss=0.147751 error=0.102127\n",
      "downhill: Adam 1703 loss=0.147545 error=0.101933\n",
      "downhill: Adam 1704 loss=0.147339 error=0.101739\n",
      "downhill: Adam 1705 loss=0.147134 error=0.101546\n",
      "downhill: Adam 1706 loss=0.146929 error=0.101353\n",
      "downhill: Adam 1707 loss=0.146724 error=0.101160\n",
      "downhill: Adam 1708 loss=0.146520 error=0.100968\n",
      "downhill: Adam 1709 loss=0.146316 error=0.100776\n",
      "downhill: Adam 1710 loss=0.146112 error=0.100585\n",
      "downhill: validation 171 loss=0.145908 error=0.100393 *\n",
      "downhill: Adam 1711 loss=0.145908 error=0.100393\n",
      "downhill: Adam 1712 loss=0.145705 error=0.100203\n",
      "downhill: Adam 1713 loss=0.145503 error=0.100012\n",
      "downhill: Adam 1714 loss=0.145300 error=0.099822\n",
      "downhill: Adam 1715 loss=0.145098 error=0.099633\n",
      "downhill: Adam 1716 loss=0.144897 error=0.099443\n",
      "downhill: Adam 1717 loss=0.144695 error=0.099254\n",
      "downhill: Adam 1718 loss=0.144494 error=0.099066\n",
      "downhill: Adam 1719 loss=0.144294 error=0.098878\n",
      "downhill: Adam 1720 loss=0.144093 error=0.098690\n",
      "downhill: validation 172 loss=0.143893 error=0.098502 *\n",
      "downhill: Adam 1721 loss=0.143893 error=0.098502\n",
      "downhill: Adam 1722 loss=0.143694 error=0.098315\n",
      "downhill: Adam 1723 loss=0.143494 error=0.098128\n",
      "downhill: Adam 1724 loss=0.143296 error=0.097942\n",
      "downhill: Adam 1725 loss=0.143097 error=0.097756\n",
      "downhill: Adam 1726 loss=0.142899 error=0.097570\n",
      "downhill: Adam 1727 loss=0.142701 error=0.097385\n",
      "downhill: Adam 1728 loss=0.142503 error=0.097200\n",
      "downhill: Adam 1729 loss=0.142306 error=0.097016\n",
      "downhill: Adam 1730 loss=0.142109 error=0.096832\n",
      "downhill: validation 173 loss=0.141913 error=0.096648 *\n",
      "downhill: Adam 1731 loss=0.141913 error=0.096648\n",
      "downhill: Adam 1732 loss=0.141717 error=0.096465\n",
      "downhill: Adam 1733 loss=0.141521 error=0.096281\n",
      "downhill: Adam 1734 loss=0.141325 error=0.096099\n",
      "downhill: Adam 1735 loss=0.141130 error=0.095916\n",
      "downhill: Adam 1736 loss=0.140935 error=0.095734\n",
      "downhill: Adam 1737 loss=0.140741 error=0.095553\n",
      "downhill: Adam 1738 loss=0.140547 error=0.095372\n",
      "downhill: Adam 1739 loss=0.140353 error=0.095191\n",
      "downhill: Adam 1740 loss=0.140159 error=0.095010\n",
      "downhill: validation 174 loss=0.139966 error=0.094830 *\n",
      "downhill: Adam 1741 loss=0.139966 error=0.094830\n",
      "downhill: Adam 1742 loss=0.139774 error=0.094650\n",
      "downhill: Adam 1743 loss=0.139581 error=0.094471\n",
      "downhill: Adam 1744 loss=0.139389 error=0.094292\n",
      "downhill: Adam 1745 loss=0.139198 error=0.094113\n",
      "downhill: Adam 1746 loss=0.139006 error=0.093935\n",
      "downhill: Adam 1747 loss=0.138815 error=0.093757\n",
      "downhill: Adam 1748 loss=0.138625 error=0.093579\n",
      "downhill: Adam 1749 loss=0.138434 error=0.093402\n",
      "downhill: Adam 1750 loss=0.138244 error=0.093225\n",
      "downhill: validation 175 loss=0.138055 error=0.093049 *\n",
      "downhill: Adam 1751 loss=0.138055 error=0.093049\n",
      "downhill: Adam 1752 loss=0.137865 error=0.092873\n",
      "downhill: Adam 1753 loss=0.137676 error=0.092697\n",
      "downhill: Adam 1754 loss=0.137488 error=0.092522\n",
      "downhill: Adam 1755 loss=0.137299 error=0.092347\n",
      "downhill: Adam 1756 loss=0.137111 error=0.092172\n",
      "downhill: Adam 1757 loss=0.136924 error=0.091998\n",
      "downhill: Adam 1758 loss=0.136737 error=0.091824\n",
      "downhill: Adam 1759 loss=0.136550 error=0.091650\n",
      "downhill: Adam 1760 loss=0.136363 error=0.091477\n",
      "downhill: validation 176 loss=0.136177 error=0.091304 *\n",
      "downhill: Adam 1761 loss=0.136177 error=0.091304\n",
      "downhill: Adam 1762 loss=0.135991 error=0.091131\n",
      "downhill: Adam 1763 loss=0.135805 error=0.090959\n",
      "downhill: Adam 1764 loss=0.135620 error=0.090787\n",
      "downhill: Adam 1765 loss=0.135435 error=0.090616\n",
      "downhill: Adam 1766 loss=0.135251 error=0.090445\n",
      "downhill: Adam 1767 loss=0.135066 error=0.090274\n",
      "downhill: Adam 1768 loss=0.134882 error=0.090103\n",
      "downhill: Adam 1769 loss=0.134699 error=0.089933\n",
      "downhill: Adam 1770 loss=0.134516 error=0.089764\n",
      "downhill: validation 177 loss=0.134333 error=0.089594 *\n",
      "downhill: Adam 1771 loss=0.134333 error=0.089594\n",
      "downhill: Adam 1772 loss=0.134150 error=0.089425\n",
      "downhill: Adam 1773 loss=0.133968 error=0.089257\n",
      "downhill: Adam 1774 loss=0.133786 error=0.089088\n",
      "downhill: Adam 1775 loss=0.133605 error=0.088920\n",
      "downhill: Adam 1776 loss=0.133423 error=0.088753\n",
      "downhill: Adam 1777 loss=0.133242 error=0.088586\n",
      "downhill: Adam 1778 loss=0.133062 error=0.088419\n",
      "downhill: Adam 1779 loss=0.132882 error=0.088252\n",
      "downhill: Adam 1780 loss=0.132702 error=0.088086\n",
      "downhill: validation 178 loss=0.132523 error=0.087920 *\n",
      "downhill: Adam 1781 loss=0.132523 error=0.087920\n",
      "downhill: Adam 1782 loss=0.132343 error=0.087755\n",
      "downhill: Adam 1783 loss=0.132165 error=0.087590\n",
      "downhill: Adam 1784 loss=0.131986 error=0.087425\n",
      "downhill: Adam 1785 loss=0.131808 error=0.087260\n",
      "downhill: Adam 1786 loss=0.131630 error=0.087096\n",
      "downhill: Adam 1787 loss=0.131453 error=0.086933\n",
      "downhill: Adam 1788 loss=0.131276 error=0.086769\n",
      "downhill: Adam 1789 loss=0.131099 error=0.086606\n",
      "downhill: Adam 1790 loss=0.130922 error=0.086444\n",
      "downhill: validation 179 loss=0.130746 error=0.086281 *\n",
      "downhill: Adam 1791 loss=0.130746 error=0.086281\n",
      "downhill: Adam 1792 loss=0.130571 error=0.086119\n",
      "downhill: Adam 1793 loss=0.130395 error=0.085958\n",
      "downhill: Adam 1794 loss=0.130220 error=0.085797\n",
      "downhill: Adam 1795 loss=0.130046 error=0.085636\n",
      "downhill: Adam 1796 loss=0.129871 error=0.085475\n",
      "downhill: Adam 1797 loss=0.129697 error=0.085315\n",
      "downhill: Adam 1798 loss=0.129523 error=0.085155\n",
      "downhill: Adam 1799 loss=0.129350 error=0.084996\n",
      "downhill: Adam 1800 loss=0.129177 error=0.084836\n",
      "downhill: validation 180 loss=0.129004 error=0.084678 *\n",
      "downhill: Adam 1801 loss=0.129004 error=0.084678\n",
      "downhill: Adam 1802 loss=0.128832 error=0.084519\n",
      "downhill: Adam 1803 loss=0.128660 error=0.084361\n",
      "downhill: Adam 1804 loss=0.128488 error=0.084203\n",
      "downhill: Adam 1805 loss=0.128317 error=0.084046\n",
      "downhill: Adam 1806 loss=0.128146 error=0.083889\n",
      "downhill: Adam 1807 loss=0.127975 error=0.083732\n",
      "downhill: Adam 1808 loss=0.127805 error=0.083576\n",
      "downhill: Adam 1809 loss=0.127635 error=0.083420\n",
      "downhill: Adam 1810 loss=0.127465 error=0.083264\n",
      "downhill: validation 181 loss=0.127296 error=0.083109 *\n",
      "downhill: Adam 1811 loss=0.127296 error=0.083109\n",
      "downhill: Adam 1812 loss=0.127127 error=0.082953\n",
      "downhill: Adam 1813 loss=0.126958 error=0.082799\n",
      "downhill: Adam 1814 loss=0.126789 error=0.082644\n",
      "downhill: Adam 1815 loss=0.126621 error=0.082490\n",
      "downhill: Adam 1816 loss=0.126454 error=0.082337\n",
      "downhill: Adam 1817 loss=0.126286 error=0.082183\n",
      "downhill: Adam 1818 loss=0.126119 error=0.082030\n",
      "downhill: Adam 1819 loss=0.125953 error=0.081878\n",
      "downhill: Adam 1820 loss=0.125786 error=0.081725\n",
      "downhill: validation 182 loss=0.125620 error=0.081573 *\n",
      "downhill: Adam 1821 loss=0.125620 error=0.081573\n",
      "downhill: Adam 1822 loss=0.125455 error=0.081422\n",
      "downhill: Adam 1823 loss=0.125289 error=0.081270\n",
      "downhill: Adam 1824 loss=0.125124 error=0.081119\n",
      "downhill: Adam 1825 loss=0.124959 error=0.080969\n",
      "downhill: Adam 1826 loss=0.124795 error=0.080818\n",
      "downhill: Adam 1827 loss=0.124631 error=0.080668\n",
      "downhill: Adam 1828 loss=0.124467 error=0.080519\n",
      "downhill: Adam 1829 loss=0.124304 error=0.080369\n",
      "downhill: Adam 1830 loss=0.124140 error=0.080220\n",
      "downhill: validation 183 loss=0.123978 error=0.080072 *\n",
      "downhill: Adam 1831 loss=0.123978 error=0.080072\n",
      "downhill: Adam 1832 loss=0.123815 error=0.079923\n",
      "downhill: Adam 1833 loss=0.123653 error=0.079775\n",
      "downhill: Adam 1834 loss=0.123491 error=0.079627\n",
      "downhill: Adam 1835 loss=0.123330 error=0.079480\n",
      "downhill: Adam 1836 loss=0.123168 error=0.079333\n",
      "downhill: Adam 1837 loss=0.123007 error=0.079186\n",
      "downhill: Adam 1838 loss=0.122847 error=0.079040\n",
      "downhill: Adam 1839 loss=0.122687 error=0.078894\n",
      "downhill: Adam 1840 loss=0.122527 error=0.078748\n",
      "downhill: validation 184 loss=0.122367 error=0.078602 *\n",
      "downhill: Adam 1841 loss=0.122367 error=0.078602\n",
      "downhill: Adam 1842 loss=0.122208 error=0.078457\n",
      "downhill: Adam 1843 loss=0.122049 error=0.078312\n",
      "downhill: Adam 1844 loss=0.121890 error=0.078168\n",
      "downhill: Adam 1845 loss=0.121731 error=0.078024\n",
      "downhill: Adam 1846 loss=0.121573 error=0.077880\n",
      "downhill: Adam 1847 loss=0.121416 error=0.077736\n",
      "downhill: Adam 1848 loss=0.121258 error=0.077593\n",
      "downhill: Adam 1849 loss=0.121101 error=0.077450\n",
      "downhill: Adam 1850 loss=0.120944 error=0.077307\n",
      "downhill: validation 185 loss=0.120788 error=0.077165 *\n",
      "downhill: Adam 1851 loss=0.120788 error=0.077165\n",
      "downhill: Adam 1852 loss=0.120631 error=0.077023\n",
      "downhill: Adam 1853 loss=0.120475 error=0.076881\n",
      "downhill: Adam 1854 loss=0.120320 error=0.076740\n",
      "downhill: Adam 1855 loss=0.120165 error=0.076599\n",
      "downhill: Adam 1856 loss=0.120010 error=0.076458\n",
      "downhill: Adam 1857 loss=0.119855 error=0.076318\n",
      "downhill: Adam 1858 loss=0.119701 error=0.076178\n",
      "downhill: Adam 1859 loss=0.119546 error=0.076038\n",
      "downhill: Adam 1860 loss=0.119393 error=0.075898\n",
      "downhill: validation 186 loss=0.119239 error=0.075759 *\n",
      "downhill: Adam 1861 loss=0.119239 error=0.075759\n",
      "downhill: Adam 1862 loss=0.119086 error=0.075620\n",
      "downhill: Adam 1863 loss=0.118933 error=0.075482\n",
      "downhill: Adam 1864 loss=0.118781 error=0.075343\n",
      "downhill: Adam 1865 loss=0.118629 error=0.075205\n",
      "downhill: Adam 1866 loss=0.118477 error=0.075068\n",
      "downhill: Adam 1867 loss=0.118325 error=0.074930\n",
      "downhill: Adam 1868 loss=0.118174 error=0.074793\n",
      "downhill: Adam 1869 loss=0.118023 error=0.074656\n",
      "downhill: Adam 1870 loss=0.117872 error=0.074520\n",
      "downhill: validation 187 loss=0.117722 error=0.074384 *\n",
      "downhill: Adam 1871 loss=0.117722 error=0.074384\n",
      "downhill: Adam 1872 loss=0.117572 error=0.074248\n",
      "downhill: Adam 1873 loss=0.117422 error=0.074112\n",
      "downhill: Adam 1874 loss=0.117272 error=0.073977\n",
      "downhill: Adam 1875 loss=0.117123 error=0.073842\n",
      "downhill: Adam 1876 loss=0.116974 error=0.073707\n",
      "downhill: Adam 1877 loss=0.116825 error=0.073573\n",
      "downhill: Adam 1878 loss=0.116677 error=0.073438\n",
      "downhill: Adam 1879 loss=0.116529 error=0.073305\n",
      "downhill: Adam 1880 loss=0.116381 error=0.073171\n",
      "downhill: validation 188 loss=0.116234 error=0.073038 *\n",
      "downhill: Adam 1881 loss=0.116234 error=0.073038\n",
      "downhill: Adam 1882 loss=0.116087 error=0.072905\n",
      "downhill: Adam 1883 loss=0.115940 error=0.072772\n",
      "downhill: Adam 1884 loss=0.115793 error=0.072640\n",
      "downhill: Adam 1885 loss=0.115647 error=0.072508\n",
      "downhill: Adam 1886 loss=0.115501 error=0.072376\n",
      "downhill: Adam 1887 loss=0.115355 error=0.072244\n",
      "downhill: Adam 1888 loss=0.115209 error=0.072113\n",
      "downhill: Adam 1889 loss=0.115064 error=0.071982\n",
      "downhill: Adam 1890 loss=0.114919 error=0.071851\n",
      "downhill: validation 189 loss=0.114775 error=0.071721 *\n",
      "downhill: Adam 1891 loss=0.114775 error=0.071721\n",
      "downhill: Adam 1892 loss=0.114630 error=0.071591\n",
      "downhill: Adam 1893 loss=0.114486 error=0.071461\n",
      "downhill: Adam 1894 loss=0.114343 error=0.071332\n",
      "downhill: Adam 1895 loss=0.114199 error=0.071202\n",
      "downhill: Adam 1896 loss=0.114056 error=0.071073\n",
      "downhill: Adam 1897 loss=0.113913 error=0.070945\n",
      "downhill: Adam 1898 loss=0.113771 error=0.070816\n",
      "downhill: Adam 1899 loss=0.113628 error=0.070688\n",
      "downhill: Adam 1900 loss=0.113486 error=0.070560\n",
      "downhill: validation 190 loss=0.113344 error=0.070433 *\n",
      "downhill: Adam 1901 loss=0.113344 error=0.070433\n",
      "downhill: Adam 1902 loss=0.113203 error=0.070305\n",
      "downhill: Adam 1903 loss=0.113062 error=0.070178\n",
      "downhill: Adam 1904 loss=0.112921 error=0.070051\n",
      "downhill: Adam 1905 loss=0.112780 error=0.069925\n",
      "downhill: Adam 1906 loss=0.112640 error=0.069799\n",
      "downhill: Adam 1907 loss=0.112500 error=0.069673\n",
      "downhill: Adam 1908 loss=0.112360 error=0.069547\n",
      "downhill: Adam 1909 loss=0.112220 error=0.069422\n",
      "downhill: Adam 1910 loss=0.112081 error=0.069296\n",
      "downhill: validation 191 loss=0.111942 error=0.069172 *\n",
      "downhill: Adam 1911 loss=0.111942 error=0.069172\n",
      "downhill: Adam 1912 loss=0.111804 error=0.069047\n",
      "downhill: Adam 1913 loss=0.111665 error=0.068923\n",
      "downhill: Adam 1914 loss=0.111527 error=0.068799\n",
      "downhill: Adam 1915 loss=0.111389 error=0.068675\n",
      "downhill: Adam 1916 loss=0.111251 error=0.068551\n",
      "downhill: Adam 1917 loss=0.111114 error=0.068428\n",
      "downhill: Adam 1918 loss=0.110977 error=0.068305\n",
      "downhill: Adam 1919 loss=0.110840 error=0.068182\n",
      "downhill: Adam 1920 loss=0.110704 error=0.068060\n",
      "downhill: validation 192 loss=0.110568 error=0.067938 *\n",
      "downhill: Adam 1921 loss=0.110568 error=0.067938\n",
      "downhill: Adam 1922 loss=0.110432 error=0.067816\n",
      "downhill: Adam 1923 loss=0.110296 error=0.067694\n",
      "downhill: Adam 1924 loss=0.110160 error=0.067573\n",
      "downhill: Adam 1925 loss=0.110025 error=0.067451\n",
      "downhill: Adam 1926 loss=0.109890 error=0.067330\n",
      "downhill: Adam 1927 loss=0.109756 error=0.067210\n",
      "downhill: Adam 1928 loss=0.109621 error=0.067089\n",
      "downhill: Adam 1929 loss=0.109487 error=0.066969\n",
      "downhill: Adam 1930 loss=0.109353 error=0.066849\n",
      "downhill: validation 193 loss=0.109220 error=0.066730 *\n",
      "downhill: Adam 1931 loss=0.109220 error=0.066730\n",
      "downhill: Adam 1932 loss=0.109087 error=0.066610\n",
      "downhill: Adam 1933 loss=0.108954 error=0.066491\n",
      "downhill: Adam 1934 loss=0.108821 error=0.066372\n",
      "downhill: Adam 1935 loss=0.108688 error=0.066254\n",
      "downhill: Adam 1936 loss=0.108556 error=0.066135\n",
      "downhill: Adam 1937 loss=0.108424 error=0.066017\n",
      "downhill: Adam 1938 loss=0.108292 error=0.065900\n",
      "downhill: Adam 1939 loss=0.108161 error=0.065782\n",
      "downhill: Adam 1940 loss=0.108029 error=0.065665\n",
      "downhill: validation 194 loss=0.107898 error=0.065547 *\n",
      "downhill: Adam 1941 loss=0.107898 error=0.065547\n",
      "downhill: Adam 1942 loss=0.107768 error=0.065431\n",
      "downhill: Adam 1943 loss=0.107637 error=0.065314\n",
      "downhill: Adam 1944 loss=0.107507 error=0.065198\n",
      "downhill: Adam 1945 loss=0.107377 error=0.065081\n",
      "downhill: Adam 1946 loss=0.107247 error=0.064966\n",
      "downhill: Adam 1947 loss=0.107118 error=0.064850\n",
      "downhill: Adam 1948 loss=0.106988 error=0.064735\n",
      "downhill: Adam 1949 loss=0.106859 error=0.064620\n",
      "downhill: Adam 1950 loss=0.106730 error=0.064505\n",
      "downhill: validation 195 loss=0.106602 error=0.064390 *\n",
      "downhill: Adam 1951 loss=0.106602 error=0.064390\n",
      "downhill: Adam 1952 loss=0.106474 error=0.064276\n",
      "downhill: Adam 1953 loss=0.106346 error=0.064161\n",
      "downhill: Adam 1954 loss=0.106218 error=0.064047\n",
      "downhill: Adam 1955 loss=0.106091 error=0.063934\n",
      "downhill: Adam 1956 loss=0.105963 error=0.063820\n",
      "downhill: Adam 1957 loss=0.105836 error=0.063707\n",
      "downhill: Adam 1958 loss=0.105710 error=0.063594\n",
      "downhill: Adam 1959 loss=0.105583 error=0.063481\n",
      "downhill: Adam 1960 loss=0.105457 error=0.063369\n",
      "downhill: validation 196 loss=0.105331 error=0.063257 *\n",
      "downhill: Adam 1961 loss=0.105331 error=0.063257\n",
      "downhill: Adam 1962 loss=0.105205 error=0.063144\n",
      "downhill: Adam 1963 loss=0.105079 error=0.063033\n",
      "downhill: Adam 1964 loss=0.104954 error=0.062921\n",
      "downhill: Adam 1965 loss=0.104829 error=0.062810\n",
      "downhill: Adam 1966 loss=0.104704 error=0.062699\n",
      "downhill: Adam 1967 loss=0.104580 error=0.062588\n",
      "downhill: Adam 1968 loss=0.104455 error=0.062477\n",
      "downhill: Adam 1969 loss=0.104331 error=0.062367\n",
      "downhill: Adam 1970 loss=0.104208 error=0.062256\n",
      "downhill: validation 197 loss=0.104084 error=0.062146 *\n",
      "downhill: Adam 1971 loss=0.104084 error=0.062146\n",
      "downhill: Adam 1972 loss=0.103961 error=0.062037\n",
      "downhill: Adam 1973 loss=0.103838 error=0.061927\n",
      "downhill: Adam 1974 loss=0.103715 error=0.061818\n",
      "downhill: Adam 1975 loss=0.103592 error=0.061709\n",
      "downhill: Adam 1976 loss=0.103470 error=0.061600\n",
      "downhill: Adam 1977 loss=0.103348 error=0.061491\n",
      "downhill: Adam 1978 loss=0.103226 error=0.061383\n",
      "downhill: Adam 1979 loss=0.103104 error=0.061275\n",
      "downhill: Adam 1980 loss=0.102983 error=0.061167\n",
      "downhill: validation 198 loss=0.102861 error=0.061059 *\n",
      "downhill: Adam 1981 loss=0.102861 error=0.061059\n",
      "downhill: Adam 1982 loss=0.102740 error=0.060952\n",
      "downhill: Adam 1983 loss=0.102620 error=0.060844\n",
      "downhill: Adam 1984 loss=0.102499 error=0.060737\n",
      "downhill: Adam 1985 loss=0.102379 error=0.060630\n",
      "downhill: Adam 1986 loss=0.102259 error=0.060524\n",
      "downhill: Adam 1987 loss=0.102139 error=0.060417\n",
      "downhill: Adam 1988 loss=0.102019 error=0.060311\n",
      "downhill: Adam 1989 loss=0.101900 error=0.060205\n",
      "downhill: Adam 1990 loss=0.101781 error=0.060099\n",
      "downhill: validation 199 loss=0.101662 error=0.059994 *\n",
      "downhill: Adam 1991 loss=0.101662 error=0.059994\n",
      "downhill: Adam 1992 loss=0.101543 error=0.059889\n",
      "downhill: Adam 1993 loss=0.101425 error=0.059783\n",
      "downhill: Adam 1994 loss=0.101306 error=0.059679\n",
      "downhill: Adam 1995 loss=0.101188 error=0.059574\n",
      "downhill: Adam 1996 loss=0.101071 error=0.059469\n",
      "downhill: Adam 1997 loss=0.100953 error=0.059365\n",
      "downhill: Adam 1998 loss=0.100836 error=0.059261\n",
      "downhill: Adam 1999 loss=0.100719 error=0.059157\n",
      "downhill: Adam 2000 loss=0.100602 error=0.059053\n",
      "downhill: validation 200 loss=0.100485 error=0.058950 *\n",
      "downhill: Adam 2001 loss=0.100485 error=0.058950\n",
      "downhill: Adam 2002 loss=0.100369 error=0.058847\n",
      "downhill: Adam 2003 loss=0.100252 error=0.058744\n",
      "downhill: Adam 2004 loss=0.100136 error=0.058641\n",
      "downhill: Adam 2005 loss=0.100020 error=0.058538\n",
      "downhill: Adam 2006 loss=0.099905 error=0.058436\n",
      "downhill: Adam 2007 loss=0.099789 error=0.058334\n",
      "downhill: Adam 2008 loss=0.099674 error=0.058232\n",
      "downhill: Adam 2009 loss=0.099559 error=0.058130\n",
      "downhill: Adam 2010 loss=0.099445 error=0.058029\n",
      "downhill: validation 201 loss=0.099330 error=0.057927 *\n",
      "downhill: Adam 2011 loss=0.099330 error=0.057927\n",
      "downhill: Adam 2012 loss=0.099216 error=0.057826\n",
      "downhill: Adam 2013 loss=0.099102 error=0.057725\n",
      "downhill: Adam 2014 loss=0.098988 error=0.057624\n",
      "downhill: Adam 2015 loss=0.098874 error=0.057524\n",
      "downhill: Adam 2016 loss=0.098761 error=0.057423\n",
      "downhill: Adam 2017 loss=0.098648 error=0.057323\n",
      "downhill: Adam 2018 loss=0.098535 error=0.057223\n",
      "downhill: Adam 2019 loss=0.098422 error=0.057123\n",
      "downhill: Adam 2020 loss=0.098309 error=0.057024\n",
      "downhill: validation 202 loss=0.098197 error=0.056925 *\n",
      "downhill: Adam 2021 loss=0.098197 error=0.056925\n",
      "downhill: Adam 2022 loss=0.098085 error=0.056825\n",
      "downhill: Adam 2023 loss=0.097973 error=0.056726\n",
      "downhill: Adam 2024 loss=0.097861 error=0.056628\n",
      "downhill: Adam 2025 loss=0.097750 error=0.056529\n",
      "downhill: Adam 2026 loss=0.097638 error=0.056431\n",
      "downhill: Adam 2027 loss=0.097527 error=0.056333\n",
      "downhill: Adam 2028 loss=0.097416 error=0.056235\n",
      "downhill: Adam 2029 loss=0.097305 error=0.056137\n",
      "downhill: Adam 2030 loss=0.097195 error=0.056039\n",
      "downhill: validation 203 loss=0.097085 error=0.055942 *\n",
      "downhill: Adam 2031 loss=0.097085 error=0.055942\n",
      "downhill: Adam 2032 loss=0.096975 error=0.055844\n",
      "downhill: Adam 2033 loss=0.096865 error=0.055748\n",
      "downhill: Adam 2034 loss=0.096755 error=0.055651\n",
      "downhill: Adam 2035 loss=0.096645 error=0.055554\n",
      "downhill: Adam 2036 loss=0.096536 error=0.055457\n",
      "downhill: Adam 2037 loss=0.096427 error=0.055361\n",
      "downhill: Adam 2038 loss=0.096318 error=0.055265\n",
      "downhill: Adam 2039 loss=0.096209 error=0.055169\n",
      "downhill: Adam 2040 loss=0.096101 error=0.055073\n",
      "downhill: validation 204 loss=0.095993 error=0.054978 *\n",
      "downhill: Adam 2041 loss=0.095993 error=0.054978\n",
      "downhill: Adam 2042 loss=0.095884 error=0.054883\n",
      "downhill: Adam 2043 loss=0.095777 error=0.054787\n",
      "downhill: Adam 2044 loss=0.095669 error=0.054692\n",
      "downhill: Adam 2045 loss=0.095561 error=0.054598\n",
      "downhill: Adam 2046 loss=0.095454 error=0.054503\n",
      "downhill: Adam 2047 loss=0.095347 error=0.054409\n",
      "downhill: Adam 2048 loss=0.095240 error=0.054314\n",
      "downhill: Adam 2049 loss=0.095133 error=0.054220\n",
      "downhill: Adam 2050 loss=0.095027 error=0.054126\n",
      "downhill: validation 205 loss=0.094920 error=0.054032 *\n",
      "downhill: Adam 2051 loss=0.094920 error=0.054032\n",
      "downhill: Adam 2052 loss=0.094814 error=0.053939\n",
      "downhill: Adam 2053 loss=0.094708 error=0.053846\n",
      "downhill: Adam 2054 loss=0.094602 error=0.053752\n",
      "downhill: Adam 2055 loss=0.094497 error=0.053659\n",
      "downhill: Adam 2056 loss=0.094391 error=0.053567\n",
      "downhill: Adam 2057 loss=0.094286 error=0.053474\n",
      "downhill: Adam 2058 loss=0.094181 error=0.053381\n",
      "downhill: Adam 2059 loss=0.094076 error=0.053289\n",
      "downhill: Adam 2060 loss=0.093972 error=0.053197\n",
      "downhill: validation 206 loss=0.093867 error=0.053105 *\n",
      "downhill: Adam 2061 loss=0.093867 error=0.053105\n",
      "downhill: Adam 2062 loss=0.093763 error=0.053013\n",
      "downhill: Adam 2063 loss=0.093659 error=0.052921\n",
      "downhill: Adam 2064 loss=0.093555 error=0.052830\n",
      "downhill: Adam 2065 loss=0.093451 error=0.052739\n",
      "downhill: Adam 2066 loss=0.093348 error=0.052648\n",
      "downhill: Adam 2067 loss=0.093244 error=0.052557\n",
      "downhill: Adam 2068 loss=0.093141 error=0.052466\n",
      "downhill: Adam 2069 loss=0.093038 error=0.052375\n",
      "downhill: Adam 2070 loss=0.092935 error=0.052285\n",
      "downhill: validation 207 loss=0.092833 error=0.052195 *\n",
      "downhill: Adam 2071 loss=0.092833 error=0.052195\n",
      "downhill: Adam 2072 loss=0.092730 error=0.052105\n",
      "downhill: Adam 2073 loss=0.092628 error=0.052015\n",
      "downhill: Adam 2074 loss=0.092526 error=0.051925\n",
      "downhill: Adam 2075 loss=0.092424 error=0.051835\n",
      "downhill: Adam 2076 loss=0.092322 error=0.051746\n",
      "downhill: Adam 2077 loss=0.092221 error=0.051657\n",
      "downhill: Adam 2078 loss=0.092119 error=0.051567\n",
      "downhill: Adam 2079 loss=0.092018 error=0.051479\n",
      "downhill: Adam 2080 loss=0.091917 error=0.051390\n",
      "downhill: validation 208 loss=0.091816 error=0.051301 *\n",
      "downhill: Adam 2081 loss=0.091816 error=0.051301\n",
      "downhill: Adam 2082 loss=0.091715 error=0.051213\n",
      "downhill: Adam 2083 loss=0.091615 error=0.051124\n",
      "downhill: Adam 2084 loss=0.091514 error=0.051036\n",
      "downhill: Adam 2085 loss=0.091414 error=0.050948\n",
      "downhill: Adam 2086 loss=0.091314 error=0.050860\n",
      "downhill: Adam 2087 loss=0.091214 error=0.050773\n",
      "downhill: Adam 2088 loss=0.091115 error=0.050685\n",
      "downhill: Adam 2089 loss=0.091015 error=0.050598\n",
      "downhill: Adam 2090 loss=0.090916 error=0.050511\n",
      "downhill: validation 209 loss=0.090817 error=0.050424 *\n",
      "downhill: Adam 2091 loss=0.090817 error=0.050424\n",
      "downhill: Adam 2092 loss=0.090718 error=0.050337\n",
      "downhill: Adam 2093 loss=0.090619 error=0.050250\n",
      "downhill: Adam 2094 loss=0.090520 error=0.050163\n",
      "downhill: Adam 2095 loss=0.090422 error=0.050077\n",
      "downhill: Adam 2096 loss=0.090323 error=0.049991\n",
      "downhill: Adam 2097 loss=0.090225 error=0.049904\n",
      "downhill: Adam 2098 loss=0.090127 error=0.049818\n",
      "downhill: Adam 2099 loss=0.090029 error=0.049733\n",
      "downhill: Adam 2100 loss=0.089931 error=0.049647\n",
      "downhill: validation 210 loss=0.089834 error=0.049561 *\n",
      "downhill: Adam 2101 loss=0.089834 error=0.049561\n",
      "downhill: Adam 2102 loss=0.089737 error=0.049476\n",
      "downhill: Adam 2103 loss=0.089639 error=0.049391\n",
      "downhill: Adam 2104 loss=0.089542 error=0.049306\n",
      "downhill: Adam 2105 loss=0.089446 error=0.049221\n",
      "downhill: Adam 2106 loss=0.089349 error=0.049136\n",
      "downhill: Adam 2107 loss=0.089252 error=0.049051\n",
      "downhill: Adam 2108 loss=0.089156 error=0.048967\n",
      "downhill: Adam 2109 loss=0.089060 error=0.048882\n",
      "downhill: Adam 2110 loss=0.088964 error=0.048798\n",
      "downhill: validation 211 loss=0.088868 error=0.048714 *\n",
      "downhill: Adam 2111 loss=0.088868 error=0.048714\n",
      "downhill: Adam 2112 loss=0.088772 error=0.048630\n",
      "downhill: Adam 2113 loss=0.088676 error=0.048546\n",
      "downhill: Adam 2114 loss=0.088581 error=0.048462\n",
      "downhill: Adam 2115 loss=0.088485 error=0.048379\n",
      "downhill: Adam 2116 loss=0.088390 error=0.048295\n",
      "downhill: Adam 2117 loss=0.088295 error=0.048212\n",
      "downhill: Adam 2118 loss=0.088200 error=0.048129\n",
      "downhill: Adam 2119 loss=0.088106 error=0.048046\n",
      "downhill: Adam 2120 loss=0.088011 error=0.047963\n",
      "downhill: validation 212 loss=0.087917 error=0.047880 *\n",
      "downhill: Adam 2121 loss=0.087917 error=0.047880\n",
      "downhill: Adam 2122 loss=0.087822 error=0.047798\n",
      "downhill: Adam 2123 loss=0.087728 error=0.047715\n",
      "downhill: Adam 2124 loss=0.087634 error=0.047633\n",
      "downhill: Adam 2125 loss=0.087541 error=0.047551\n",
      "downhill: Adam 2126 loss=0.087447 error=0.047469\n",
      "downhill: Adam 2127 loss=0.087353 error=0.047387\n",
      "downhill: Adam 2128 loss=0.087260 error=0.047305\n",
      "downhill: Adam 2129 loss=0.087167 error=0.047223\n",
      "downhill: Adam 2130 loss=0.087074 error=0.047142\n",
      "downhill: validation 213 loss=0.086981 error=0.047061 *\n",
      "downhill: Adam 2131 loss=0.086981 error=0.047061\n",
      "downhill: Adam 2132 loss=0.086888 error=0.046979\n",
      "downhill: Adam 2133 loss=0.086795 error=0.046898\n",
      "downhill: Adam 2134 loss=0.086703 error=0.046817\n",
      "downhill: Adam 2135 loss=0.086610 error=0.046736\n",
      "downhill: Adam 2136 loss=0.086518 error=0.046655\n",
      "downhill: Adam 2137 loss=0.086426 error=0.046575\n",
      "downhill: Adam 2138 loss=0.086334 error=0.046494\n",
      "downhill: Adam 2139 loss=0.086242 error=0.046414\n",
      "downhill: Adam 2140 loss=0.086151 error=0.046334\n",
      "downhill: validation 214 loss=0.086059 error=0.046254 *\n",
      "downhill: Adam 2141 loss=0.086059 error=0.046254\n",
      "downhill: Adam 2142 loss=0.085968 error=0.046174\n",
      "downhill: Adam 2143 loss=0.085877 error=0.046094\n",
      "downhill: Adam 2144 loss=0.085786 error=0.046014\n",
      "downhill: Adam 2145 loss=0.085695 error=0.045934\n",
      "downhill: Adam 2146 loss=0.085604 error=0.045855\n",
      "downhill: Adam 2147 loss=0.085513 error=0.045775\n",
      "downhill: Adam 2148 loss=0.085422 error=0.045696\n",
      "downhill: Adam 2149 loss=0.085332 error=0.045617\n",
      "downhill: Adam 2150 loss=0.085242 error=0.045538\n",
      "downhill: validation 215 loss=0.085152 error=0.045459 *\n",
      "downhill: Adam 2151 loss=0.085152 error=0.045459\n",
      "downhill: Adam 2152 loss=0.085062 error=0.045380\n",
      "downhill: Adam 2153 loss=0.084972 error=0.045302\n",
      "downhill: Adam 2154 loss=0.084882 error=0.045223\n",
      "downhill: Adam 2155 loss=0.084792 error=0.045144\n",
      "downhill: Adam 2156 loss=0.084703 error=0.045066\n",
      "downhill: Adam 2157 loss=0.084613 error=0.044988\n",
      "downhill: Adam 2158 loss=0.084524 error=0.044910\n",
      "downhill: Adam 2159 loss=0.084435 error=0.044832\n",
      "downhill: Adam 2160 loss=0.084346 error=0.044754\n",
      "downhill: validation 216 loss=0.084257 error=0.044676 *\n",
      "downhill: Adam 2161 loss=0.084257 error=0.044676\n",
      "downhill: Adam 2162 loss=0.084168 error=0.044599\n",
      "downhill: Adam 2163 loss=0.084080 error=0.044521\n",
      "downhill: Adam 2164 loss=0.083991 error=0.044444\n",
      "downhill: Adam 2165 loss=0.083903 error=0.044366\n",
      "downhill: Adam 2166 loss=0.083815 error=0.044289\n",
      "downhill: Adam 2167 loss=0.083727 error=0.044212\n",
      "downhill: Adam 2168 loss=0.083639 error=0.044135\n",
      "downhill: Adam 2169 loss=0.083551 error=0.044058\n",
      "downhill: Adam 2170 loss=0.083463 error=0.043981\n",
      "downhill: validation 217 loss=0.083376 error=0.043905 *\n",
      "downhill: Adam 2171 loss=0.083376 error=0.043905\n",
      "downhill: Adam 2172 loss=0.083288 error=0.043828\n",
      "downhill: Adam 2173 loss=0.083201 error=0.043752\n",
      "downhill: Adam 2174 loss=0.083114 error=0.043675\n",
      "downhill: Adam 2175 loss=0.083027 error=0.043599\n",
      "downhill: Adam 2176 loss=0.082940 error=0.043523\n",
      "downhill: Adam 2177 loss=0.082853 error=0.043447\n",
      "downhill: Adam 2178 loss=0.082766 error=0.043371\n",
      "downhill: Adam 2179 loss=0.082679 error=0.043295\n",
      "downhill: Adam 2180 loss=0.082593 error=0.043219\n",
      "downhill: validation 218 loss=0.082507 error=0.043143 *\n",
      "downhill: Adam 2181 loss=0.082507 error=0.043143\n",
      "downhill: Adam 2182 loss=0.082420 error=0.043068\n",
      "downhill: Adam 2183 loss=0.082334 error=0.042993\n",
      "downhill: Adam 2184 loss=0.082248 error=0.042917\n",
      "downhill: Adam 2185 loss=0.082162 error=0.042842\n",
      "downhill: Adam 2186 loss=0.082077 error=0.042767\n",
      "downhill: Adam 2187 loss=0.081991 error=0.042692\n",
      "downhill: Adam 2188 loss=0.081905 error=0.042617\n",
      "downhill: Adam 2189 loss=0.081820 error=0.042542\n",
      "downhill: Adam 2190 loss=0.081735 error=0.042467\n",
      "downhill: validation 219 loss=0.081650 error=0.042393 *\n",
      "downhill: Adam 2191 loss=0.081650 error=0.042393\n",
      "downhill: Adam 2192 loss=0.081564 error=0.042318\n",
      "downhill: Adam 2193 loss=0.081480 error=0.042244\n",
      "downhill: Adam 2194 loss=0.081395 error=0.042169\n",
      "downhill: Adam 2195 loss=0.081310 error=0.042095\n",
      "downhill: Adam 2196 loss=0.081225 error=0.042021\n",
      "downhill: Adam 2197 loss=0.081141 error=0.041947\n",
      "downhill: Adam 2198 loss=0.081057 error=0.041873\n",
      "downhill: Adam 2199 loss=0.080972 error=0.041799\n",
      "downhill: Adam 2200 loss=0.080888 error=0.041725\n",
      "downhill: validation 220 loss=0.080804 error=0.041652 *\n",
      "downhill: Adam 2201 loss=0.080804 error=0.041652\n",
      "downhill: Adam 2202 loss=0.080720 error=0.041578\n",
      "downhill: Adam 2203 loss=0.080637 error=0.041505\n",
      "downhill: Adam 2204 loss=0.080553 error=0.041431\n",
      "downhill: Adam 2205 loss=0.080469 error=0.041358\n",
      "downhill: Adam 2206 loss=0.080386 error=0.041285\n",
      "downhill: Adam 2207 loss=0.080302 error=0.041212\n",
      "downhill: Adam 2208 loss=0.080219 error=0.041139\n",
      "downhill: Adam 2209 loss=0.080136 error=0.041066\n",
      "downhill: Adam 2210 loss=0.080053 error=0.040993\n",
      "downhill: validation 221 loss=0.079970 error=0.040920 *\n",
      "downhill: Adam 2211 loss=0.079970 error=0.040920\n",
      "downhill: Adam 2212 loss=0.079887 error=0.040848\n",
      "downhill: Adam 2213 loss=0.079805 error=0.040775\n",
      "downhill: Adam 2214 loss=0.079722 error=0.040703\n",
      "downhill: Adam 2215 loss=0.079639 error=0.040630\n",
      "downhill: Adam 2216 loss=0.079557 error=0.040558\n",
      "downhill: Adam 2217 loss=0.079475 error=0.040486\n",
      "downhill: Adam 2218 loss=0.079393 error=0.040414\n",
      "downhill: Adam 2219 loss=0.079311 error=0.040342\n",
      "downhill: Adam 2220 loss=0.079229 error=0.040270\n",
      "downhill: validation 222 loss=0.079147 error=0.040198 *\n",
      "downhill: Adam 2221 loss=0.079147 error=0.040198\n",
      "downhill: Adam 2222 loss=0.079065 error=0.040126\n",
      "downhill: Adam 2223 loss=0.078983 error=0.040055\n",
      "downhill: Adam 2224 loss=0.078902 error=0.039983\n",
      "downhill: Adam 2225 loss=0.078820 error=0.039912\n",
      "downhill: Adam 2226 loss=0.078739 error=0.039840\n",
      "downhill: Adam 2227 loss=0.078658 error=0.039769\n",
      "downhill: Adam 2228 loss=0.078577 error=0.039697\n",
      "downhill: Adam 2229 loss=0.078496 error=0.039626\n",
      "downhill: Adam 2230 loss=0.078415 error=0.039555\n",
      "downhill: validation 223 loss=0.078334 error=0.039484 *\n",
      "downhill: Adam 2231 loss=0.078334 error=0.039484\n",
      "downhill: Adam 2232 loss=0.078253 error=0.039413\n",
      "downhill: Adam 2233 loss=0.078172 error=0.039342\n",
      "downhill: Adam 2234 loss=0.078092 error=0.039272\n",
      "downhill: Adam 2235 loss=0.078011 error=0.039201\n",
      "downhill: Adam 2236 loss=0.077931 error=0.039130\n",
      "downhill: Adam 2237 loss=0.077851 error=0.039060\n",
      "downhill: Adam 2238 loss=0.077771 error=0.038990\n",
      "downhill: Adam 2239 loss=0.077690 error=0.038919\n",
      "downhill: Adam 2240 loss=0.077610 error=0.038849\n",
      "downhill: validation 224 loss=0.077531 error=0.038779 *\n",
      "downhill: Adam 2241 loss=0.077531 error=0.038779\n",
      "downhill: Adam 2242 loss=0.077451 error=0.038709\n",
      "downhill: Adam 2243 loss=0.077371 error=0.038639\n",
      "downhill: Adam 2244 loss=0.077291 error=0.038569\n",
      "downhill: Adam 2245 loss=0.077212 error=0.038499\n",
      "downhill: Adam 2246 loss=0.077133 error=0.038429\n",
      "downhill: Adam 2247 loss=0.077053 error=0.038359\n",
      "downhill: Adam 2248 loss=0.076974 error=0.038290\n",
      "downhill: Adam 2249 loss=0.076895 error=0.038220\n",
      "downhill: Adam 2250 loss=0.076816 error=0.038151\n",
      "downhill: validation 225 loss=0.076737 error=0.038081 *\n",
      "downhill: Adam 2251 loss=0.076737 error=0.038081\n",
      "downhill: Adam 2252 loss=0.076658 error=0.038012\n",
      "downhill: Adam 2253 loss=0.076579 error=0.037943\n",
      "downhill: Adam 2254 loss=0.076501 error=0.037874\n",
      "downhill: Adam 2255 loss=0.076422 error=0.037805\n",
      "downhill: Adam 2256 loss=0.076343 error=0.037736\n",
      "downhill: Adam 2257 loss=0.076265 error=0.037667\n",
      "downhill: Adam 2258 loss=0.076187 error=0.037598\n",
      "downhill: Adam 2259 loss=0.076109 error=0.037529\n",
      "downhill: Adam 2260 loss=0.076030 error=0.037460\n",
      "downhill: validation 226 loss=0.075952 error=0.037392 *\n",
      "downhill: Adam 2261 loss=0.075952 error=0.037392\n",
      "downhill: Adam 2262 loss=0.075875 error=0.037323\n",
      "downhill: Adam 2263 loss=0.075797 error=0.037255\n",
      "downhill: Adam 2264 loss=0.075719 error=0.037186\n",
      "downhill: Adam 2265 loss=0.075641 error=0.037118\n",
      "downhill: Adam 2266 loss=0.075564 error=0.037050\n",
      "downhill: Adam 2267 loss=0.075486 error=0.036982\n",
      "downhill: Adam 2268 loss=0.075409 error=0.036913\n",
      "downhill: Adam 2269 loss=0.075332 error=0.036845\n",
      "downhill: Adam 2270 loss=0.075255 error=0.036777\n",
      "downhill: validation 227 loss=0.075177 error=0.036710 *\n",
      "downhill: Adam 2271 loss=0.075177 error=0.036710\n",
      "downhill: Adam 2272 loss=0.075100 error=0.036642\n",
      "downhill: Adam 2273 loss=0.075024 error=0.036574\n",
      "downhill: Adam 2274 loss=0.074947 error=0.036506\n",
      "downhill: Adam 2275 loss=0.074870 error=0.036439\n",
      "downhill: Adam 2276 loss=0.074793 error=0.036371\n",
      "downhill: Adam 2277 loss=0.074717 error=0.036304\n",
      "downhill: Adam 2278 loss=0.074640 error=0.036236\n",
      "downhill: Adam 2279 loss=0.074564 error=0.036169\n",
      "downhill: Adam 2280 loss=0.074488 error=0.036102\n",
      "downhill: validation 228 loss=0.074412 error=0.036035 *\n",
      "downhill: Adam 2281 loss=0.074412 error=0.036035\n",
      "downhill: Adam 2282 loss=0.074336 error=0.035968\n",
      "downhill: Adam 2283 loss=0.074260 error=0.035901\n",
      "downhill: Adam 2284 loss=0.074184 error=0.035834\n",
      "downhill: Adam 2285 loss=0.074108 error=0.035767\n",
      "downhill: Adam 2286 loss=0.074032 error=0.035700\n",
      "downhill: Adam 2287 loss=0.073957 error=0.035634\n",
      "downhill: Adam 2288 loss=0.073881 error=0.035567\n",
      "downhill: Adam 2289 loss=0.073806 error=0.035501\n",
      "downhill: Adam 2290 loss=0.073730 error=0.035434\n",
      "downhill: validation 229 loss=0.073655 error=0.035368 *\n",
      "downhill: Adam 2291 loss=0.073655 error=0.035368\n",
      "downhill: Adam 2292 loss=0.073580 error=0.035302\n",
      "downhill: Adam 2293 loss=0.073505 error=0.035235\n",
      "downhill: Adam 2294 loss=0.073430 error=0.035169\n",
      "downhill: Adam 2295 loss=0.073355 error=0.035103\n",
      "downhill: Adam 2296 loss=0.073280 error=0.035037\n",
      "downhill: Adam 2297 loss=0.073205 error=0.034971\n",
      "downhill: Adam 2298 loss=0.073131 error=0.034905\n",
      "downhill: Adam 2299 loss=0.073056 error=0.034840\n",
      "downhill: Adam 2300 loss=0.072982 error=0.034774\n",
      "downhill: validation 230 loss=0.072907 error=0.034708 *\n",
      "downhill: Adam 2301 loss=0.072907 error=0.034708\n",
      "downhill: Adam 2302 loss=0.072833 error=0.034643\n",
      "downhill: Adam 2303 loss=0.072759 error=0.034577\n",
      "downhill: Adam 2304 loss=0.072685 error=0.034512\n",
      "downhill: Adam 2305 loss=0.072611 error=0.034447\n",
      "downhill: Adam 2306 loss=0.072537 error=0.034382\n",
      "downhill: Adam 2307 loss=0.072463 error=0.034316\n",
      "downhill: Adam 2308 loss=0.072389 error=0.034251\n",
      "downhill: Adam 2309 loss=0.072316 error=0.034186\n",
      "downhill: Adam 2310 loss=0.072242 error=0.034122\n",
      "downhill: validation 231 loss=0.072169 error=0.034057 *\n",
      "downhill: Adam 2311 loss=0.072169 error=0.034057\n",
      "downhill: Adam 2312 loss=0.072095 error=0.033992\n",
      "downhill: Adam 2313 loss=0.072022 error=0.033927\n",
      "downhill: Adam 2314 loss=0.071949 error=0.033863\n",
      "downhill: Adam 2315 loss=0.071876 error=0.033798\n",
      "downhill: Adam 2316 loss=0.071803 error=0.033734\n",
      "downhill: Adam 2317 loss=0.071730 error=0.033670\n",
      "downhill: Adam 2318 loss=0.071657 error=0.033605\n",
      "downhill: Adam 2319 loss=0.071584 error=0.033541\n",
      "downhill: Adam 2320 loss=0.071512 error=0.033477\n",
      "downhill: validation 232 loss=0.071439 error=0.033413 *\n",
      "downhill: Adam 2321 loss=0.071439 error=0.033413\n",
      "downhill: Adam 2322 loss=0.071367 error=0.033349\n",
      "downhill: Adam 2323 loss=0.071294 error=0.033285\n",
      "downhill: Adam 2324 loss=0.071222 error=0.033221\n",
      "downhill: Adam 2325 loss=0.071150 error=0.033158\n",
      "downhill: Adam 2326 loss=0.071078 error=0.033094\n",
      "downhill: Adam 2327 loss=0.071005 error=0.033031\n",
      "downhill: Adam 2328 loss=0.070934 error=0.032967\n",
      "downhill: Adam 2329 loss=0.070862 error=0.032904\n",
      "downhill: Adam 2330 loss=0.070790 error=0.032840\n",
      "downhill: validation 233 loss=0.070718 error=0.032777 *\n",
      "downhill: Adam 2331 loss=0.070718 error=0.032777\n",
      "downhill: Adam 2332 loss=0.070647 error=0.032714\n",
      "downhill: Adam 2333 loss=0.070575 error=0.032651\n",
      "downhill: Adam 2334 loss=0.070504 error=0.032588\n",
      "downhill: Adam 2335 loss=0.070433 error=0.032525\n",
      "downhill: Adam 2336 loss=0.070361 error=0.032462\n",
      "downhill: Adam 2337 loss=0.070290 error=0.032400\n",
      "downhill: Adam 2338 loss=0.070219 error=0.032337\n",
      "downhill: Adam 2339 loss=0.070148 error=0.032275\n",
      "downhill: Adam 2340 loss=0.070078 error=0.032212\n",
      "downhill: validation 234 loss=0.070007 error=0.032150 *\n",
      "downhill: Adam 2341 loss=0.070007 error=0.032150\n",
      "downhill: Adam 2342 loss=0.069936 error=0.032087\n",
      "downhill: Adam 2343 loss=0.069866 error=0.032025\n",
      "downhill: Adam 2344 loss=0.069795 error=0.031963\n",
      "downhill: Adam 2345 loss=0.069725 error=0.031901\n",
      "downhill: Adam 2346 loss=0.069655 error=0.031839\n",
      "downhill: Adam 2347 loss=0.069584 error=0.031778\n",
      "downhill: Adam 2348 loss=0.069514 error=0.031716\n",
      "downhill: Adam 2349 loss=0.069444 error=0.031654\n",
      "downhill: Adam 2350 loss=0.069375 error=0.031592\n",
      "downhill: validation 235 loss=0.069305 error=0.031531 *\n",
      "downhill: Adam 2351 loss=0.069305 error=0.031531\n",
      "downhill: Adam 2352 loss=0.069235 error=0.031469\n",
      "downhill: Adam 2353 loss=0.069165 error=0.031408\n",
      "downhill: Adam 2354 loss=0.069096 error=0.031347\n",
      "downhill: Adam 2355 loss=0.069026 error=0.031286\n",
      "downhill: Adam 2356 loss=0.068957 error=0.031225\n",
      "downhill: Adam 2357 loss=0.068888 error=0.031164\n",
      "downhill: Adam 2358 loss=0.068819 error=0.031103\n",
      "downhill: Adam 2359 loss=0.068750 error=0.031042\n",
      "downhill: Adam 2360 loss=0.068681 error=0.030981\n",
      "downhill: validation 236 loss=0.068612 error=0.030920 *\n",
      "downhill: Adam 2361 loss=0.068612 error=0.030920\n",
      "downhill: Adam 2362 loss=0.068543 error=0.030860\n",
      "downhill: Adam 2363 loss=0.068474 error=0.030799\n",
      "downhill: Adam 2364 loss=0.068406 error=0.030739\n",
      "downhill: Adam 2365 loss=0.068337 error=0.030679\n",
      "downhill: Adam 2366 loss=0.068269 error=0.030618\n",
      "downhill: Adam 2367 loss=0.068201 error=0.030558\n",
      "downhill: Adam 2368 loss=0.068132 error=0.030498\n",
      "downhill: Adam 2369 loss=0.068064 error=0.030438\n",
      "downhill: Adam 2370 loss=0.067996 error=0.030378\n",
      "downhill: validation 237 loss=0.067928 error=0.030319 *\n",
      "downhill: Adam 2371 loss=0.067928 error=0.030319\n",
      "downhill: Adam 2372 loss=0.067861 error=0.030259\n",
      "downhill: Adam 2373 loss=0.067793 error=0.030199\n",
      "downhill: Adam 2374 loss=0.067725 error=0.030140\n",
      "downhill: Adam 2375 loss=0.067658 error=0.030080\n",
      "downhill: Adam 2376 loss=0.067590 error=0.030021\n",
      "downhill: Adam 2377 loss=0.067523 error=0.029962\n",
      "downhill: Adam 2378 loss=0.067456 error=0.029903\n",
      "downhill: Adam 2379 loss=0.067389 error=0.029844\n",
      "downhill: Adam 2380 loss=0.067322 error=0.029785\n",
      "downhill: validation 238 loss=0.067255 error=0.029726 *\n",
      "downhill: Adam 2381 loss=0.067255 error=0.029726\n",
      "downhill: Adam 2382 loss=0.067188 error=0.029667\n",
      "downhill: Adam 2383 loss=0.067121 error=0.029609\n",
      "downhill: Adam 2384 loss=0.067055 error=0.029550\n",
      "downhill: Adam 2385 loss=0.066988 error=0.029492\n",
      "downhill: Adam 2386 loss=0.066922 error=0.029433\n",
      "downhill: Adam 2387 loss=0.066855 error=0.029375\n",
      "downhill: Adam 2388 loss=0.066789 error=0.029317\n",
      "downhill: Adam 2389 loss=0.066723 error=0.029259\n",
      "downhill: Adam 2390 loss=0.066657 error=0.029201\n",
      "downhill: validation 239 loss=0.066591 error=0.029143 *\n",
      "downhill: Adam 2391 loss=0.066591 error=0.029143\n",
      "downhill: Adam 2392 loss=0.066525 error=0.029085\n",
      "downhill: Adam 2393 loss=0.066460 error=0.029028\n",
      "downhill: Adam 2394 loss=0.066394 error=0.028970\n",
      "downhill: Adam 2395 loss=0.066328 error=0.028912\n",
      "downhill: Adam 2396 loss=0.066263 error=0.028855\n",
      "downhill: Adam 2397 loss=0.066198 error=0.028798\n",
      "downhill: Adam 2398 loss=0.066133 error=0.028741\n",
      "downhill: Adam 2399 loss=0.066067 error=0.028683\n",
      "downhill: Adam 2400 loss=0.066002 error=0.028627\n",
      "downhill: validation 240 loss=0.065937 error=0.028570 *\n",
      "downhill: Adam 2401 loss=0.065937 error=0.028570\n",
      "downhill: Adam 2402 loss=0.065873 error=0.028513\n",
      "downhill: Adam 2403 loss=0.065808 error=0.028456\n",
      "downhill: Adam 2404 loss=0.065743 error=0.028400\n",
      "downhill: Adam 2405 loss=0.065679 error=0.028343\n",
      "downhill: Adam 2406 loss=0.065614 error=0.028287\n",
      "downhill: Adam 2407 loss=0.065550 error=0.028230\n",
      "downhill: Adam 2408 loss=0.065486 error=0.028174\n",
      "downhill: Adam 2409 loss=0.065422 error=0.028118\n",
      "downhill: Adam 2410 loss=0.065358 error=0.028062\n",
      "downhill: validation 241 loss=0.065294 error=0.028006 *\n",
      "downhill: Adam 2411 loss=0.065294 error=0.028006\n",
      "downhill: Adam 2412 loss=0.065230 error=0.027950\n",
      "downhill: Adam 2413 loss=0.065166 error=0.027894\n",
      "downhill: Adam 2414 loss=0.065103 error=0.027839\n",
      "downhill: Adam 2415 loss=0.065039 error=0.027783\n",
      "downhill: Adam 2416 loss=0.064976 error=0.027728\n",
      "downhill: Adam 2417 loss=0.064913 error=0.027673\n",
      "downhill: Adam 2418 loss=0.064849 error=0.027618\n",
      "downhill: Adam 2419 loss=0.064786 error=0.027562\n",
      "downhill: Adam 2420 loss=0.064723 error=0.027507\n",
      "downhill: validation 242 loss=0.064661 error=0.027452 *\n",
      "downhill: Adam 2421 loss=0.064661 error=0.027452\n",
      "downhill: Adam 2422 loss=0.064598 error=0.027398\n",
      "downhill: Adam 2423 loss=0.064535 error=0.027343\n",
      "downhill: Adam 2424 loss=0.064473 error=0.027288\n",
      "downhill: Adam 2425 loss=0.064410 error=0.027234\n",
      "downhill: Adam 2426 loss=0.064348 error=0.027180\n",
      "downhill: Adam 2427 loss=0.064286 error=0.027125\n",
      "downhill: Adam 2428 loss=0.064224 error=0.027071\n",
      "downhill: Adam 2429 loss=0.064162 error=0.027017\n",
      "downhill: Adam 2430 loss=0.064100 error=0.026963\n",
      "downhill: validation 243 loss=0.064038 error=0.026909 *\n",
      "downhill: Adam 2431 loss=0.064038 error=0.026909\n",
      "downhill: Adam 2432 loss=0.063976 error=0.026855\n",
      "downhill: Adam 2433 loss=0.063915 error=0.026802\n",
      "downhill: Adam 2434 loss=0.063853 error=0.026748\n",
      "downhill: Adam 2435 loss=0.063792 error=0.026695\n",
      "downhill: Adam 2436 loss=0.063731 error=0.026641\n",
      "downhill: Adam 2437 loss=0.063669 error=0.026588\n",
      "downhill: Adam 2438 loss=0.063608 error=0.026535\n",
      "downhill: Adam 2439 loss=0.063547 error=0.026482\n",
      "downhill: Adam 2440 loss=0.063487 error=0.026429\n",
      "downhill: validation 244 loss=0.063426 error=0.026376 *\n",
      "downhill: Adam 2441 loss=0.063426 error=0.026376\n",
      "downhill: Adam 2442 loss=0.063365 error=0.026324\n",
      "downhill: Adam 2443 loss=0.063305 error=0.026271\n",
      "downhill: Adam 2444 loss=0.063245 error=0.026219\n",
      "downhill: Adam 2445 loss=0.063184 error=0.026166\n",
      "downhill: Adam 2446 loss=0.063124 error=0.026114\n",
      "downhill: Adam 2447 loss=0.063064 error=0.026062\n",
      "downhill: Adam 2448 loss=0.063004 error=0.026010\n",
      "downhill: Adam 2449 loss=0.062944 error=0.025958\n",
      "downhill: Adam 2450 loss=0.062885 error=0.025906\n",
      "downhill: validation 245 loss=0.062825 error=0.025854 *\n",
      "downhill: Adam 2451 loss=0.062825 error=0.025854\n",
      "downhill: Adam 2452 loss=0.062766 error=0.025802\n",
      "downhill: Adam 2453 loss=0.062706 error=0.025751\n",
      "downhill: Adam 2454 loss=0.062647 error=0.025699\n",
      "downhill: Adam 2455 loss=0.062588 error=0.025648\n",
      "downhill: Adam 2456 loss=0.062529 error=0.025597\n",
      "downhill: Adam 2457 loss=0.062470 error=0.025546\n",
      "downhill: Adam 2458 loss=0.062411 error=0.025495\n",
      "downhill: Adam 2459 loss=0.062353 error=0.025444\n",
      "downhill: Adam 2460 loss=0.062294 error=0.025394\n",
      "downhill: validation 246 loss=0.062235 error=0.025343 *\n",
      "downhill: Adam 2461 loss=0.062235 error=0.025343\n",
      "downhill: Adam 2462 loss=0.062177 error=0.025293\n",
      "downhill: Adam 2463 loss=0.062119 error=0.025242\n",
      "downhill: Adam 2464 loss=0.062061 error=0.025192\n",
      "downhill: Adam 2465 loss=0.062003 error=0.025142\n",
      "downhill: Adam 2466 loss=0.061945 error=0.025092\n",
      "downhill: Adam 2467 loss=0.061887 error=0.025042\n",
      "downhill: Adam 2468 loss=0.061829 error=0.024992\n",
      "downhill: Adam 2469 loss=0.061772 error=0.024942\n",
      "downhill: Adam 2470 loss=0.061714 error=0.024893\n",
      "downhill: validation 247 loss=0.061657 error=0.024843 *\n",
      "downhill: Adam 2471 loss=0.061657 error=0.024843\n",
      "downhill: Adam 2472 loss=0.061600 error=0.024794\n",
      "downhill: Adam 2473 loss=0.061543 error=0.024745\n",
      "downhill: Adam 2474 loss=0.061486 error=0.024695\n",
      "downhill: Adam 2475 loss=0.061429 error=0.024646\n",
      "downhill: Adam 2476 loss=0.061372 error=0.024597\n",
      "downhill: Adam 2477 loss=0.061315 error=0.024549\n",
      "downhill: Adam 2478 loss=0.061259 error=0.024500\n",
      "downhill: Adam 2479 loss=0.061203 error=0.024452\n",
      "downhill: Adam 2480 loss=0.061146 error=0.024403\n",
      "downhill: validation 248 loss=0.061090 error=0.024355 *\n",
      "downhill: Adam 2481 loss=0.061090 error=0.024355\n",
      "downhill: Adam 2482 loss=0.061034 error=0.024306\n",
      "downhill: Adam 2483 loss=0.060978 error=0.024258\n",
      "downhill: Adam 2484 loss=0.060922 error=0.024210\n",
      "downhill: Adam 2485 loss=0.060867 error=0.024163\n",
      "downhill: Adam 2486 loss=0.060811 error=0.024115\n",
      "downhill: Adam 2487 loss=0.060756 error=0.024067\n",
      "downhill: Adam 2488 loss=0.060700 error=0.024019\n",
      "downhill: Adam 2489 loss=0.060645 error=0.023972\n",
      "downhill: Adam 2490 loss=0.060590 error=0.023925\n",
      "downhill: validation 249 loss=0.060535 error=0.023877 *\n",
      "downhill: Adam 2491 loss=0.060535 error=0.023877\n",
      "downhill: Adam 2492 loss=0.060480 error=0.023831\n",
      "downhill: Adam 2493 loss=0.060425 error=0.023783\n",
      "downhill: Adam 2494 loss=0.060371 error=0.023737\n",
      "downhill: Adam 2495 loss=0.060316 error=0.023690\n",
      "downhill: Adam 2496 loss=0.060262 error=0.023643\n",
      "downhill: Adam 2497 loss=0.060208 error=0.023597\n",
      "downhill: Adam 2498 loss=0.060153 error=0.023550\n",
      "downhill: Adam 2499 loss=0.060099 error=0.023504\n",
      "downhill: Adam 2500 loss=0.060045 error=0.023458\n",
      "downhill: validation 250 loss=0.059992 error=0.023412 *\n",
      "downhill: Adam 2501 loss=0.059992 error=0.023412\n",
      "downhill: Adam 2502 loss=0.059938 error=0.023366\n",
      "downhill: Adam 2503 loss=0.059884 error=0.023320\n",
      "downhill: Adam 2504 loss=0.059831 error=0.023275\n",
      "downhill: Adam 2505 loss=0.059777 error=0.023229\n",
      "downhill: Adam 2506 loss=0.059724 error=0.023183\n",
      "downhill: Adam 2507 loss=0.059671 error=0.023138\n",
      "downhill: Adam 2508 loss=0.059618 error=0.023093\n",
      "downhill: Adam 2509 loss=0.059565 error=0.023048\n",
      "downhill: Adam 2510 loss=0.059512 error=0.023003\n",
      "downhill: validation 251 loss=0.059460 error=0.022958 *\n",
      "downhill: Adam 2511 loss=0.059460 error=0.022958\n",
      "downhill: Adam 2512 loss=0.059407 error=0.022913\n",
      "downhill: Adam 2513 loss=0.059355 error=0.022868\n",
      "downhill: Adam 2514 loss=0.059303 error=0.022824\n",
      "downhill: Adam 2515 loss=0.059250 error=0.022779\n",
      "downhill: Adam 2516 loss=0.059198 error=0.022735\n",
      "downhill: Adam 2517 loss=0.059146 error=0.022691\n",
      "downhill: Adam 2518 loss=0.059095 error=0.022647\n",
      "downhill: Adam 2519 loss=0.059043 error=0.022603\n",
      "downhill: Adam 2520 loss=0.058991 error=0.022559\n",
      "downhill: validation 252 loss=0.058940 error=0.022515 *\n",
      "downhill: Adam 2521 loss=0.058940 error=0.022515\n",
      "downhill: Adam 2522 loss=0.058888 error=0.022472\n",
      "downhill: Adam 2523 loss=0.058837 error=0.022428\n",
      "downhill: Adam 2524 loss=0.058786 error=0.022385\n",
      "downhill: Adam 2525 loss=0.058735 error=0.022341\n",
      "downhill: Adam 2526 loss=0.058684 error=0.022299\n",
      "downhill: Adam 2527 loss=0.058633 error=0.022255\n",
      "downhill: Adam 2528 loss=0.058583 error=0.022212\n",
      "downhill: Adam 2529 loss=0.058532 error=0.022170\n",
      "downhill: Adam 2530 loss=0.058482 error=0.022127\n",
      "downhill: validation 253 loss=0.058432 error=0.022084 *\n",
      "downhill: Adam 2531 loss=0.058432 error=0.022084\n",
      "downhill: Adam 2532 loss=0.058381 error=0.022042\n",
      "downhill: Adam 2533 loss=0.058331 error=0.021999\n",
      "downhill: Adam 2534 loss=0.058281 error=0.021957\n",
      "downhill: Adam 2535 loss=0.058232 error=0.021915\n",
      "downhill: Adam 2536 loss=0.058182 error=0.021873\n",
      "downhill: Adam 2537 loss=0.058132 error=0.021831\n",
      "downhill: Adam 2538 loss=0.058083 error=0.021790\n",
      "downhill: Adam 2539 loss=0.058034 error=0.021748\n",
      "downhill: Adam 2540 loss=0.057984 error=0.021707\n",
      "downhill: validation 254 loss=0.057935 error=0.021665 *\n",
      "downhill: Adam 2541 loss=0.057935 error=0.021665\n",
      "downhill: Adam 2542 loss=0.057886 error=0.021624\n",
      "downhill: Adam 2543 loss=0.057837 error=0.021583\n",
      "downhill: Adam 2544 loss=0.057789 error=0.021541\n",
      "downhill: Adam 2545 loss=0.057740 error=0.021501\n",
      "downhill: Adam 2546 loss=0.057691 error=0.021460\n",
      "downhill: Adam 2547 loss=0.057643 error=0.021419\n",
      "downhill: Adam 2548 loss=0.057595 error=0.021378\n",
      "downhill: Adam 2549 loss=0.057547 error=0.021338\n",
      "downhill: Adam 2550 loss=0.057498 error=0.021297\n",
      "downhill: validation 255 loss=0.057451 error=0.021257 *\n",
      "downhill: Adam 2551 loss=0.057451 error=0.021257\n",
      "downhill: Adam 2552 loss=0.057403 error=0.021217\n",
      "downhill: Adam 2553 loss=0.057355 error=0.021177\n",
      "downhill: Adam 2554 loss=0.057307 error=0.021137\n",
      "downhill: Adam 2555 loss=0.057260 error=0.021097\n",
      "downhill: Adam 2556 loss=0.057213 error=0.021058\n",
      "downhill: Adam 2557 loss=0.057165 error=0.021018\n",
      "downhill: Adam 2558 loss=0.057118 error=0.020978\n",
      "downhill: Adam 2559 loss=0.057071 error=0.020939\n",
      "downhill: Adam 2560 loss=0.057024 error=0.020900\n",
      "downhill: validation 256 loss=0.056977 error=0.020861 *\n",
      "downhill: Adam 2561 loss=0.056977 error=0.020861\n",
      "downhill: Adam 2562 loss=0.056931 error=0.020822\n",
      "downhill: Adam 2563 loss=0.056884 error=0.020783\n",
      "downhill: Adam 2564 loss=0.056838 error=0.020744\n",
      "downhill: Adam 2565 loss=0.056791 error=0.020706\n",
      "downhill: Adam 2566 loss=0.056745 error=0.020667\n",
      "downhill: Adam 2567 loss=0.056699 error=0.020629\n",
      "downhill: Adam 2568 loss=0.056653 error=0.020590\n",
      "downhill: Adam 2569 loss=0.056607 error=0.020552\n",
      "downhill: Adam 2570 loss=0.056562 error=0.020514\n",
      "downhill: validation 257 loss=0.056516 error=0.020476 *\n",
      "downhill: Adam 2571 loss=0.056516 error=0.020476\n",
      "downhill: Adam 2572 loss=0.056470 error=0.020438\n",
      "downhill: Adam 2573 loss=0.056425 error=0.020400\n",
      "downhill: Adam 2574 loss=0.056380 error=0.020363\n",
      "downhill: Adam 2575 loss=0.056334 error=0.020325\n",
      "downhill: Adam 2576 loss=0.056289 error=0.020288\n",
      "downhill: Adam 2577 loss=0.056244 error=0.020251\n",
      "downhill: Adam 2578 loss=0.056200 error=0.020213\n",
      "downhill: Adam 2579 loss=0.056155 error=0.020176\n",
      "downhill: Adam 2580 loss=0.056110 error=0.020139\n",
      "downhill: validation 258 loss=0.056066 error=0.020103 *\n",
      "downhill: Adam 2581 loss=0.056066 error=0.020103\n",
      "downhill: Adam 2582 loss=0.056021 error=0.020066\n",
      "downhill: Adam 2583 loss=0.055977 error=0.020029\n",
      "downhill: Adam 2584 loss=0.055933 error=0.019992\n",
      "downhill: Adam 2585 loss=0.055889 error=0.019956\n",
      "downhill: Adam 2586 loss=0.055845 error=0.019920\n",
      "downhill: Adam 2587 loss=0.055801 error=0.019884\n",
      "downhill: Adam 2588 loss=0.055757 error=0.019848\n",
      "downhill: Adam 2589 loss=0.055714 error=0.019812\n",
      "downhill: Adam 2590 loss=0.055670 error=0.019776\n",
      "downhill: validation 259 loss=0.055627 error=0.019740 *\n",
      "downhill: Adam 2591 loss=0.055627 error=0.019740\n",
      "downhill: Adam 2592 loss=0.055583 error=0.019704\n",
      "downhill: Adam 2593 loss=0.055540 error=0.019669\n",
      "downhill: Adam 2594 loss=0.055497 error=0.019633\n",
      "downhill: Adam 2595 loss=0.055454 error=0.019598\n",
      "downhill: Adam 2596 loss=0.055412 error=0.019563\n",
      "downhill: Adam 2597 loss=0.055369 error=0.019528\n",
      "downhill: Adam 2598 loss=0.055326 error=0.019493\n",
      "downhill: Adam 2599 loss=0.055284 error=0.019458\n",
      "downhill: Adam 2600 loss=0.055241 error=0.019423\n",
      "downhill: validation 260 loss=0.055199 error=0.019388 *\n",
      "downhill: Adam 2601 loss=0.055199 error=0.019388\n",
      "downhill: Adam 2602 loss=0.055157 error=0.019354\n",
      "downhill: Adam 2603 loss=0.055115 error=0.019319\n",
      "downhill: Adam 2604 loss=0.055073 error=0.019286\n",
      "downhill: Adam 2605 loss=0.055031 error=0.019250\n",
      "downhill: Adam 2606 loss=0.054990 error=0.019217\n",
      "downhill: Adam 2607 loss=0.054948 error=0.019182\n",
      "downhill: Adam 2608 loss=0.054906 error=0.019149\n",
      "downhill: Adam 2609 loss=0.054865 error=0.019115\n",
      "downhill: Adam 2610 loss=0.054824 error=0.019081\n",
      "downhill: validation 261 loss=0.054783 error=0.019048 *\n",
      "downhill: Adam 2611 loss=0.054783 error=0.019048\n",
      "downhill: Adam 2612 loss=0.054742 error=0.019014\n",
      "downhill: Adam 2613 loss=0.054701 error=0.018981\n",
      "downhill: Adam 2614 loss=0.054660 error=0.018947\n",
      "downhill: Adam 2615 loss=0.054619 error=0.018914\n",
      "downhill: Adam 2616 loss=0.054579 error=0.018881\n",
      "downhill: Adam 2617 loss=0.054538 error=0.018848\n",
      "downhill: Adam 2618 loss=0.054498 error=0.018815\n",
      "downhill: Adam 2619 loss=0.054457 error=0.018782\n",
      "downhill: Adam 2620 loss=0.054417 error=0.018750\n",
      "downhill: validation 262 loss=0.054377 error=0.018717 *\n",
      "downhill: Adam 2621 loss=0.054377 error=0.018717\n",
      "downhill: Adam 2622 loss=0.054337 error=0.018685\n",
      "downhill: Adam 2623 loss=0.054297 error=0.018652\n",
      "downhill: Adam 2624 loss=0.054258 error=0.018620\n",
      "downhill: Adam 2625 loss=0.054218 error=0.018588\n",
      "downhill: Adam 2626 loss=0.054178 error=0.018556\n",
      "downhill: Adam 2627 loss=0.054139 error=0.018524\n",
      "downhill: Adam 2628 loss=0.054100 error=0.018492\n",
      "downhill: Adam 2629 loss=0.054060 error=0.018460\n",
      "downhill: Adam 2630 loss=0.054021 error=0.018429\n",
      "downhill: validation 263 loss=0.053982 error=0.018397 *\n",
      "downhill: Adam 2631 loss=0.053982 error=0.018397\n",
      "downhill: Adam 2632 loss=0.053943 error=0.018366\n",
      "downhill: Adam 2633 loss=0.053905 error=0.018334\n",
      "downhill: Adam 2634 loss=0.053866 error=0.018303\n",
      "downhill: Adam 2635 loss=0.053827 error=0.018272\n",
      "downhill: Adam 2636 loss=0.053789 error=0.018241\n",
      "downhill: Adam 2637 loss=0.053750 error=0.018210\n",
      "downhill: Adam 2638 loss=0.053712 error=0.018179\n",
      "downhill: Adam 2639 loss=0.053674 error=0.018149\n",
      "downhill: Adam 2640 loss=0.053636 error=0.018118\n",
      "downhill: validation 264 loss=0.053598 error=0.018087 *\n",
      "downhill: Adam 2641 loss=0.053598 error=0.018087\n",
      "downhill: Adam 2642 loss=0.053560 error=0.018057\n",
      "downhill: Adam 2643 loss=0.053522 error=0.018027\n",
      "downhill: Adam 2644 loss=0.053485 error=0.017996\n",
      "downhill: Adam 2645 loss=0.053447 error=0.017966\n",
      "downhill: Adam 2646 loss=0.053410 error=0.017936\n",
      "downhill: Adam 2647 loss=0.053372 error=0.017906\n",
      "downhill: Adam 2648 loss=0.053335 error=0.017877\n",
      "downhill: Adam 2649 loss=0.053298 error=0.017847\n",
      "downhill: Adam 2650 loss=0.053261 error=0.017817\n",
      "downhill: validation 265 loss=0.053224 error=0.017787 *\n",
      "downhill: Adam 2651 loss=0.053224 error=0.017787\n",
      "downhill: Adam 2652 loss=0.053187 error=0.017758\n",
      "downhill: Adam 2653 loss=0.053150 error=0.017728\n",
      "downhill: Adam 2654 loss=0.053114 error=0.017700\n",
      "downhill: Adam 2655 loss=0.053077 error=0.017669\n",
      "downhill: Adam 2656 loss=0.053041 error=0.017642\n",
      "downhill: Adam 2657 loss=0.053004 error=0.017611\n",
      "downhill: Adam 2658 loss=0.052968 error=0.017584\n",
      "downhill: Adam 2659 loss=0.052932 error=0.017554\n",
      "downhill: Adam 2660 loss=0.052896 error=0.017525\n",
      "downhill: validation 266 loss=0.052860 error=0.017497 *\n",
      "downhill: Adam 2661 loss=0.052860 error=0.017497\n",
      "downhill: Adam 2662 loss=0.052824 error=0.017468\n",
      "downhill: Adam 2663 loss=0.052788 error=0.017440\n",
      "downhill: Adam 2664 loss=0.052753 error=0.017412\n",
      "downhill: Adam 2665 loss=0.052717 error=0.017383\n",
      "downhill: Adam 2666 loss=0.052682 error=0.017355\n",
      "downhill: Adam 2667 loss=0.052646 error=0.017327\n",
      "downhill: Adam 2668 loss=0.052611 error=0.017299\n",
      "downhill: Adam 2669 loss=0.052576 error=0.017271\n",
      "downhill: Adam 2670 loss=0.052541 error=0.017243\n",
      "downhill: validation 267 loss=0.052506 error=0.017216 *\n",
      "downhill: Adam 2671 loss=0.052506 error=0.017216\n",
      "downhill: Adam 2672 loss=0.052471 error=0.017188\n",
      "downhill: Adam 2673 loss=0.052436 error=0.017161\n",
      "downhill: Adam 2674 loss=0.052401 error=0.017133\n",
      "downhill: Adam 2675 loss=0.052366 error=0.017106\n",
      "downhill: Adam 2676 loss=0.052332 error=0.017078\n",
      "downhill: Adam 2677 loss=0.052298 error=0.017051\n",
      "downhill: Adam 2678 loss=0.052263 error=0.017024\n",
      "downhill: Adam 2679 loss=0.052229 error=0.016997\n",
      "downhill: Adam 2680 loss=0.052195 error=0.016970\n",
      "downhill: validation 268 loss=0.052161 error=0.016943 *\n",
      "downhill: Adam 2681 loss=0.052161 error=0.016943\n",
      "downhill: Adam 2682 loss=0.052127 error=0.016916\n",
      "downhill: Adam 2683 loss=0.052093 error=0.016890\n",
      "downhill: Adam 2684 loss=0.052059 error=0.016863\n",
      "downhill: Adam 2685 loss=0.052025 error=0.016836\n",
      "downhill: Adam 2686 loss=0.051992 error=0.016810\n",
      "downhill: Adam 2687 loss=0.051958 error=0.016784\n",
      "downhill: Adam 2688 loss=0.051925 error=0.016757\n",
      "downhill: Adam 2689 loss=0.051891 error=0.016731\n",
      "downhill: Adam 2690 loss=0.051858 error=0.016705\n",
      "downhill: validation 269 loss=0.051825 error=0.016679 *\n",
      "downhill: Adam 2691 loss=0.051825 error=0.016679\n",
      "downhill: Adam 2692 loss=0.051792 error=0.016653\n",
      "downhill: Adam 2693 loss=0.051759 error=0.016627\n",
      "downhill: Adam 2694 loss=0.051726 error=0.016601\n",
      "downhill: Adam 2695 loss=0.051693 error=0.016575\n",
      "downhill: Adam 2696 loss=0.051660 error=0.016550\n",
      "downhill: Adam 2697 loss=0.051628 error=0.016524\n",
      "downhill: Adam 2698 loss=0.051595 error=0.016499\n",
      "downhill: Adam 2699 loss=0.051563 error=0.016473\n",
      "downhill: Adam 2700 loss=0.051530 error=0.016448\n",
      "downhill: validation 270 loss=0.051498 error=0.016423 *\n",
      "downhill: Adam 2701 loss=0.051498 error=0.016423\n",
      "downhill: Adam 2702 loss=0.051466 error=0.016398\n",
      "downhill: Adam 2703 loss=0.051434 error=0.016372\n",
      "downhill: Adam 2704 loss=0.051402 error=0.016347\n",
      "downhill: Adam 2705 loss=0.051370 error=0.016322\n",
      "downhill: Adam 2706 loss=0.051338 error=0.016298\n",
      "downhill: Adam 2707 loss=0.051306 error=0.016273\n",
      "downhill: Adam 2708 loss=0.051274 error=0.016248\n",
      "downhill: Adam 2709 loss=0.051243 error=0.016223\n",
      "downhill: Adam 2710 loss=0.051211 error=0.016199\n",
      "downhill: validation 271 loss=0.051180 error=0.016174 *\n",
      "downhill: Adam 2711 loss=0.051180 error=0.016174\n",
      "downhill: Adam 2712 loss=0.051148 error=0.016150\n",
      "downhill: Adam 2713 loss=0.051117 error=0.016125\n",
      "downhill: Adam 2714 loss=0.051086 error=0.016102\n",
      "downhill: Adam 2715 loss=0.051055 error=0.016076\n",
      "downhill: Adam 2716 loss=0.051023 error=0.016054\n",
      "downhill: Adam 2717 loss=0.050992 error=0.016028\n",
      "downhill: Adam 2718 loss=0.050962 error=0.016005\n",
      "downhill: Adam 2719 loss=0.050931 error=0.015980\n",
      "downhill: Adam 2720 loss=0.050900 error=0.015956\n",
      "downhill: validation 272 loss=0.050869 error=0.015933 *\n",
      "downhill: Adam 2721 loss=0.050869 error=0.015933\n",
      "downhill: Adam 2722 loss=0.050839 error=0.015909\n",
      "downhill: Adam 2723 loss=0.050808 error=0.015886\n",
      "downhill: Adam 2724 loss=0.050778 error=0.015862\n",
      "downhill: Adam 2725 loss=0.050747 error=0.015838\n",
      "downhill: Adam 2726 loss=0.050717 error=0.015815\n",
      "downhill: Adam 2727 loss=0.050687 error=0.015791\n",
      "downhill: Adam 2728 loss=0.050656 error=0.015768\n",
      "downhill: Adam 2729 loss=0.050626 error=0.015744\n",
      "downhill: Adam 2730 loss=0.050596 error=0.015721\n",
      "downhill: validation 273 loss=0.050566 error=0.015698 *\n",
      "downhill: Adam 2731 loss=0.050566 error=0.015698\n",
      "downhill: Adam 2732 loss=0.050537 error=0.015674\n",
      "downhill: Adam 2733 loss=0.050507 error=0.015652\n",
      "downhill: Adam 2734 loss=0.050477 error=0.015628\n",
      "downhill: Adam 2735 loss=0.050447 error=0.015605\n",
      "downhill: Adam 2736 loss=0.050418 error=0.015583\n",
      "downhill: Adam 2737 loss=0.050388 error=0.015559\n",
      "downhill: Adam 2738 loss=0.050359 error=0.015537\n",
      "downhill: Adam 2739 loss=0.050329 error=0.015514\n",
      "downhill: Adam 2740 loss=0.050300 error=0.015491\n",
      "downhill: validation 274 loss=0.050271 error=0.015469 *\n",
      "downhill: Adam 2741 loss=0.050271 error=0.015469\n",
      "downhill: Adam 2742 loss=0.050242 error=0.015446\n",
      "downhill: Adam 2743 loss=0.050212 error=0.015424\n",
      "downhill: Adam 2744 loss=0.050183 error=0.015401\n",
      "downhill: Adam 2745 loss=0.050154 error=0.015378\n",
      "downhill: Adam 2746 loss=0.050125 error=0.015356\n",
      "downhill: Adam 2747 loss=0.050097 error=0.015334\n",
      "downhill: Adam 2748 loss=0.050068 error=0.015311\n",
      "downhill: Adam 2749 loss=0.050039 error=0.015289\n",
      "downhill: Adam 2750 loss=0.050010 error=0.015267\n",
      "downhill: validation 275 loss=0.049982 error=0.015245 *\n",
      "downhill: Adam 2751 loss=0.049982 error=0.015245\n",
      "downhill: Adam 2752 loss=0.049953 error=0.015222\n",
      "downhill: Adam 2753 loss=0.049925 error=0.015200\n",
      "downhill: Adam 2754 loss=0.049896 error=0.015178\n",
      "downhill: Adam 2755 loss=0.049868 error=0.015156\n",
      "downhill: Adam 2756 loss=0.049839 error=0.015134\n",
      "downhill: Adam 2757 loss=0.049811 error=0.015113\n",
      "downhill: Adam 2758 loss=0.049783 error=0.015091\n",
      "downhill: Adam 2759 loss=0.049755 error=0.015069\n",
      "downhill: Adam 2760 loss=0.049727 error=0.015047\n",
      "downhill: validation 276 loss=0.049698 error=0.015025 *\n",
      "downhill: Adam 2761 loss=0.049698 error=0.015025\n",
      "downhill: Adam 2762 loss=0.049670 error=0.015003\n",
      "downhill: Adam 2763 loss=0.049642 error=0.014982\n",
      "downhill: Adam 2764 loss=0.049615 error=0.014960\n",
      "downhill: Adam 2765 loss=0.049587 error=0.014938\n",
      "downhill: Adam 2766 loss=0.049559 error=0.014917\n",
      "downhill: Adam 2767 loss=0.049531 error=0.014895\n",
      "downhill: Adam 2768 loss=0.049503 error=0.014874\n",
      "downhill: Adam 2769 loss=0.049476 error=0.014852\n",
      "downhill: Adam 2770 loss=0.049448 error=0.014831\n",
      "downhill: validation 277 loss=0.049421 error=0.014809 *\n",
      "downhill: Adam 2771 loss=0.049421 error=0.014809\n",
      "downhill: Adam 2772 loss=0.049393 error=0.014788\n",
      "downhill: Adam 2773 loss=0.049365 error=0.014766\n",
      "downhill: Adam 2774 loss=0.049338 error=0.014745\n",
      "downhill: Adam 2775 loss=0.049311 error=0.014724\n",
      "downhill: Adam 2776 loss=0.049283 error=0.014703\n",
      "downhill: Adam 2777 loss=0.049256 error=0.014681\n",
      "downhill: Adam 2778 loss=0.049229 error=0.014661\n",
      "downhill: Adam 2779 loss=0.049202 error=0.014638\n",
      "downhill: Adam 2780 loss=0.049174 error=0.014619\n",
      "downhill: validation 278 loss=0.049147 error=0.014596 *\n",
      "downhill: Adam 2781 loss=0.049147 error=0.014596\n",
      "downhill: Adam 2782 loss=0.049120 error=0.014576\n",
      "downhill: Adam 2783 loss=0.049093 error=0.014555\n",
      "downhill: Adam 2784 loss=0.049066 error=0.014533\n",
      "downhill: Adam 2785 loss=0.049039 error=0.014513\n",
      "downhill: Adam 2786 loss=0.049012 error=0.014491\n",
      "downhill: Adam 2787 loss=0.048985 error=0.014470\n",
      "downhill: Adam 2788 loss=0.048958 error=0.014449\n",
      "downhill: Adam 2789 loss=0.048932 error=0.014428\n",
      "downhill: Adam 2790 loss=0.048905 error=0.014408\n",
      "downhill: validation 279 loss=0.048878 error=0.014386 *\n",
      "downhill: Adam 2791 loss=0.048878 error=0.014386\n",
      "downhill: Adam 2792 loss=0.048851 error=0.014365\n",
      "downhill: Adam 2793 loss=0.048825 error=0.014345\n",
      "downhill: Adam 2794 loss=0.048798 error=0.014323\n",
      "downhill: Adam 2795 loss=0.048771 error=0.014303\n",
      "downhill: Adam 2796 loss=0.048745 error=0.014282\n",
      "downhill: Adam 2797 loss=0.048718 error=0.014261\n",
      "downhill: Adam 2798 loss=0.048692 error=0.014240\n",
      "downhill: Adam 2799 loss=0.048665 error=0.014219\n",
      "downhill: Adam 2800 loss=0.048639 error=0.014198\n",
      "downhill: validation 280 loss=0.048612 error=0.014177 *\n",
      "downhill: Adam 2801 loss=0.048612 error=0.014177\n",
      "downhill: Adam 2802 loss=0.048586 error=0.014156\n",
      "downhill: Adam 2803 loss=0.048559 error=0.014136\n",
      "downhill: Adam 2804 loss=0.048533 error=0.014115\n",
      "downhill: Adam 2805 loss=0.048507 error=0.014094\n",
      "downhill: Adam 2806 loss=0.048480 error=0.014073\n",
      "downhill: Adam 2807 loss=0.048454 error=0.014053\n",
      "downhill: Adam 2808 loss=0.048428 error=0.014032\n",
      "downhill: Adam 2809 loss=0.048402 error=0.014011\n",
      "downhill: Adam 2810 loss=0.048376 error=0.013990\n",
      "downhill: validation 281 loss=0.048349 error=0.013969 *\n",
      "downhill: Adam 2811 loss=0.048349 error=0.013969\n",
      "downhill: Adam 2812 loss=0.048323 error=0.013949\n",
      "downhill: Adam 2813 loss=0.048297 error=0.013928\n",
      "downhill: Adam 2814 loss=0.048271 error=0.013907\n",
      "downhill: Adam 2815 loss=0.048245 error=0.013886\n",
      "downhill: Adam 2816 loss=0.048219 error=0.013865\n",
      "downhill: Adam 2817 loss=0.048193 error=0.013845\n",
      "downhill: Adam 2818 loss=0.048167 error=0.013824\n",
      "downhill: Adam 2819 loss=0.048141 error=0.013803\n",
      "downhill: Adam 2820 loss=0.048115 error=0.013782\n",
      "downhill: validation 282 loss=0.048089 error=0.013762 *\n",
      "downhill: Adam 2821 loss=0.048089 error=0.013762\n",
      "downhill: Adam 2822 loss=0.048063 error=0.013741\n",
      "downhill: Adam 2823 loss=0.048037 error=0.013720\n",
      "downhill: Adam 2824 loss=0.048011 error=0.013699\n",
      "downhill: Adam 2825 loss=0.047985 error=0.013678\n",
      "downhill: Adam 2826 loss=0.047959 error=0.013657\n",
      "downhill: Adam 2827 loss=0.047933 error=0.013637\n",
      "downhill: Adam 2828 loss=0.047907 error=0.013616\n",
      "downhill: Adam 2829 loss=0.047881 error=0.013595\n",
      "downhill: Adam 2830 loss=0.047856 error=0.013574\n",
      "downhill: validation 283 loss=0.047830 error=0.013553 *\n",
      "downhill: Adam 2831 loss=0.047830 error=0.013553\n",
      "downhill: Adam 2832 loss=0.047804 error=0.013532\n",
      "downhill: Adam 2833 loss=0.047778 error=0.013511\n",
      "downhill: Adam 2834 loss=0.047752 error=0.013490\n",
      "downhill: Adam 2835 loss=0.047727 error=0.013469\n",
      "downhill: Adam 2836 loss=0.047701 error=0.013448\n",
      "downhill: Adam 2837 loss=0.047675 error=0.013427\n",
      "downhill: Adam 2838 loss=0.047649 error=0.013407\n",
      "downhill: Adam 2839 loss=0.047624 error=0.013385\n",
      "downhill: Adam 2840 loss=0.047598 error=0.013365\n",
      "downhill: validation 284 loss=0.047572 error=0.013343 *\n",
      "downhill: Adam 2841 loss=0.047572 error=0.013343\n",
      "downhill: Adam 2842 loss=0.047547 error=0.013323\n",
      "downhill: Adam 2843 loss=0.047521 error=0.013300\n",
      "downhill: Adam 2844 loss=0.047495 error=0.013282\n",
      "downhill: Adam 2845 loss=0.047470 error=0.013257\n",
      "downhill: Adam 2846 loss=0.047444 error=0.013239\n",
      "downhill: Adam 2847 loss=0.047418 error=0.013216\n",
      "downhill: Adam 2848 loss=0.047393 error=0.013195\n",
      "downhill: Adam 2849 loss=0.047367 error=0.013175\n",
      "downhill: Adam 2850 loss=0.047341 error=0.013153\n",
      "downhill: validation 285 loss=0.047316 error=0.013132 *\n",
      "downhill: Adam 2851 loss=0.047316 error=0.013132\n",
      "downhill: Adam 2852 loss=0.047290 error=0.013111\n",
      "downhill: Adam 2853 loss=0.047264 error=0.013089\n",
      "downhill: Adam 2854 loss=0.047239 error=0.013068\n",
      "downhill: Adam 2855 loss=0.047213 error=0.013047\n",
      "downhill: Adam 2856 loss=0.047187 error=0.013025\n",
      "downhill: Adam 2857 loss=0.047162 error=0.013004\n",
      "downhill: Adam 2858 loss=0.047136 error=0.012982\n",
      "downhill: Adam 2859 loss=0.047111 error=0.012961\n",
      "downhill: Adam 2860 loss=0.047085 error=0.012940\n",
      "downhill: validation 286 loss=0.047059 error=0.012918 *\n",
      "downhill: Adam 2861 loss=0.047059 error=0.012918\n",
      "downhill: Adam 2862 loss=0.047034 error=0.012897\n",
      "downhill: Adam 2863 loss=0.047008 error=0.012875\n",
      "downhill: Adam 2864 loss=0.046983 error=0.012854\n",
      "downhill: Adam 2865 loss=0.046957 error=0.012832\n",
      "downhill: Adam 2866 loss=0.046931 error=0.012810\n",
      "downhill: Adam 2867 loss=0.046906 error=0.012789\n",
      "downhill: Adam 2868 loss=0.046880 error=0.012767\n",
      "downhill: Adam 2869 loss=0.046855 error=0.012746\n",
      "downhill: Adam 2870 loss=0.046829 error=0.012724\n",
      "downhill: validation 287 loss=0.046803 error=0.012702 *\n",
      "downhill: Adam 2871 loss=0.046803 error=0.012702\n",
      "downhill: Adam 2872 loss=0.046778 error=0.012680\n",
      "downhill: Adam 2873 loss=0.046752 error=0.012659\n",
      "downhill: Adam 2874 loss=0.046726 error=0.012637\n",
      "downhill: Adam 2875 loss=0.046701 error=0.012615\n",
      "downhill: Adam 2876 loss=0.046675 error=0.012593\n",
      "downhill: Adam 2877 loss=0.046650 error=0.012571\n",
      "downhill: Adam 2878 loss=0.046624 error=0.012550\n",
      "downhill: Adam 2879 loss=0.046598 error=0.012527\n",
      "downhill: Adam 2880 loss=0.046573 error=0.012506\n",
      "downhill: validation 288 loss=0.046547 error=0.012483 *\n",
      "downhill: Adam 2881 loss=0.046547 error=0.012483\n",
      "downhill: Adam 2882 loss=0.046521 error=0.012461\n",
      "downhill: Adam 2883 loss=0.046496 error=0.012439\n",
      "downhill: Adam 2884 loss=0.046470 error=0.012417\n",
      "downhill: Adam 2885 loss=0.046444 error=0.012395\n",
      "downhill: Adam 2886 loss=0.046419 error=0.012373\n",
      "downhill: Adam 2887 loss=0.046393 error=0.012351\n",
      "downhill: Adam 2888 loss=0.046367 error=0.012329\n",
      "downhill: Adam 2889 loss=0.046342 error=0.012306\n",
      "downhill: Adam 2890 loss=0.046316 error=0.012284\n",
      "downhill: validation 289 loss=0.046290 error=0.012262 *\n",
      "downhill: Adam 2891 loss=0.046290 error=0.012262\n",
      "downhill: Adam 2892 loss=0.046265 error=0.012239\n",
      "downhill: Adam 2893 loss=0.046239 error=0.012217\n",
      "downhill: Adam 2894 loss=0.046213 error=0.012194\n",
      "downhill: Adam 2895 loss=0.046188 error=0.012172\n",
      "downhill: Adam 2896 loss=0.046162 error=0.012150\n",
      "downhill: Adam 2897 loss=0.046136 error=0.012127\n",
      "downhill: Adam 2898 loss=0.046110 error=0.012104\n",
      "downhill: Adam 2899 loss=0.046085 error=0.012082\n",
      "downhill: Adam 2900 loss=0.046059 error=0.012059\n",
      "downhill: validation 290 loss=0.046033 error=0.012037 *\n",
      "downhill: Adam 2901 loss=0.046033 error=0.012037\n",
      "downhill: Adam 2902 loss=0.046008 error=0.012014\n",
      "downhill: Adam 2903 loss=0.045982 error=0.011992\n",
      "downhill: Adam 2904 loss=0.045956 error=0.011969\n",
      "downhill: Adam 2905 loss=0.045930 error=0.011946\n",
      "downhill: Adam 2906 loss=0.045905 error=0.011923\n",
      "downhill: Adam 2907 loss=0.045879 error=0.011901\n",
      "downhill: Adam 2908 loss=0.045853 error=0.011878\n",
      "downhill: Adam 2909 loss=0.045827 error=0.011855\n",
      "downhill: Adam 2910 loss=0.045802 error=0.011832\n",
      "downhill: validation 291 loss=0.045776 error=0.011809 *\n",
      "downhill: Adam 2911 loss=0.045776 error=0.011809\n",
      "downhill: Adam 2912 loss=0.045750 error=0.011786\n",
      "downhill: Adam 2913 loss=0.045724 error=0.011764\n",
      "downhill: Adam 2914 loss=0.045698 error=0.011740\n",
      "downhill: Adam 2915 loss=0.045673 error=0.011718\n",
      "downhill: Adam 2916 loss=0.045647 error=0.011694\n",
      "downhill: Adam 2917 loss=0.045621 error=0.011673\n",
      "downhill: Adam 2918 loss=0.045595 error=0.011647\n",
      "downhill: Adam 2919 loss=0.045569 error=0.011627\n",
      "downhill: Adam 2920 loss=0.045544 error=0.011601\n",
      "downhill: validation 292 loss=0.045518 error=0.011580 *\n",
      "downhill: Adam 2921 loss=0.045518 error=0.011580\n",
      "downhill: Adam 2922 loss=0.045492 error=0.011556\n",
      "downhill: Adam 2923 loss=0.045466 error=0.011532\n",
      "downhill: Adam 2924 loss=0.045440 error=0.011510\n",
      "downhill: Adam 2925 loss=0.045414 error=0.011486\n",
      "downhill: Adam 2926 loss=0.045389 error=0.011464\n",
      "downhill: Adam 2927 loss=0.045363 error=0.011440\n",
      "downhill: Adam 2928 loss=0.045337 error=0.011417\n",
      "downhill: Adam 2929 loss=0.045311 error=0.011394\n",
      "downhill: Adam 2930 loss=0.045285 error=0.011370\n",
      "downhill: validation 293 loss=0.045259 error=0.011347 *\n",
      "downhill: Adam 2931 loss=0.045259 error=0.011347\n",
      "downhill: Adam 2932 loss=0.045234 error=0.011324\n",
      "downhill: Adam 2933 loss=0.045208 error=0.011300\n",
      "downhill: Adam 2934 loss=0.045182 error=0.011277\n",
      "downhill: Adam 2935 loss=0.045156 error=0.011253\n",
      "downhill: Adam 2936 loss=0.045130 error=0.011231\n",
      "downhill: Adam 2937 loss=0.045104 error=0.011207\n",
      "downhill: Adam 2938 loss=0.045079 error=0.011184\n",
      "downhill: Adam 2939 loss=0.045053 error=0.011160\n",
      "downhill: Adam 2940 loss=0.045027 error=0.011136\n",
      "downhill: validation 294 loss=0.045001 error=0.011114 *\n",
      "downhill: Adam 2941 loss=0.045001 error=0.011114\n",
      "downhill: Adam 2942 loss=0.044975 error=0.011090\n",
      "downhill: Adam 2943 loss=0.044950 error=0.011067\n",
      "downhill: Adam 2944 loss=0.044924 error=0.011043\n",
      "downhill: Adam 2945 loss=0.044898 error=0.011020\n",
      "downhill: Adam 2946 loss=0.044872 error=0.010996\n",
      "downhill: Adam 2947 loss=0.044847 error=0.010973\n",
      "downhill: Adam 2948 loss=0.044821 error=0.010949\n",
      "downhill: Adam 2949 loss=0.044795 error=0.010926\n",
      "downhill: Adam 2950 loss=0.044769 error=0.010902\n",
      "downhill: validation 295 loss=0.044744 error=0.010879 *\n",
      "downhill: Adam 2951 loss=0.044744 error=0.010879\n",
      "downhill: Adam 2952 loss=0.044718 error=0.010855\n",
      "downhill: Adam 2953 loss=0.044692 error=0.010832\n",
      "downhill: Adam 2954 loss=0.044667 error=0.010808\n",
      "downhill: Adam 2955 loss=0.044641 error=0.010785\n",
      "downhill: Adam 2956 loss=0.044615 error=0.010761\n",
      "downhill: Adam 2957 loss=0.044590 error=0.010738\n",
      "downhill: Adam 2958 loss=0.044564 error=0.010714\n",
      "downhill: Adam 2959 loss=0.044539 error=0.010691\n",
      "downhill: Adam 2960 loss=0.044513 error=0.010668\n",
      "downhill: validation 296 loss=0.044487 error=0.010645 *\n",
      "downhill: Adam 2961 loss=0.044487 error=0.010645\n",
      "downhill: Adam 2962 loss=0.044462 error=0.010621\n",
      "downhill: Adam 2963 loss=0.044436 error=0.010598\n",
      "downhill: Adam 2964 loss=0.044411 error=0.010574\n",
      "downhill: Adam 2965 loss=0.044385 error=0.010551\n",
      "downhill: Adam 2966 loss=0.044360 error=0.010527\n",
      "downhill: Adam 2967 loss=0.044335 error=0.010504\n",
      "downhill: Adam 2968 loss=0.044309 error=0.010480\n",
      "downhill: Adam 2969 loss=0.044284 error=0.010458\n",
      "downhill: Adam 2970 loss=0.044258 error=0.010433\n",
      "downhill: validation 297 loss=0.044233 error=0.010412 *\n",
      "downhill: Adam 2971 loss=0.044233 error=0.010412\n",
      "downhill: Adam 2972 loss=0.044208 error=0.010386\n",
      "downhill: Adam 2973 loss=0.044183 error=0.010365\n",
      "downhill: Adam 2974 loss=0.044157 error=0.010340\n",
      "downhill: Adam 2975 loss=0.044132 error=0.010318\n",
      "downhill: Adam 2976 loss=0.044107 error=0.010294\n",
      "downhill: Adam 2977 loss=0.044082 error=0.010271\n",
      "downhill: Adam 2978 loss=0.044056 error=0.010249\n",
      "downhill: Adam 2979 loss=0.044031 error=0.010224\n",
      "downhill: Adam 2980 loss=0.044006 error=0.010202\n",
      "downhill: validation 298 loss=0.043981 error=0.010178 *\n",
      "downhill: Adam 2981 loss=0.043981 error=0.010178\n",
      "downhill: Adam 2982 loss=0.043956 error=0.010156\n",
      "downhill: Adam 2983 loss=0.043931 error=0.010133\n",
      "downhill: Adam 2984 loss=0.043906 error=0.010109\n",
      "downhill: Adam 2985 loss=0.043881 error=0.010087\n",
      "downhill: Adam 2986 loss=0.043856 error=0.010063\n",
      "downhill: Adam 2987 loss=0.043831 error=0.010041\n",
      "downhill: Adam 2988 loss=0.043806 error=0.010017\n",
      "downhill: Adam 2989 loss=0.043781 error=0.009995\n",
      "downhill: Adam 2990 loss=0.043756 error=0.009972\n",
      "downhill: validation 299 loss=0.043732 error=0.009949 *\n",
      "downhill: Adam 2991 loss=0.043732 error=0.009949\n",
      "downhill: Adam 2992 loss=0.043707 error=0.009926\n",
      "downhill: Adam 2993 loss=0.043682 error=0.009903\n",
      "downhill: Adam 2994 loss=0.043657 error=0.009881\n",
      "downhill: Adam 2995 loss=0.043633 error=0.009857\n",
      "downhill: Adam 2996 loss=0.043608 error=0.009835\n",
      "downhill: Adam 2997 loss=0.043583 error=0.009812\n",
      "downhill: Adam 2998 loss=0.043559 error=0.009790\n",
      "downhill: Adam 2999 loss=0.043534 error=0.009767\n",
      "downhill: Adam 3000 loss=0.043510 error=0.009745\n",
      "downhill: validation 300 loss=0.043485 error=0.009722 *\n",
      "downhill: Adam 3001 loss=0.043485 error=0.009722\n",
      "downhill: Adam 3002 loss=0.043461 error=0.009700\n",
      "downhill: Adam 3003 loss=0.043436 error=0.009677\n",
      "downhill: Adam 3004 loss=0.043412 error=0.009655\n",
      "downhill: Adam 3005 loss=0.043388 error=0.009633\n",
      "downhill: Adam 3006 loss=0.043363 error=0.009610\n",
      "downhill: Adam 3007 loss=0.043339 error=0.009588\n",
      "downhill: Adam 3008 loss=0.043315 error=0.009565\n",
      "downhill: Adam 3009 loss=0.043291 error=0.009544\n",
      "downhill: Adam 3010 loss=0.043267 error=0.009521\n",
      "downhill: validation 301 loss=0.043243 error=0.009500 *\n",
      "downhill: Adam 3011 loss=0.043243 error=0.009500\n",
      "downhill: Adam 3012 loss=0.043219 error=0.009477\n",
      "downhill: Adam 3013 loss=0.043195 error=0.009457\n",
      "downhill: Adam 3014 loss=0.043171 error=0.009432\n",
      "downhill: Adam 3015 loss=0.043147 error=0.009412\n",
      "downhill: Adam 3016 loss=0.043123 error=0.009389\n",
      "downhill: Adam 3017 loss=0.043099 error=0.009368\n",
      "downhill: Adam 3018 loss=0.043075 error=0.009347\n",
      "downhill: Adam 3019 loss=0.043052 error=0.009324\n",
      "downhill: Adam 3020 loss=0.043028 error=0.009304\n",
      "downhill: validation 302 loss=0.043004 error=0.009281 *\n",
      "downhill: Adam 3021 loss=0.043004 error=0.009281\n",
      "downhill: Adam 3022 loss=0.042981 error=0.009260\n",
      "downhill: Adam 3023 loss=0.042957 error=0.009238\n",
      "downhill: Adam 3024 loss=0.042934 error=0.009217\n",
      "downhill: Adam 3025 loss=0.042910 error=0.009196\n",
      "downhill: Adam 3026 loss=0.042887 error=0.009174\n",
      "downhill: Adam 3027 loss=0.042863 error=0.009153\n",
      "downhill: Adam 3028 loss=0.042840 error=0.009131\n",
      "downhill: Adam 3029 loss=0.042817 error=0.009111\n",
      "downhill: Adam 3030 loss=0.042794 error=0.009089\n",
      "downhill: validation 303 loss=0.042771 error=0.009068 *\n",
      "downhill: Adam 3031 loss=0.042771 error=0.009068\n",
      "downhill: Adam 3032 loss=0.042747 error=0.009048\n",
      "downhill: Adam 3033 loss=0.042724 error=0.009026\n",
      "downhill: Adam 3034 loss=0.042701 error=0.009006\n",
      "downhill: Adam 3035 loss=0.042678 error=0.008984\n",
      "downhill: Adam 3036 loss=0.042656 error=0.008964\n",
      "downhill: Adam 3037 loss=0.042633 error=0.008943\n",
      "downhill: Adam 3038 loss=0.042610 error=0.008923\n",
      "downhill: Adam 3039 loss=0.042587 error=0.008902\n",
      "downhill: Adam 3040 loss=0.042564 error=0.008881\n",
      "downhill: validation 304 loss=0.042542 error=0.008861 *\n",
      "downhill: Adam 3041 loss=0.042542 error=0.008861\n",
      "downhill: Adam 3042 loss=0.042519 error=0.008840\n",
      "downhill: Adam 3043 loss=0.042496 error=0.008820\n",
      "downhill: Adam 3044 loss=0.042474 error=0.008799\n",
      "downhill: Adam 3045 loss=0.042451 error=0.008780\n",
      "downhill: Adam 3046 loss=0.042429 error=0.008759\n",
      "downhill: Adam 3047 loss=0.042407 error=0.008739\n",
      "downhill: Adam 3048 loss=0.042384 error=0.008719\n",
      "downhill: Adam 3049 loss=0.042362 error=0.008699\n",
      "downhill: Adam 3050 loss=0.042340 error=0.008679\n",
      "downhill: validation 305 loss=0.042318 error=0.008659 *\n",
      "downhill: Adam 3051 loss=0.042318 error=0.008659\n",
      "downhill: Adam 3052 loss=0.042296 error=0.008639\n",
      "downhill: Adam 3053 loss=0.042274 error=0.008620\n",
      "downhill: Adam 3054 loss=0.042251 error=0.008599\n",
      "downhill: Adam 3055 loss=0.042230 error=0.008581\n",
      "downhill: Adam 3056 loss=0.042208 error=0.008559\n",
      "downhill: Adam 3057 loss=0.042186 error=0.008542\n",
      "downhill: Adam 3058 loss=0.042164 error=0.008520\n",
      "downhill: Adam 3059 loss=0.042142 error=0.008503\n",
      "downhill: Adam 3060 loss=0.042120 error=0.008482\n",
      "downhill: validation 306 loss=0.042099 error=0.008464 *\n",
      "downhill: Adam 3061 loss=0.042099 error=0.008464\n",
      "downhill: Adam 3062 loss=0.042077 error=0.008444\n",
      "downhill: Adam 3063 loss=0.042055 error=0.008424\n",
      "downhill: Adam 3064 loss=0.042034 error=0.008406\n",
      "downhill: Adam 3065 loss=0.042012 error=0.008386\n",
      "downhill: Adam 3066 loss=0.041991 error=0.008368\n",
      "downhill: Adam 3067 loss=0.041970 error=0.008348\n",
      "downhill: Adam 3068 loss=0.041948 error=0.008330\n",
      "downhill: Adam 3069 loss=0.041927 error=0.008311\n",
      "downhill: Adam 3070 loss=0.041906 error=0.008292\n",
      "downhill: validation 307 loss=0.041885 error=0.008274 *\n",
      "downhill: Adam 3071 loss=0.041885 error=0.008274\n",
      "downhill: Adam 3072 loss=0.041864 error=0.008254\n",
      "downhill: Adam 3073 loss=0.041842 error=0.008237\n",
      "downhill: Adam 3074 loss=0.041821 error=0.008217\n",
      "downhill: Adam 3075 loss=0.041801 error=0.008199\n",
      "downhill: Adam 3076 loss=0.041780 error=0.008181\n",
      "downhill: Adam 3077 loss=0.041759 error=0.008162\n",
      "downhill: Adam 3078 loss=0.041738 error=0.008144\n",
      "downhill: Adam 3079 loss=0.041717 error=0.008126\n",
      "downhill: Adam 3080 loss=0.041697 error=0.008108\n",
      "downhill: validation 308 loss=0.041676 error=0.008089\n",
      "downhill: Adam 3081 loss=0.041676 error=0.008089\n",
      "downhill: Adam 3082 loss=0.041655 error=0.008072\n",
      "downhill: Adam 3083 loss=0.041635 error=0.008053\n",
      "downhill: Adam 3084 loss=0.041614 error=0.008036\n",
      "downhill: Adam 3085 loss=0.041594 error=0.008018\n",
      "downhill: Adam 3086 loss=0.041573 error=0.008000\n",
      "downhill: Adam 3087 loss=0.041553 error=0.007982\n",
      "downhill: Adam 3088 loss=0.041533 error=0.007965\n",
      "downhill: Adam 3089 loss=0.041513 error=0.007947\n",
      "downhill: Adam 3090 loss=0.041492 error=0.007929\n",
      "downhill: validation 309 loss=0.041472 error=0.007912 *\n",
      "downhill: Adam 3091 loss=0.041472 error=0.007912\n",
      "downhill: Adam 3092 loss=0.041452 error=0.007894\n",
      "downhill: Adam 3093 loss=0.041432 error=0.007878\n",
      "downhill: Adam 3094 loss=0.041412 error=0.007859\n",
      "downhill: Adam 3095 loss=0.041392 error=0.007843\n",
      "downhill: Adam 3096 loss=0.041372 error=0.007825\n",
      "downhill: Adam 3097 loss=0.041353 error=0.007809\n",
      "downhill: Adam 3098 loss=0.041333 error=0.007790\n",
      "downhill: Adam 3099 loss=0.041313 error=0.007775\n",
      "downhill: Adam 3100 loss=0.041293 error=0.007756\n",
      "downhill: validation 310 loss=0.041274 error=0.007741\n",
      "downhill: Adam 3101 loss=0.041274 error=0.007741\n",
      "downhill: Adam 3102 loss=0.041254 error=0.007723\n",
      "downhill: Adam 3103 loss=0.041235 error=0.007707\n",
      "downhill: Adam 3104 loss=0.041215 error=0.007690\n",
      "downhill: Adam 3105 loss=0.041196 error=0.007673\n",
      "downhill: Adam 3106 loss=0.041176 error=0.007657\n",
      "downhill: Adam 3107 loss=0.041157 error=0.007640\n",
      "downhill: Adam 3108 loss=0.041138 error=0.007625\n",
      "downhill: Adam 3109 loss=0.041119 error=0.007607\n",
      "downhill: Adam 3110 loss=0.041100 error=0.007592\n",
      "downhill: validation 311 loss=0.041080 error=0.007574 *\n",
      "downhill: Adam 3111 loss=0.041080 error=0.007574\n",
      "downhill: Adam 3112 loss=0.041061 error=0.007559\n",
      "downhill: Adam 3113 loss=0.041042 error=0.007542\n",
      "downhill: Adam 3114 loss=0.041023 error=0.007527\n",
      "downhill: Adam 3115 loss=0.041005 error=0.007510\n",
      "downhill: Adam 3116 loss=0.040986 error=0.007494\n",
      "downhill: Adam 3117 loss=0.040967 error=0.007479\n",
      "downhill: Adam 3118 loss=0.040948 error=0.007462\n",
      "downhill: Adam 3119 loss=0.040929 error=0.007447\n",
      "downhill: Adam 3120 loss=0.040911 error=0.007431\n",
      "downhill: validation 312 loss=0.040892 error=0.007416\n",
      "downhill: Adam 3121 loss=0.040892 error=0.007416\n",
      "downhill: Adam 3122 loss=0.040874 error=0.007399\n",
      "downhill: Adam 3123 loss=0.040855 error=0.007385\n",
      "downhill: Adam 3124 loss=0.040837 error=0.007368\n",
      "downhill: Adam 3125 loss=0.040818 error=0.007354\n",
      "downhill: Adam 3126 loss=0.040800 error=0.007337\n",
      "downhill: Adam 3127 loss=0.040781 error=0.007323\n",
      "downhill: Adam 3128 loss=0.040763 error=0.007306\n",
      "downhill: Adam 3129 loss=0.040745 error=0.007293\n",
      "downhill: Adam 3130 loss=0.040727 error=0.007276\n",
      "downhill: validation 313 loss=0.040709 error=0.007262 *\n",
      "downhill: Adam 3131 loss=0.040709 error=0.007262\n",
      "downhill: Adam 3132 loss=0.040691 error=0.007246\n",
      "downhill: Adam 3133 loss=0.040673 error=0.007232\n",
      "downhill: Adam 3134 loss=0.040655 error=0.007217\n",
      "downhill: Adam 3135 loss=0.040637 error=0.007201\n",
      "downhill: Adam 3136 loss=0.040619 error=0.007188\n",
      "downhill: Adam 3137 loss=0.040601 error=0.007171\n",
      "downhill: Adam 3138 loss=0.040583 error=0.007158\n",
      "downhill: Adam 3139 loss=0.040565 error=0.007142\n",
      "downhill: Adam 3140 loss=0.040548 error=0.007129\n",
      "downhill: validation 314 loss=0.040530 error=0.007113\n",
      "downhill: Adam 3141 loss=0.040530 error=0.007113\n",
      "downhill: Adam 3142 loss=0.040512 error=0.007099\n",
      "downhill: Adam 3143 loss=0.040495 error=0.007085\n",
      "downhill: Adam 3144 loss=0.040477 error=0.007070\n",
      "downhill: Adam 3145 loss=0.040460 error=0.007056\n",
      "downhill: Adam 3146 loss=0.040442 error=0.007041\n",
      "downhill: Adam 3147 loss=0.040425 error=0.007028\n",
      "downhill: Adam 3148 loss=0.040407 error=0.007013\n",
      "downhill: Adam 3149 loss=0.040390 error=0.006999\n",
      "downhill: Adam 3150 loss=0.040373 error=0.006985\n",
      "downhill: validation 315 loss=0.040356 error=0.006971 *\n",
      "downhill: Adam 3151 loss=0.040356 error=0.006971\n",
      "downhill: Adam 3152 loss=0.040338 error=0.006957\n",
      "downhill: Adam 3153 loss=0.040321 error=0.006943\n",
      "downhill: Adam 3154 loss=0.040304 error=0.006929\n",
      "downhill: Adam 3155 loss=0.040287 error=0.006916\n",
      "downhill: Adam 3156 loss=0.040270 error=0.006902\n",
      "downhill: Adam 3157 loss=0.040253 error=0.006888\n",
      "downhill: Adam 3158 loss=0.040236 error=0.006874\n",
      "downhill: Adam 3159 loss=0.040219 error=0.006861\n",
      "downhill: Adam 3160 loss=0.040203 error=0.006847\n",
      "downhill: validation 316 loss=0.040186 error=0.006833\n",
      "downhill: Adam 3161 loss=0.040186 error=0.006833\n",
      "downhill: Adam 3162 loss=0.040169 error=0.006820\n",
      "downhill: Adam 3163 loss=0.040152 error=0.006806\n",
      "downhill: Adam 3164 loss=0.040136 error=0.006794\n",
      "downhill: Adam 3165 loss=0.040119 error=0.006779\n",
      "downhill: Adam 3166 loss=0.040103 error=0.006768\n",
      "downhill: Adam 3167 loss=0.040086 error=0.006753\n",
      "downhill: Adam 3168 loss=0.040070 error=0.006742\n",
      "downhill: Adam 3169 loss=0.040053 error=0.006726\n",
      "downhill: Adam 3170 loss=0.040037 error=0.006716\n",
      "downhill: validation 317 loss=0.040021 error=0.006700 *\n",
      "downhill: Adam 3171 loss=0.040021 error=0.006700\n",
      "downhill: Adam 3172 loss=0.040004 error=0.006689\n",
      "downhill: Adam 3173 loss=0.039988 error=0.006675\n",
      "downhill: Adam 3174 loss=0.039972 error=0.006662\n",
      "downhill: Adam 3175 loss=0.039956 error=0.006651\n",
      "downhill: Adam 3176 loss=0.039939 error=0.006636\n",
      "downhill: Adam 3177 loss=0.039923 error=0.006625\n",
      "downhill: Adam 3178 loss=0.039907 error=0.006611\n",
      "downhill: Adam 3179 loss=0.039891 error=0.006598\n",
      "downhill: Adam 3180 loss=0.039875 error=0.006587\n",
      "downhill: validation 318 loss=0.039859 error=0.006573\n",
      "downhill: Adam 3181 loss=0.039859 error=0.006573\n",
      "downhill: Adam 3182 loss=0.039844 error=0.006562\n",
      "downhill: Adam 3183 loss=0.039828 error=0.006549\n",
      "downhill: Adam 3184 loss=0.039812 error=0.006536\n",
      "downhill: Adam 3185 loss=0.039796 error=0.006524\n",
      "downhill: Adam 3186 loss=0.039781 error=0.006511\n",
      "downhill: Adam 3187 loss=0.039765 error=0.006500\n",
      "downhill: Adam 3188 loss=0.039749 error=0.006487\n",
      "downhill: Adam 3189 loss=0.039734 error=0.006475\n",
      "downhill: Adam 3190 loss=0.039718 error=0.006463\n",
      "downhill: validation 319 loss=0.039703 error=0.006450 *\n",
      "downhill: Adam 3191 loss=0.039703 error=0.006450\n",
      "downhill: Adam 3192 loss=0.039687 error=0.006439\n",
      "downhill: Adam 3193 loss=0.039672 error=0.006427\n",
      "downhill: Adam 3194 loss=0.039656 error=0.006415\n",
      "downhill: Adam 3195 loss=0.039641 error=0.006403\n",
      "downhill: Adam 3196 loss=0.039626 error=0.006391\n",
      "downhill: Adam 3197 loss=0.039610 error=0.006379\n",
      "downhill: Adam 3198 loss=0.039595 error=0.006367\n",
      "downhill: Adam 3199 loss=0.039580 error=0.006356\n",
      "downhill: Adam 3200 loss=0.039565 error=0.006344\n",
      "downhill: validation 320 loss=0.039550 error=0.006332\n",
      "downhill: Adam 3201 loss=0.039550 error=0.006332\n",
      "downhill: Adam 3202 loss=0.039535 error=0.006321\n",
      "downhill: Adam 3203 loss=0.039520 error=0.006309\n",
      "downhill: Adam 3204 loss=0.039505 error=0.006298\n",
      "downhill: Adam 3205 loss=0.039490 error=0.006286\n",
      "downhill: Adam 3206 loss=0.039475 error=0.006275\n",
      "downhill: Adam 3207 loss=0.039460 error=0.006263\n",
      "downhill: Adam 3208 loss=0.039445 error=0.006252\n",
      "downhill: Adam 3209 loss=0.039430 error=0.006241\n",
      "downhill: Adam 3210 loss=0.039416 error=0.006229\n",
      "downhill: validation 321 loss=0.039401 error=0.006218 *\n",
      "downhill: Adam 3211 loss=0.039401 error=0.006218\n",
      "downhill: Adam 3212 loss=0.039386 error=0.006207\n",
      "downhill: Adam 3213 loss=0.039372 error=0.006196\n",
      "downhill: Adam 3214 loss=0.039357 error=0.006185\n",
      "downhill: Adam 3215 loss=0.039342 error=0.006174\n",
      "downhill: Adam 3216 loss=0.039328 error=0.006163\n",
      "downhill: Adam 3217 loss=0.039313 error=0.006152\n",
      "downhill: Adam 3218 loss=0.039299 error=0.006140\n",
      "downhill: Adam 3219 loss=0.039284 error=0.006130\n",
      "downhill: Adam 3220 loss=0.039270 error=0.006118\n",
      "downhill: validation 322 loss=0.039256 error=0.006109\n",
      "downhill: Adam 3221 loss=0.039256 error=0.006109\n",
      "downhill: Adam 3222 loss=0.039241 error=0.006097\n",
      "downhill: Adam 3223 loss=0.039227 error=0.006087\n",
      "downhill: Adam 3224 loss=0.039213 error=0.006075\n",
      "downhill: Adam 3225 loss=0.039199 error=0.006066\n",
      "downhill: Adam 3226 loss=0.039185 error=0.006053\n",
      "downhill: Adam 3227 loss=0.039170 error=0.006045\n",
      "downhill: Adam 3228 loss=0.039156 error=0.006032\n",
      "downhill: Adam 3229 loss=0.039142 error=0.006024\n",
      "downhill: Adam 3230 loss=0.039128 error=0.006012\n",
      "downhill: validation 323 loss=0.039114 error=0.006001 *\n",
      "downhill: Adam 3231 loss=0.039114 error=0.006001\n",
      "downhill: Adam 3232 loss=0.039100 error=0.005992\n",
      "downhill: Adam 3233 loss=0.039086 error=0.005980\n",
      "downhill: Adam 3234 loss=0.039073 error=0.005972\n",
      "downhill: Adam 3235 loss=0.039059 error=0.005960\n",
      "downhill: Adam 3236 loss=0.039045 error=0.005950\n",
      "downhill: Adam 3237 loss=0.039031 error=0.005940\n",
      "downhill: Adam 3238 loss=0.039017 error=0.005929\n",
      "downhill: Adam 3239 loss=0.039004 error=0.005920\n",
      "downhill: Adam 3240 loss=0.038990 error=0.005909\n",
      "downhill: validation 324 loss=0.038976 error=0.005900\n",
      "downhill: Adam 3241 loss=0.038976 error=0.005900\n",
      "downhill: Adam 3242 loss=0.038963 error=0.005889\n",
      "downhill: Adam 3243 loss=0.038949 error=0.005879\n",
      "downhill: Adam 3244 loss=0.038936 error=0.005870\n",
      "downhill: Adam 3245 loss=0.038922 error=0.005859\n",
      "downhill: Adam 3246 loss=0.038909 error=0.005850\n",
      "downhill: Adam 3247 loss=0.038895 error=0.005839\n",
      "downhill: Adam 3248 loss=0.038882 error=0.005830\n",
      "downhill: Adam 3249 loss=0.038869 error=0.005820\n",
      "downhill: Adam 3250 loss=0.038855 error=0.005810\n",
      "downhill: validation 325 loss=0.038842 error=0.005801 *\n",
      "downhill: Adam 3251 loss=0.038842 error=0.005801\n",
      "downhill: Adam 3252 loss=0.038829 error=0.005791\n",
      "downhill: Adam 3253 loss=0.038816 error=0.005782\n",
      "downhill: Adam 3254 loss=0.038802 error=0.005772\n",
      "downhill: Adam 3255 loss=0.038789 error=0.005762\n",
      "downhill: Adam 3256 loss=0.038776 error=0.005753\n",
      "downhill: Adam 3257 loss=0.038763 error=0.005743\n",
      "downhill: Adam 3258 loss=0.038750 error=0.005734\n",
      "downhill: Adam 3259 loss=0.038737 error=0.005724\n",
      "downhill: Adam 3260 loss=0.038724 error=0.005715\n",
      "downhill: validation 326 loss=0.038711 error=0.005705\n",
      "downhill: Adam 3261 loss=0.038711 error=0.005705\n",
      "downhill: Adam 3262 loss=0.038698 error=0.005696\n",
      "downhill: Adam 3263 loss=0.038685 error=0.005687\n",
      "downhill: Adam 3264 loss=0.038673 error=0.005678\n",
      "downhill: Adam 3265 loss=0.038660 error=0.005668\n",
      "downhill: Adam 3266 loss=0.038647 error=0.005659\n",
      "downhill: Adam 3267 loss=0.038634 error=0.005650\n",
      "downhill: Adam 3268 loss=0.038622 error=0.005641\n",
      "downhill: Adam 3269 loss=0.038609 error=0.005632\n",
      "downhill: Adam 3270 loss=0.038596 error=0.005623\n",
      "downhill: validation 327 loss=0.038584 error=0.005614 *\n",
      "downhill: Adam 3271 loss=0.038584 error=0.005614\n",
      "downhill: Adam 3272 loss=0.038571 error=0.005604\n",
      "downhill: Adam 3273 loss=0.038558 error=0.005596\n",
      "downhill: Adam 3274 loss=0.038546 error=0.005587\n",
      "downhill: Adam 3275 loss=0.038533 error=0.005578\n",
      "downhill: Adam 3276 loss=0.038521 error=0.005569\n",
      "downhill: Adam 3277 loss=0.038509 error=0.005560\n",
      "downhill: Adam 3278 loss=0.038496 error=0.005552\n",
      "downhill: Adam 3279 loss=0.038484 error=0.005542\n",
      "downhill: Adam 3280 loss=0.038471 error=0.005534\n",
      "downhill: validation 328 loss=0.038459 error=0.005524\n",
      "downhill: Adam 3281 loss=0.038459 error=0.005524\n",
      "downhill: Adam 3282 loss=0.038447 error=0.005517\n",
      "downhill: Adam 3283 loss=0.038435 error=0.005506\n",
      "downhill: Adam 3284 loss=0.038422 error=0.005501\n",
      "downhill: Adam 3285 loss=0.038410 error=0.005488\n",
      "downhill: Adam 3286 loss=0.038398 error=0.005483\n",
      "downhill: Adam 3287 loss=0.038386 error=0.005473\n",
      "downhill: Adam 3288 loss=0.038374 error=0.005464\n",
      "downhill: Adam 3289 loss=0.038362 error=0.005457\n",
      "downhill: Adam 3290 loss=0.038350 error=0.005447\n",
      "downhill: validation 329 loss=0.038338 error=0.005439 *\n",
      "downhill: Adam 3291 loss=0.038338 error=0.005439\n",
      "downhill: Adam 3292 loss=0.038326 error=0.005432\n",
      "downhill: Adam 3293 loss=0.038314 error=0.005421\n",
      "downhill: Adam 3294 loss=0.038302 error=0.005415\n",
      "downhill: Adam 3295 loss=0.038290 error=0.005406\n",
      "downhill: Adam 3296 loss=0.038279 error=0.005397\n",
      "downhill: Adam 3297 loss=0.038267 error=0.005390\n",
      "downhill: Adam 3298 loss=0.038255 error=0.005381\n",
      "downhill: Adam 3299 loss=0.038243 error=0.005373\n",
      "downhill: Adam 3300 loss=0.038232 error=0.005365\n",
      "downhill: validation 330 loss=0.038220 error=0.005356\n",
      "downhill: Adam 3301 loss=0.038220 error=0.005356\n",
      "downhill: Adam 3302 loss=0.038208 error=0.005349\n",
      "downhill: Adam 3303 loss=0.038197 error=0.005340\n",
      "downhill: Adam 3304 loss=0.038185 error=0.005333\n",
      "downhill: Adam 3305 loss=0.038174 error=0.005325\n",
      "downhill: Adam 3306 loss=0.038162 error=0.005316\n",
      "downhill: Adam 3307 loss=0.038151 error=0.005309\n",
      "downhill: Adam 3308 loss=0.038139 error=0.005301\n",
      "downhill: Adam 3309 loss=0.038128 error=0.005293\n",
      "downhill: Adam 3310 loss=0.038116 error=0.005285\n",
      "downhill: validation 331 loss=0.038105 error=0.005277 *\n",
      "downhill: Adam 3311 loss=0.038105 error=0.005277\n",
      "downhill: Adam 3312 loss=0.038094 error=0.005270\n",
      "downhill: Adam 3313 loss=0.038083 error=0.005262\n",
      "downhill: Adam 3314 loss=0.038071 error=0.005254\n",
      "downhill: Adam 3315 loss=0.038060 error=0.005247\n",
      "downhill: Adam 3316 loss=0.038049 error=0.005239\n",
      "downhill: Adam 3317 loss=0.038038 error=0.005231\n",
      "downhill: Adam 3318 loss=0.038027 error=0.005224\n",
      "downhill: Adam 3319 loss=0.038015 error=0.005216\n",
      "downhill: Adam 3320 loss=0.038004 error=0.005209\n",
      "downhill: validation 332 loss=0.037993 error=0.005201\n",
      "downhill: Adam 3321 loss=0.037993 error=0.005201\n",
      "downhill: Adam 3322 loss=0.037982 error=0.005193\n",
      "downhill: Adam 3323 loss=0.037971 error=0.005186\n",
      "downhill: Adam 3324 loss=0.037960 error=0.005178\n",
      "downhill: Adam 3325 loss=0.037949 error=0.005171\n",
      "downhill: Adam 3326 loss=0.037938 error=0.005163\n",
      "downhill: Adam 3327 loss=0.037927 error=0.005156\n",
      "downhill: Adam 3328 loss=0.037917 error=0.005149\n",
      "downhill: Adam 3329 loss=0.037906 error=0.005142\n",
      "downhill: Adam 3330 loss=0.037895 error=0.005134\n",
      "downhill: validation 333 loss=0.037884 error=0.005127 *\n",
      "downhill: Adam 3331 loss=0.037884 error=0.005127\n",
      "downhill: Adam 3332 loss=0.037873 error=0.005120\n",
      "downhill: Adam 3333 loss=0.037863 error=0.005112\n",
      "downhill: Adam 3334 loss=0.037852 error=0.005106\n",
      "downhill: Adam 3335 loss=0.037841 error=0.005098\n",
      "downhill: Adam 3336 loss=0.037831 error=0.005091\n",
      "downhill: Adam 3337 loss=0.037820 error=0.005084\n",
      "downhill: Adam 3338 loss=0.037810 error=0.005077\n",
      "downhill: Adam 3339 loss=0.037799 error=0.005070\n",
      "downhill: Adam 3340 loss=0.037788 error=0.005063\n",
      "downhill: validation 334 loss=0.037778 error=0.005056\n",
      "downhill: Adam 3341 loss=0.037778 error=0.005056\n",
      "downhill: Adam 3342 loss=0.037767 error=0.005049\n",
      "downhill: Adam 3343 loss=0.037757 error=0.005042\n",
      "downhill: Adam 3344 loss=0.037747 error=0.005035\n",
      "downhill: Adam 3345 loss=0.037736 error=0.005029\n",
      "downhill: Adam 3346 loss=0.037726 error=0.005021\n",
      "downhill: Adam 3347 loss=0.037715 error=0.005015\n",
      "downhill: Adam 3348 loss=0.037705 error=0.005007\n",
      "downhill: Adam 3349 loss=0.037695 error=0.005002\n",
      "downhill: Adam 3350 loss=0.037685 error=0.004993\n",
      "downhill: validation 335 loss=0.037674 error=0.004989 *\n",
      "downhill: Adam 3351 loss=0.037674 error=0.004989\n",
      "downhill: Adam 3352 loss=0.037664 error=0.004980\n",
      "downhill: Adam 3353 loss=0.037654 error=0.004976\n",
      "downhill: Adam 3354 loss=0.037644 error=0.004966\n",
      "downhill: Adam 3355 loss=0.037634 error=0.004962\n",
      "downhill: Adam 3356 loss=0.037624 error=0.004953\n",
      "downhill: Adam 3357 loss=0.037613 error=0.004948\n",
      "downhill: Adam 3358 loss=0.037603 error=0.004941\n",
      "downhill: Adam 3359 loss=0.037593 error=0.004934\n",
      "downhill: Adam 3360 loss=0.037583 error=0.004929\n",
      "downhill: validation 336 loss=0.037573 error=0.004921\n",
      "downhill: Adam 3361 loss=0.037573 error=0.004921\n",
      "downhill: Adam 3362 loss=0.037563 error=0.004916\n",
      "downhill: Adam 3363 loss=0.037554 error=0.004908\n",
      "downhill: Adam 3364 loss=0.037544 error=0.004902\n",
      "downhill: Adam 3365 loss=0.037534 error=0.004896\n",
      "downhill: Adam 3366 loss=0.037524 error=0.004889\n",
      "downhill: Adam 3367 loss=0.037514 error=0.004884\n",
      "downhill: Adam 3368 loss=0.037504 error=0.004876\n",
      "downhill: Adam 3369 loss=0.037494 error=0.004870\n",
      "downhill: Adam 3370 loss=0.037485 error=0.004864\n",
      "downhill: validation 337 loss=0.037475 error=0.004857 *\n",
      "downhill: Adam 3371 loss=0.037475 error=0.004857\n",
      "downhill: Adam 3372 loss=0.037465 error=0.004852\n",
      "downhill: Adam 3373 loss=0.037456 error=0.004845\n",
      "downhill: Adam 3374 loss=0.037446 error=0.004839\n",
      "downhill: Adam 3375 loss=0.037436 error=0.004833\n",
      "downhill: Adam 3376 loss=0.037427 error=0.004826\n",
      "downhill: Adam 3377 loss=0.037417 error=0.004821\n",
      "downhill: Adam 3378 loss=0.037408 error=0.004814\n",
      "downhill: Adam 3379 loss=0.037398 error=0.004809\n",
      "downhill: Adam 3380 loss=0.037389 error=0.004801\n",
      "downhill: validation 338 loss=0.037379 error=0.004797\n",
      "downhill: Adam 3381 loss=0.037379 error=0.004797\n",
      "downhill: Adam 3382 loss=0.037370 error=0.004789\n",
      "downhill: Adam 3383 loss=0.037360 error=0.004784\n",
      "downhill: Adam 3384 loss=0.037351 error=0.004778\n",
      "downhill: Adam 3385 loss=0.037341 error=0.004772\n",
      "downhill: Adam 3386 loss=0.037332 error=0.004767\n",
      "downhill: Adam 3387 loss=0.037323 error=0.004760\n",
      "downhill: Adam 3388 loss=0.037313 error=0.004755\n",
      "downhill: Adam 3389 loss=0.037304 error=0.004748\n",
      "downhill: Adam 3390 loss=0.037295 error=0.004743\n",
      "downhill: validation 339 loss=0.037286 error=0.004736 *\n",
      "downhill: Adam 3391 loss=0.037286 error=0.004736\n",
      "downhill: Adam 3392 loss=0.037276 error=0.004731\n",
      "downhill: Adam 3393 loss=0.037267 error=0.004725\n",
      "downhill: Adam 3394 loss=0.037258 error=0.004720\n",
      "downhill: Adam 3395 loss=0.037249 error=0.004714\n",
      "downhill: Adam 3396 loss=0.037240 error=0.004708\n",
      "downhill: Adam 3397 loss=0.037231 error=0.004702\n",
      "downhill: Adam 3398 loss=0.037222 error=0.004696\n",
      "downhill: Adam 3399 loss=0.037213 error=0.004691\n",
      "downhill: Adam 3400 loss=0.037204 error=0.004685\n",
      "downhill: validation 340 loss=0.037195 error=0.004680\n",
      "downhill: Adam 3401 loss=0.037195 error=0.004680\n",
      "downhill: Adam 3402 loss=0.037186 error=0.004674\n",
      "downhill: Adam 3403 loss=0.037177 error=0.004669\n",
      "downhill: Adam 3404 loss=0.037168 error=0.004663\n",
      "downhill: Adam 3405 loss=0.037159 error=0.004658\n",
      "downhill: Adam 3406 loss=0.037150 error=0.004651\n",
      "downhill: Adam 3407 loss=0.037141 error=0.004647\n",
      "downhill: Adam 3408 loss=0.037132 error=0.004640\n",
      "downhill: Adam 3409 loss=0.037124 error=0.004637\n",
      "downhill: Adam 3410 loss=0.037115 error=0.004628\n",
      "downhill: validation 341 loss=0.037106 error=0.004626\n",
      "downhill: Adam 3411 loss=0.037106 error=0.004626\n",
      "downhill: Adam 3412 loss=0.037097 error=0.004618\n",
      "downhill: Adam 3413 loss=0.037089 error=0.004615\n",
      "downhill: Adam 3414 loss=0.037080 error=0.004608\n",
      "downhill: Adam 3415 loss=0.037071 error=0.004603\n",
      "downhill: Adam 3416 loss=0.037063 error=0.004598\n",
      "downhill: Adam 3417 loss=0.037054 error=0.004591\n",
      "downhill: Adam 3418 loss=0.037046 error=0.004588\n",
      "downhill: Adam 3419 loss=0.037037 error=0.004581\n",
      "downhill: Adam 3420 loss=0.037029 error=0.004577\n",
      "downhill: validation 342 loss=0.037020 error=0.004572 *\n",
      "downhill: Adam 3421 loss=0.037020 error=0.004572\n",
      "downhill: Adam 3422 loss=0.037012 error=0.004566\n",
      "downhill: Adam 3423 loss=0.037003 error=0.004562\n",
      "downhill: Adam 3424 loss=0.036995 error=0.004555\n",
      "downhill: Adam 3425 loss=0.036986 error=0.004551\n",
      "downhill: Adam 3426 loss=0.036978 error=0.004546\n",
      "downhill: Adam 3427 loss=0.036969 error=0.004540\n",
      "downhill: Adam 3428 loss=0.036961 error=0.004536\n",
      "downhill: Adam 3429 loss=0.036953 error=0.004530\n",
      "downhill: Adam 3430 loss=0.036944 error=0.004526\n",
      "downhill: validation 343 loss=0.036936 error=0.004521\n",
      "downhill: Adam 3431 loss=0.036936 error=0.004521\n",
      "downhill: Adam 3432 loss=0.036928 error=0.004515\n",
      "downhill: Adam 3433 loss=0.036920 error=0.004511\n",
      "downhill: Adam 3434 loss=0.036911 error=0.004505\n",
      "downhill: Adam 3435 loss=0.036903 error=0.004501\n",
      "downhill: Adam 3436 loss=0.036895 error=0.004496\n",
      "downhill: Adam 3437 loss=0.036887 error=0.004491\n",
      "downhill: Adam 3438 loss=0.036879 error=0.004487\n",
      "downhill: Adam 3439 loss=0.036871 error=0.004481\n",
      "downhill: Adam 3440 loss=0.036862 error=0.004477\n",
      "downhill: validation 344 loss=0.036854 error=0.004472\n",
      "downhill: Adam 3441 loss=0.036854 error=0.004472\n",
      "downhill: Adam 3442 loss=0.036846 error=0.004467\n",
      "downhill: Adam 3443 loss=0.036838 error=0.004462\n",
      "downhill: Adam 3444 loss=0.036830 error=0.004457\n",
      "downhill: Adam 3445 loss=0.036822 error=0.004453\n",
      "downhill: Adam 3446 loss=0.036814 error=0.004448\n",
      "downhill: Adam 3447 loss=0.036806 error=0.004444\n",
      "downhill: Adam 3448 loss=0.036798 error=0.004438\n",
      "downhill: Adam 3449 loss=0.036790 error=0.004434\n",
      "downhill: Adam 3450 loss=0.036783 error=0.004429\n",
      "downhill: validation 345 loss=0.036775 error=0.004425 *\n",
      "downhill: Adam 3451 loss=0.036775 error=0.004425\n",
      "downhill: Adam 3452 loss=0.036767 error=0.004420\n",
      "downhill: Adam 3453 loss=0.036759 error=0.004415\n",
      "downhill: Adam 3454 loss=0.036751 error=0.004411\n",
      "downhill: Adam 3455 loss=0.036743 error=0.004406\n",
      "downhill: Adam 3456 loss=0.036736 error=0.004402\n",
      "downhill: Adam 3457 loss=0.036728 error=0.004397\n",
      "downhill: Adam 3458 loss=0.036720 error=0.004393\n",
      "downhill: Adam 3459 loss=0.036712 error=0.004388\n",
      "downhill: Adam 3460 loss=0.036705 error=0.004384\n",
      "downhill: validation 346 loss=0.036697 error=0.004380\n",
      "downhill: Adam 3461 loss=0.036697 error=0.004380\n",
      "downhill: Adam 3462 loss=0.036689 error=0.004375\n",
      "downhill: Adam 3463 loss=0.036682 error=0.004371\n",
      "downhill: Adam 3464 loss=0.036674 error=0.004366\n",
      "downhill: Adam 3465 loss=0.036667 error=0.004362\n",
      "downhill: Adam 3466 loss=0.036659 error=0.004358\n",
      "downhill: Adam 3467 loss=0.036651 error=0.004354\n",
      "downhill: Adam 3468 loss=0.036644 error=0.004349\n",
      "downhill: Adam 3469 loss=0.036636 error=0.004345\n",
      "downhill: Adam 3470 loss=0.036629 error=0.004340\n",
      "downhill: validation 347 loss=0.036621 error=0.004337\n",
      "downhill: Adam 3471 loss=0.036621 error=0.004337\n",
      "downhill: Adam 3472 loss=0.036614 error=0.004330\n",
      "downhill: Adam 3473 loss=0.036607 error=0.004330\n",
      "downhill: Adam 3474 loss=0.036599 error=0.004322\n",
      "downhill: Adam 3475 loss=0.036592 error=0.004320\n",
      "downhill: Adam 3476 loss=0.036584 error=0.004315\n",
      "downhill: Adam 3477 loss=0.036577 error=0.004310\n",
      "downhill: Adam 3478 loss=0.036570 error=0.004308\n",
      "downhill: Adam 3479 loss=0.036562 error=0.004301\n",
      "downhill: Adam 3480 loss=0.036555 error=0.004299\n",
      "downhill: validation 348 loss=0.036548 error=0.004294 *\n",
      "downhill: Adam 3481 loss=0.036548 error=0.004294\n",
      "downhill: Adam 3482 loss=0.036540 error=0.004290\n",
      "downhill: Adam 3483 loss=0.036533 error=0.004287\n",
      "downhill: Adam 3484 loss=0.036526 error=0.004281\n",
      "downhill: Adam 3485 loss=0.036519 error=0.004278\n",
      "downhill: Adam 3486 loss=0.036512 error=0.004274\n",
      "downhill: Adam 3487 loss=0.036504 error=0.004270\n",
      "downhill: Adam 3488 loss=0.036497 error=0.004267\n",
      "downhill: Adam 3489 loss=0.036490 error=0.004262\n",
      "downhill: Adam 3490 loss=0.036483 error=0.004259\n",
      "downhill: validation 349 loss=0.036476 error=0.004254\n",
      "downhill: Adam 3491 loss=0.036476 error=0.004254\n",
      "downhill: Adam 3492 loss=0.036469 error=0.004250\n",
      "downhill: Adam 3493 loss=0.036462 error=0.004247\n",
      "downhill: Adam 3494 loss=0.036454 error=0.004242\n",
      "downhill: Adam 3495 loss=0.036447 error=0.004239\n",
      "downhill: Adam 3496 loss=0.036440 error=0.004235\n",
      "downhill: Adam 3497 loss=0.036433 error=0.004231\n",
      "downhill: Adam 3498 loss=0.036426 error=0.004227\n",
      "downhill: Adam 3499 loss=0.036419 error=0.004223\n",
      "downhill: Adam 3500 loss=0.036412 error=0.004220\n",
      "downhill: validation 350 loss=0.036405 error=0.004216\n",
      "downhill: Adam 3501 loss=0.036405 error=0.004216\n",
      "downhill: Adam 3502 loss=0.036399 error=0.004212\n",
      "downhill: Adam 3503 loss=0.036392 error=0.004208\n",
      "downhill: Adam 3504 loss=0.036385 error=0.004204\n",
      "downhill: Adam 3505 loss=0.036378 error=0.004201\n",
      "downhill: Adam 3506 loss=0.036371 error=0.004197\n",
      "downhill: Adam 3507 loss=0.036364 error=0.004194\n",
      "downhill: Adam 3508 loss=0.036357 error=0.004190\n",
      "downhill: Adam 3509 loss=0.036350 error=0.004186\n",
      "downhill: Adam 3510 loss=0.036344 error=0.004183\n",
      "downhill: validation 351 loss=0.036337 error=0.004179 *\n",
      "downhill: Adam 3511 loss=0.036337 error=0.004179\n",
      "downhill: Adam 3512 loss=0.036330 error=0.004176\n",
      "downhill: Adam 3513 loss=0.036323 error=0.004172\n",
      "downhill: Adam 3514 loss=0.036317 error=0.004168\n",
      "downhill: Adam 3515 loss=0.036310 error=0.004165\n",
      "downhill: Adam 3516 loss=0.036303 error=0.004161\n",
      "downhill: Adam 3517 loss=0.036296 error=0.004158\n",
      "downhill: Adam 3518 loss=0.036290 error=0.004154\n",
      "downhill: Adam 3519 loss=0.036283 error=0.004151\n",
      "downhill: Adam 3520 loss=0.036276 error=0.004147\n",
      "downhill: validation 352 loss=0.036270 error=0.004144\n",
      "downhill: Adam 3521 loss=0.036270 error=0.004144\n",
      "downhill: Adam 3522 loss=0.036263 error=0.004140\n",
      "downhill: Adam 3523 loss=0.036257 error=0.004138\n",
      "downhill: Adam 3524 loss=0.036250 error=0.004133\n",
      "downhill: Adam 3525 loss=0.036243 error=0.004131\n",
      "downhill: Adam 3526 loss=0.036237 error=0.004126\n",
      "downhill: Adam 3527 loss=0.036230 error=0.004124\n",
      "downhill: Adam 3528 loss=0.036224 error=0.004120\n",
      "downhill: Adam 3529 loss=0.036217 error=0.004117\n",
      "downhill: Adam 3530 loss=0.036211 error=0.004113\n",
      "downhill: validation 353 loss=0.036204 error=0.004110\n",
      "downhill: Adam 3531 loss=0.036204 error=0.004110\n",
      "downhill: Adam 3532 loss=0.036198 error=0.004107\n",
      "downhill: Adam 3533 loss=0.036191 error=0.004103\n",
      "downhill: Adam 3534 loss=0.036185 error=0.004100\n",
      "downhill: Adam 3535 loss=0.036179 error=0.004097\n",
      "downhill: Adam 3536 loss=0.036172 error=0.004094\n",
      "downhill: Adam 3537 loss=0.036166 error=0.004090\n",
      "downhill: Adam 3538 loss=0.036159 error=0.004088\n",
      "downhill: Adam 3539 loss=0.036153 error=0.004084\n",
      "downhill: Adam 3540 loss=0.036147 error=0.004081\n",
      "downhill: validation 354 loss=0.036140 error=0.004077 *\n",
      "downhill: Adam 3541 loss=0.036140 error=0.004077\n",
      "downhill: Adam 3542 loss=0.036134 error=0.004075\n",
      "downhill: Adam 3543 loss=0.036128 error=0.004070\n",
      "downhill: Adam 3544 loss=0.036121 error=0.004070\n",
      "downhill: Adam 3545 loss=0.036115 error=0.004063\n",
      "downhill: Adam 3546 loss=0.036109 error=0.004064\n",
      "downhill: Adam 3547 loss=0.036103 error=0.004057\n",
      "downhill: Adam 3548 loss=0.036096 error=0.004057\n",
      "downhill: Adam 3549 loss=0.036090 error=0.004052\n",
      "downhill: Adam 3550 loss=0.036084 error=0.004049\n",
      "downhill: validation 355 loss=0.036078 error=0.004047\n",
      "downhill: Adam 3551 loss=0.036078 error=0.004047\n",
      "downhill: Adam 3552 loss=0.036072 error=0.004042\n",
      "downhill: Adam 3553 loss=0.036066 error=0.004041\n",
      "downhill: Adam 3554 loss=0.036059 error=0.004037\n",
      "downhill: Adam 3555 loss=0.036053 error=0.004034\n",
      "downhill: Adam 3556 loss=0.036047 error=0.004032\n",
      "downhill: Adam 3557 loss=0.036041 error=0.004028\n",
      "downhill: Adam 3558 loss=0.036035 error=0.004026\n",
      "downhill: Adam 3559 loss=0.036029 error=0.004022\n",
      "downhill: Adam 3560 loss=0.036023 error=0.004019\n",
      "downhill: validation 356 loss=0.036017 error=0.004017\n",
      "downhill: Adam 3561 loss=0.036017 error=0.004017\n",
      "downhill: Adam 3562 loss=0.036011 error=0.004013\n",
      "downhill: Adam 3563 loss=0.036005 error=0.004011\n",
      "downhill: Adam 3564 loss=0.035999 error=0.004008\n",
      "downhill: Adam 3565 loss=0.035993 error=0.004005\n",
      "downhill: Adam 3566 loss=0.035987 error=0.004003\n",
      "downhill: Adam 3567 loss=0.035981 error=0.003999\n",
      "downhill: Adam 3568 loss=0.035975 error=0.003997\n",
      "downhill: Adam 3569 loss=0.035969 error=0.003994\n",
      "downhill: Adam 3570 loss=0.035963 error=0.003991\n",
      "downhill: validation 357 loss=0.035957 error=0.003988 *\n",
      "downhill: Adam 3571 loss=0.035957 error=0.003988\n",
      "downhill: Adam 3572 loss=0.035951 error=0.003985\n",
      "downhill: Adam 3573 loss=0.035945 error=0.003983\n",
      "downhill: Adam 3574 loss=0.035939 error=0.003980\n",
      "downhill: Adam 3575 loss=0.035933 error=0.003977\n",
      "downhill: Adam 3576 loss=0.035927 error=0.003975\n",
      "downhill: Adam 3577 loss=0.035922 error=0.003971\n",
      "downhill: Adam 3578 loss=0.035916 error=0.003969\n",
      "downhill: Adam 3579 loss=0.035910 error=0.003966\n",
      "downhill: Adam 3580 loss=0.035904 error=0.003963\n",
      "downhill: validation 358 loss=0.035898 error=0.003961\n",
      "downhill: Adam 3581 loss=0.035898 error=0.003961\n",
      "downhill: Adam 3582 loss=0.035893 error=0.003958\n",
      "downhill: Adam 3583 loss=0.035887 error=0.003956\n",
      "downhill: Adam 3584 loss=0.035881 error=0.003953\n",
      "downhill: Adam 3585 loss=0.035875 error=0.003950\n",
      "downhill: Adam 3586 loss=0.035869 error=0.003948\n",
      "downhill: Adam 3587 loss=0.035864 error=0.003945\n",
      "downhill: Adam 3588 loss=0.035858 error=0.003942\n",
      "downhill: Adam 3589 loss=0.035852 error=0.003940\n",
      "downhill: Adam 3590 loss=0.035847 error=0.003937\n",
      "downhill: validation 359 loss=0.035841 error=0.003935\n",
      "downhill: Adam 3591 loss=0.035841 error=0.003935\n",
      "downhill: Adam 3592 loss=0.035835 error=0.003932\n",
      "downhill: Adam 3593 loss=0.035830 error=0.003930\n",
      "downhill: Adam 3594 loss=0.035824 error=0.003926\n",
      "downhill: Adam 3595 loss=0.035818 error=0.003925\n",
      "downhill: Adam 3596 loss=0.035813 error=0.003922\n",
      "downhill: Adam 3597 loss=0.035807 error=0.003920\n",
      "downhill: Adam 3598 loss=0.035801 error=0.003917\n",
      "downhill: Adam 3599 loss=0.035796 error=0.003914\n",
      "downhill: Adam 3600 loss=0.035790 error=0.003913\n",
      "downhill: validation 360 loss=0.035784 error=0.003909\n",
      "downhill: Adam 3601 loss=0.035784 error=0.003909\n",
      "downhill: Adam 3602 loss=0.035779 error=0.003908\n",
      "downhill: Adam 3603 loss=0.035773 error=0.003905\n",
      "downhill: Adam 3604 loss=0.035768 error=0.003903\n",
      "downhill: Adam 3605 loss=0.035762 error=0.003900\n",
      "downhill: Adam 3606 loss=0.035757 error=0.003898\n",
      "downhill: Adam 3607 loss=0.035751 error=0.003895\n",
      "downhill: Adam 3608 loss=0.035745 error=0.003893\n",
      "downhill: Adam 3609 loss=0.035740 error=0.003890\n",
      "downhill: Adam 3610 loss=0.035734 error=0.003889\n",
      "downhill: validation 361 loss=0.035729 error=0.003885 *\n",
      "downhill: Adam 3611 loss=0.035729 error=0.003885\n",
      "downhill: Adam 3612 loss=0.035723 error=0.003885\n",
      "downhill: Adam 3613 loss=0.035718 error=0.003880\n",
      "downhill: Adam 3614 loss=0.035712 error=0.003880\n",
      "downhill: Adam 3615 loss=0.035707 error=0.003876\n",
      "downhill: Adam 3616 loss=0.035702 error=0.003875\n",
      "downhill: Adam 3617 loss=0.035696 error=0.003871\n",
      "downhill: Adam 3618 loss=0.035691 error=0.003871\n",
      "downhill: Adam 3619 loss=0.035685 error=0.003867\n",
      "downhill: Adam 3620 loss=0.035680 error=0.003865\n",
      "downhill: validation 362 loss=0.035674 error=0.003863\n",
      "downhill: Adam 3621 loss=0.035674 error=0.003863\n",
      "downhill: Adam 3622 loss=0.035669 error=0.003860\n",
      "downhill: Adam 3623 loss=0.035664 error=0.003859\n",
      "downhill: Adam 3624 loss=0.035658 error=0.003855\n",
      "downhill: Adam 3625 loss=0.035653 error=0.003855\n",
      "downhill: Adam 3626 loss=0.035647 error=0.003851\n",
      "downhill: Adam 3627 loss=0.035642 error=0.003850\n",
      "downhill: Adam 3628 loss=0.035637 error=0.003847\n",
      "downhill: Adam 3629 loss=0.035631 error=0.003845\n",
      "downhill: Adam 3630 loss=0.035626 error=0.003843\n",
      "downhill: validation 363 loss=0.035621 error=0.003841\n",
      "downhill: Adam 3631 loss=0.035621 error=0.003841\n",
      "downhill: Adam 3632 loss=0.035615 error=0.003839\n",
      "downhill: Adam 3633 loss=0.035610 error=0.003836\n",
      "downhill: Adam 3634 loss=0.035605 error=0.003835\n",
      "downhill: Adam 3635 loss=0.035599 error=0.003832\n",
      "downhill: Adam 3636 loss=0.035594 error=0.003830\n",
      "downhill: Adam 3637 loss=0.035589 error=0.003828\n",
      "downhill: Adam 3638 loss=0.035584 error=0.003826\n",
      "downhill: Adam 3639 loss=0.035578 error=0.003824\n",
      "downhill: Adam 3640 loss=0.035573 error=0.003822\n",
      "downhill: validation 364 loss=0.035568 error=0.003820\n",
      "downhill: Adam 3641 loss=0.035568 error=0.003820\n",
      "downhill: Adam 3642 loss=0.035563 error=0.003818\n",
      "downhill: Adam 3643 loss=0.035557 error=0.003816\n",
      "downhill: Adam 3644 loss=0.035552 error=0.003814\n",
      "downhill: Adam 3645 loss=0.035547 error=0.003811\n",
      "downhill: Adam 3646 loss=0.035542 error=0.003810\n",
      "downhill: Adam 3647 loss=0.035537 error=0.003807\n",
      "downhill: Adam 3648 loss=0.035531 error=0.003806\n",
      "downhill: Adam 3649 loss=0.035526 error=0.003803\n",
      "downhill: Adam 3650 loss=0.035521 error=0.003802\n",
      "downhill: validation 365 loss=0.035516 error=0.003799 *\n",
      "downhill: Adam 3651 loss=0.035516 error=0.003799\n",
      "downhill: Adam 3652 loss=0.035511 error=0.003798\n",
      "downhill: Adam 3653 loss=0.035506 error=0.003795\n",
      "downhill: Adam 3654 loss=0.035500 error=0.003794\n",
      "downhill: Adam 3655 loss=0.035495 error=0.003791\n",
      "downhill: Adam 3656 loss=0.035490 error=0.003790\n",
      "downhill: Adam 3657 loss=0.035485 error=0.003787\n",
      "downhill: Adam 3658 loss=0.035480 error=0.003786\n",
      "downhill: Adam 3659 loss=0.035475 error=0.003783\n",
      "downhill: Adam 3660 loss=0.035470 error=0.003783\n",
      "downhill: validation 366 loss=0.035465 error=0.003779\n",
      "downhill: Adam 3661 loss=0.035465 error=0.003779\n",
      "downhill: Adam 3662 loss=0.035460 error=0.003780\n",
      "downhill: Adam 3663 loss=0.035455 error=0.003774\n",
      "downhill: Adam 3664 loss=0.035450 error=0.003776\n",
      "downhill: Adam 3665 loss=0.035444 error=0.003771\n",
      "downhill: Adam 3666 loss=0.035439 error=0.003770\n",
      "downhill: Adam 3667 loss=0.035434 error=0.003769\n",
      "downhill: Adam 3668 loss=0.035429 error=0.003765\n",
      "downhill: Adam 3669 loss=0.035424 error=0.003766\n",
      "downhill: Adam 3670 loss=0.035419 error=0.003762\n",
      "downhill: validation 367 loss=0.035414 error=0.003760\n",
      "downhill: Adam 3671 loss=0.035414 error=0.003760\n",
      "downhill: Adam 3672 loss=0.035409 error=0.003760\n",
      "downhill: Adam 3673 loss=0.035404 error=0.003756\n",
      "downhill: Adam 3674 loss=0.035399 error=0.003755\n",
      "downhill: Adam 3675 loss=0.035394 error=0.003754\n",
      "downhill: Adam 3676 loss=0.035390 error=0.003751\n",
      "downhill: Adam 3677 loss=0.035385 error=0.003750\n",
      "downhill: Adam 3678 loss=0.035380 error=0.003748\n",
      "downhill: Adam 3679 loss=0.035375 error=0.003745\n",
      "downhill: Adam 3680 loss=0.035370 error=0.003745\n",
      "downhill: validation 368 loss=0.035365 error=0.003742\n",
      "downhill: Adam 3681 loss=0.035365 error=0.003742\n",
      "downhill: Adam 3682 loss=0.035360 error=0.003740\n",
      "downhill: Adam 3683 loss=0.035355 error=0.003739\n",
      "downhill: Adam 3684 loss=0.035350 error=0.003737\n",
      "downhill: Adam 3685 loss=0.035345 error=0.003735\n",
      "downhill: Adam 3686 loss=0.035340 error=0.003734\n",
      "downhill: Adam 3687 loss=0.035335 error=0.003732\n",
      "downhill: Adam 3688 loss=0.035331 error=0.003730\n",
      "downhill: Adam 3689 loss=0.035326 error=0.003728\n",
      "downhill: Adam 3690 loss=0.035321 error=0.003726\n",
      "downhill: validation 369 loss=0.035316 error=0.003725 *\n",
      "downhill: Adam 3691 loss=0.035316 error=0.003725\n",
      "downhill: Adam 3692 loss=0.035311 error=0.003723\n",
      "downhill: Adam 3693 loss=0.035306 error=0.003721\n",
      "downhill: Adam 3694 loss=0.035301 error=0.003720\n",
      "downhill: Adam 3695 loss=0.035297 error=0.003718\n",
      "downhill: Adam 3696 loss=0.035292 error=0.003716\n",
      "downhill: Adam 3697 loss=0.035287 error=0.003714\n",
      "downhill: Adam 3698 loss=0.035282 error=0.003713\n",
      "downhill: Adam 3699 loss=0.035277 error=0.003711\n",
      "downhill: Adam 3700 loss=0.035273 error=0.003709\n",
      "downhill: validation 370 loss=0.035268 error=0.003708\n",
      "downhill: Adam 3701 loss=0.035268 error=0.003708\n",
      "downhill: Adam 3702 loss=0.035263 error=0.003706\n",
      "downhill: Adam 3703 loss=0.035258 error=0.003704\n",
      "downhill: Adam 3704 loss=0.035254 error=0.003703\n",
      "downhill: Adam 3705 loss=0.035249 error=0.003701\n",
      "downhill: Adam 3706 loss=0.035244 error=0.003700\n",
      "downhill: Adam 3707 loss=0.035239 error=0.003698\n",
      "downhill: Adam 3708 loss=0.035235 error=0.003696\n",
      "downhill: Adam 3709 loss=0.035230 error=0.003694\n",
      "downhill: Adam 3710 loss=0.035225 error=0.003693\n",
      "downhill: validation 371 loss=0.035220 error=0.003691\n",
      "downhill: Adam 3711 loss=0.035220 error=0.003691\n",
      "downhill: Adam 3712 loss=0.035216 error=0.003690\n",
      "downhill: Adam 3713 loss=0.035211 error=0.003688\n",
      "downhill: Adam 3714 loss=0.035206 error=0.003686\n",
      "downhill: Adam 3715 loss=0.035202 error=0.003685\n",
      "downhill: Adam 3716 loss=0.035197 error=0.003683\n",
      "downhill: Adam 3717 loss=0.035192 error=0.003682\n",
      "downhill: Adam 3718 loss=0.035188 error=0.003680\n",
      "downhill: Adam 3719 loss=0.035183 error=0.003679\n",
      "downhill: Adam 3720 loss=0.035178 error=0.003677\n",
      "downhill: validation 372 loss=0.035174 error=0.003675\n",
      "downhill: Adam 3721 loss=0.035174 error=0.003675\n",
      "downhill: Adam 3722 loss=0.035169 error=0.003674\n",
      "downhill: Adam 3723 loss=0.035164 error=0.003672\n",
      "downhill: Adam 3724 loss=0.035160 error=0.003671\n",
      "downhill: Adam 3725 loss=0.035155 error=0.003669\n",
      "downhill: Adam 3726 loss=0.035151 error=0.003668\n",
      "downhill: Adam 3727 loss=0.035146 error=0.003666\n",
      "downhill: Adam 3728 loss=0.035141 error=0.003664\n",
      "downhill: Adam 3729 loss=0.035137 error=0.003663\n",
      "downhill: Adam 3730 loss=0.035132 error=0.003661\n",
      "downhill: validation 373 loss=0.035128 error=0.003660 *\n",
      "downhill: Adam 3731 loss=0.035128 error=0.003660\n",
      "downhill: Adam 3732 loss=0.035123 error=0.003658\n",
      "downhill: Adam 3733 loss=0.035118 error=0.003657\n",
      "downhill: Adam 3734 loss=0.035114 error=0.003655\n",
      "downhill: Adam 3735 loss=0.035109 error=0.003654\n",
      "downhill: Adam 3736 loss=0.035105 error=0.003652\n",
      "downhill: Adam 3737 loss=0.035100 error=0.003651\n",
      "downhill: Adam 3738 loss=0.035096 error=0.003649\n",
      "downhill: Adam 3739 loss=0.035091 error=0.003648\n",
      "downhill: Adam 3740 loss=0.035086 error=0.003646\n",
      "downhill: validation 374 loss=0.035082 error=0.003645\n",
      "downhill: Adam 3741 loss=0.035082 error=0.003645\n",
      "downhill: Adam 3742 loss=0.035077 error=0.003643\n",
      "downhill: Adam 3743 loss=0.035073 error=0.003642\n",
      "downhill: Adam 3744 loss=0.035068 error=0.003640\n",
      "downhill: Adam 3745 loss=0.035064 error=0.003639\n",
      "downhill: Adam 3746 loss=0.035059 error=0.003637\n",
      "downhill: Adam 3747 loss=0.035055 error=0.003636\n",
      "downhill: Adam 3748 loss=0.035050 error=0.003635\n",
      "downhill: Adam 3749 loss=0.035046 error=0.003633\n",
      "downhill: Adam 3750 loss=0.035041 error=0.003632\n",
      "downhill: validation 375 loss=0.035037 error=0.003631\n",
      "downhill: Adam 3751 loss=0.035037 error=0.003631\n",
      "downhill: Adam 3752 loss=0.035032 error=0.003629\n",
      "downhill: Adam 3753 loss=0.035028 error=0.003628\n",
      "downhill: Adam 3754 loss=0.035023 error=0.003625\n",
      "downhill: Adam 3755 loss=0.035019 error=0.003626\n",
      "downhill: Adam 3756 loss=0.035015 error=0.003622\n",
      "downhill: Adam 3757 loss=0.035010 error=0.003624\n",
      "downhill: Adam 3758 loss=0.035006 error=0.003619\n",
      "downhill: Adam 3759 loss=0.035001 error=0.003621\n",
      "downhill: Adam 3760 loss=0.034997 error=0.003617\n",
      "downhill: validation 376 loss=0.034992 error=0.003616\n",
      "downhill: Adam 3761 loss=0.034992 error=0.003616\n",
      "downhill: Adam 3762 loss=0.034988 error=0.003615\n",
      "downhill: Adam 3763 loss=0.034984 error=0.003612\n",
      "downhill: Adam 3764 loss=0.034979 error=0.003613\n",
      "downhill: Adam 3765 loss=0.034975 error=0.003610\n",
      "downhill: Adam 3766 loss=0.034970 error=0.003609\n",
      "downhill: Adam 3767 loss=0.034966 error=0.003608\n",
      "downhill: Adam 3768 loss=0.034962 error=0.003605\n",
      "downhill: Adam 3769 loss=0.034957 error=0.003606\n",
      "downhill: Adam 3770 loss=0.034953 error=0.003603\n",
      "downhill: validation 377 loss=0.034949 error=0.003602 *\n",
      "downhill: Adam 3771 loss=0.034949 error=0.003602\n",
      "downhill: Adam 3772 loss=0.034944 error=0.003601\n",
      "downhill: Adam 3773 loss=0.034940 error=0.003599\n",
      "downhill: Adam 3774 loss=0.034936 error=0.003598\n",
      "downhill: Adam 3775 loss=0.034931 error=0.003597\n",
      "downhill: Adam 3776 loss=0.034927 error=0.003595\n",
      "downhill: Adam 3777 loss=0.034923 error=0.003594\n",
      "downhill: Adam 3778 loss=0.034918 error=0.003592\n",
      "downhill: Adam 3779 loss=0.034914 error=0.003591\n",
      "downhill: Adam 3780 loss=0.034910 error=0.003590\n",
      "downhill: validation 378 loss=0.034905 error=0.003588\n",
      "downhill: Adam 3781 loss=0.034905 error=0.003588\n",
      "downhill: Adam 3782 loss=0.034901 error=0.003587\n",
      "downhill: Adam 3783 loss=0.034897 error=0.003586\n",
      "downhill: Adam 3784 loss=0.034892 error=0.003585\n",
      "downhill: Adam 3785 loss=0.034888 error=0.003583\n",
      "downhill: Adam 3786 loss=0.034884 error=0.003582\n",
      "downhill: Adam 3787 loss=0.034879 error=0.003581\n",
      "downhill: Adam 3788 loss=0.034875 error=0.003579\n",
      "downhill: Adam 3789 loss=0.034871 error=0.003578\n",
      "downhill: Adam 3790 loss=0.034867 error=0.003576\n",
      "downhill: validation 379 loss=0.034862 error=0.003575\n",
      "downhill: Adam 3791 loss=0.034862 error=0.003575\n",
      "downhill: Adam 3792 loss=0.034858 error=0.003574\n",
      "downhill: Adam 3793 loss=0.034854 error=0.003573\n",
      "downhill: Adam 3794 loss=0.034849 error=0.003571\n",
      "downhill: Adam 3795 loss=0.034845 error=0.003570\n",
      "downhill: Adam 3796 loss=0.034841 error=0.003569\n",
      "downhill: Adam 3797 loss=0.034837 error=0.003567\n",
      "downhill: Adam 3798 loss=0.034832 error=0.003566\n",
      "downhill: Adam 3799 loss=0.034828 error=0.003565\n",
      "downhill: Adam 3800 loss=0.034824 error=0.003563\n",
      "downhill: validation 380 loss=0.034820 error=0.003562\n",
      "downhill: Adam 3801 loss=0.034820 error=0.003562\n",
      "downhill: Adam 3802 loss=0.034816 error=0.003560\n",
      "downhill: Adam 3803 loss=0.034811 error=0.003559\n",
      "downhill: Adam 3804 loss=0.034807 error=0.003557\n",
      "downhill: Adam 3805 loss=0.034803 error=0.003557\n",
      "downhill: Adam 3806 loss=0.034799 error=0.003555\n",
      "downhill: Adam 3807 loss=0.034794 error=0.003555\n",
      "downhill: Adam 3808 loss=0.034790 error=0.003552\n",
      "downhill: Adam 3809 loss=0.034786 error=0.003552\n",
      "downhill: Adam 3810 loss=0.034782 error=0.003549\n",
      "downhill: validation 381 loss=0.034778 error=0.003549\n",
      "downhill: Adam 3811 loss=0.034778 error=0.003549\n",
      "downhill: Adam 3812 loss=0.034773 error=0.003547\n",
      "downhill: Adam 3813 loss=0.034769 error=0.003546\n",
      "downhill: Adam 3814 loss=0.034765 error=0.003544\n",
      "downhill: Adam 3815 loss=0.034761 error=0.003543\n",
      "downhill: Adam 3816 loss=0.034757 error=0.003542\n",
      "downhill: Adam 3817 loss=0.034753 error=0.003540\n",
      "downhill: Adam 3818 loss=0.034749 error=0.003539\n",
      "downhill: Adam 3819 loss=0.034744 error=0.003537\n",
      "downhill: Adam 3820 loss=0.034740 error=0.003537\n",
      "downhill: validation 382 loss=0.034736 error=0.003534 *\n",
      "downhill: Adam 3821 loss=0.034736 error=0.003534\n",
      "downhill: Adam 3822 loss=0.034732 error=0.003534\n",
      "downhill: Adam 3823 loss=0.034728 error=0.003532\n",
      "downhill: Adam 3824 loss=0.034724 error=0.003531\n",
      "downhill: Adam 3825 loss=0.034720 error=0.003530\n",
      "downhill: Adam 3826 loss=0.034716 error=0.003527\n",
      "downhill: Adam 3827 loss=0.034712 error=0.003527\n",
      "downhill: Adam 3828 loss=0.034707 error=0.003525\n",
      "downhill: Adam 3829 loss=0.034703 error=0.003524\n",
      "downhill: Adam 3830 loss=0.034699 error=0.003522\n",
      "downhill: validation 383 loss=0.034695 error=0.003521\n",
      "downhill: Adam 3831 loss=0.034695 error=0.003521\n",
      "downhill: Adam 3832 loss=0.034691 error=0.003520\n",
      "downhill: Adam 3833 loss=0.034687 error=0.003519\n",
      "downhill: Adam 3834 loss=0.034683 error=0.003517\n",
      "downhill: Adam 3835 loss=0.034679 error=0.003516\n",
      "downhill: Adam 3836 loss=0.034675 error=0.003514\n",
      "downhill: Adam 3837 loss=0.034671 error=0.003513\n",
      "downhill: Adam 3838 loss=0.034667 error=0.003512\n",
      "downhill: Adam 3839 loss=0.034663 error=0.003511\n",
      "downhill: Adam 3840 loss=0.034659 error=0.003509\n",
      "downhill: validation 384 loss=0.034655 error=0.003508\n",
      "downhill: Adam 3841 loss=0.034655 error=0.003508\n",
      "downhill: Adam 3842 loss=0.034651 error=0.003506\n",
      "downhill: Adam 3843 loss=0.034647 error=0.003505\n",
      "downhill: Adam 3844 loss=0.034643 error=0.003504\n",
      "downhill: Adam 3845 loss=0.034639 error=0.003503\n",
      "downhill: Adam 3846 loss=0.034635 error=0.003501\n",
      "downhill: Adam 3847 loss=0.034631 error=0.003501\n",
      "downhill: Adam 3848 loss=0.034627 error=0.003498\n",
      "downhill: Adam 3849 loss=0.034623 error=0.003498\n",
      "downhill: Adam 3850 loss=0.034619 error=0.003495\n",
      "downhill: validation 385 loss=0.034615 error=0.003496\n",
      "downhill: Adam 3851 loss=0.034615 error=0.003496\n",
      "downhill: Adam 3852 loss=0.034611 error=0.003492\n",
      "downhill: Adam 3853 loss=0.034608 error=0.003492\n",
      "downhill: Adam 3854 loss=0.034604 error=0.003491\n",
      "downhill: Adam 3855 loss=0.034600 error=0.003489\n",
      "downhill: Adam 3856 loss=0.034596 error=0.003488\n",
      "downhill: Adam 3857 loss=0.034592 error=0.003486\n",
      "downhill: Adam 3858 loss=0.034588 error=0.003486\n",
      "downhill: Adam 3859 loss=0.034584 error=0.003483\n",
      "downhill: Adam 3860 loss=0.034580 error=0.003483\n",
      "downhill: validation 386 loss=0.034576 error=0.003481\n",
      "downhill: Adam 3861 loss=0.034576 error=0.003481\n",
      "downhill: Adam 3862 loss=0.034572 error=0.003479\n",
      "downhill: Adam 3863 loss=0.034569 error=0.003479\n",
      "downhill: Adam 3864 loss=0.034565 error=0.003477\n",
      "downhill: Adam 3865 loss=0.034561 error=0.003476\n",
      "downhill: Adam 3866 loss=0.034557 error=0.003475\n",
      "downhill: Adam 3867 loss=0.034553 error=0.003473\n",
      "downhill: Adam 3868 loss=0.034549 error=0.003473\n",
      "downhill: Adam 3869 loss=0.034545 error=0.003470\n",
      "downhill: Adam 3870 loss=0.034542 error=0.003470\n",
      "downhill: validation 387 loss=0.034538 error=0.003468 *\n",
      "downhill: Adam 3871 loss=0.034538 error=0.003468\n",
      "downhill: Adam 3872 loss=0.034534 error=0.003467\n",
      "downhill: Adam 3873 loss=0.034530 error=0.003466\n",
      "downhill: Adam 3874 loss=0.034526 error=0.003464\n",
      "downhill: Adam 3875 loss=0.034523 error=0.003463\n",
      "downhill: Adam 3876 loss=0.034519 error=0.003462\n",
      "downhill: Adam 3877 loss=0.034515 error=0.003460\n",
      "downhill: Adam 3878 loss=0.034511 error=0.003459\n",
      "downhill: Adam 3879 loss=0.034507 error=0.003458\n",
      "downhill: Adam 3880 loss=0.034504 error=0.003456\n",
      "downhill: validation 388 loss=0.034500 error=0.003455\n",
      "downhill: Adam 3881 loss=0.034500 error=0.003455\n",
      "downhill: Adam 3882 loss=0.034496 error=0.003454\n",
      "downhill: Adam 3883 loss=0.034492 error=0.003453\n",
      "downhill: Adam 3884 loss=0.034488 error=0.003452\n",
      "downhill: Adam 3885 loss=0.034485 error=0.003450\n",
      "downhill: Adam 3886 loss=0.034481 error=0.003449\n",
      "downhill: Adam 3887 loss=0.034477 error=0.003448\n",
      "downhill: Adam 3888 loss=0.034473 error=0.003446\n",
      "downhill: Adam 3889 loss=0.034470 error=0.003445\n",
      "downhill: Adam 3890 loss=0.034466 error=0.003444\n",
      "downhill: validation 389 loss=0.034462 error=0.003443\n",
      "downhill: Adam 3891 loss=0.034462 error=0.003443\n",
      "downhill: Adam 3892 loss=0.034458 error=0.003441\n",
      "downhill: Adam 3893 loss=0.034455 error=0.003440\n",
      "downhill: Adam 3894 loss=0.034451 error=0.003439\n",
      "downhill: Adam 3895 loss=0.034447 error=0.003437\n",
      "downhill: Adam 3896 loss=0.034443 error=0.003436\n",
      "downhill: Adam 3897 loss=0.034440 error=0.003435\n",
      "downhill: Adam 3898 loss=0.034436 error=0.003434\n",
      "downhill: Adam 3899 loss=0.034432 error=0.003432\n",
      "downhill: Adam 3900 loss=0.034429 error=0.003431\n",
      "downhill: validation 390 loss=0.034425 error=0.003429\n",
      "downhill: Adam 3901 loss=0.034425 error=0.003429\n",
      "downhill: Adam 3902 loss=0.034421 error=0.003429\n",
      "downhill: Adam 3903 loss=0.034418 error=0.003426\n",
      "downhill: Adam 3904 loss=0.034414 error=0.003426\n",
      "downhill: Adam 3905 loss=0.034410 error=0.003423\n",
      "downhill: Adam 3906 loss=0.034406 error=0.003424\n",
      "downhill: Adam 3907 loss=0.034403 error=0.003420\n",
      "downhill: Adam 3908 loss=0.034399 error=0.003422\n",
      "downhill: Adam 3909 loss=0.034395 error=0.003418\n",
      "downhill: Adam 3910 loss=0.034392 error=0.003418\n",
      "downhill: validation 391 loss=0.034388 error=0.003417\n",
      "downhill: Adam 3911 loss=0.034388 error=0.003417\n",
      "downhill: Adam 3912 loss=0.034384 error=0.003414\n",
      "downhill: Adam 3913 loss=0.034381 error=0.003414\n",
      "downhill: Adam 3914 loss=0.034377 error=0.003412\n",
      "downhill: Adam 3915 loss=0.034374 error=0.003411\n",
      "downhill: Adam 3916 loss=0.034370 error=0.003410\n",
      "downhill: Adam 3917 loss=0.034366 error=0.003408\n",
      "downhill: Adam 3918 loss=0.034363 error=0.003407\n",
      "downhill: Adam 3919 loss=0.034359 error=0.003406\n",
      "downhill: Adam 3920 loss=0.034355 error=0.003405\n",
      "downhill: validation 392 loss=0.034352 error=0.003403 *\n",
      "downhill: Adam 3921 loss=0.034352 error=0.003403\n",
      "downhill: Adam 3922 loss=0.034348 error=0.003402\n",
      "downhill: Adam 3923 loss=0.034345 error=0.003401\n",
      "downhill: Adam 3924 loss=0.034341 error=0.003399\n",
      "downhill: Adam 3925 loss=0.034337 error=0.003398\n",
      "downhill: Adam 3926 loss=0.034334 error=0.003397\n",
      "downhill: Adam 3927 loss=0.034330 error=0.003395\n",
      "downhill: Adam 3928 loss=0.034327 error=0.003394\n",
      "downhill: Adam 3929 loss=0.034323 error=0.003393\n",
      "downhill: Adam 3930 loss=0.034319 error=0.003392\n",
      "downhill: validation 393 loss=0.034316 error=0.003390\n",
      "downhill: Adam 3931 loss=0.034316 error=0.003390\n",
      "downhill: Adam 3932 loss=0.034312 error=0.003389\n",
      "downhill: Adam 3933 loss=0.034309 error=0.003387\n",
      "downhill: Adam 3934 loss=0.034305 error=0.003386\n",
      "downhill: Adam 3935 loss=0.034302 error=0.003385\n",
      "downhill: Adam 3936 loss=0.034298 error=0.003383\n",
      "downhill: Adam 3937 loss=0.034294 error=0.003382\n",
      "downhill: Adam 3938 loss=0.034291 error=0.003381\n",
      "downhill: Adam 3939 loss=0.034287 error=0.003380\n",
      "downhill: Adam 3940 loss=0.034284 error=0.003378\n",
      "downhill: validation 394 loss=0.034280 error=0.003377\n",
      "downhill: Adam 3941 loss=0.034280 error=0.003377\n",
      "downhill: Adam 3942 loss=0.034277 error=0.003376\n",
      "downhill: Adam 3943 loss=0.034273 error=0.003374\n",
      "downhill: Adam 3944 loss=0.034270 error=0.003373\n",
      "downhill: Adam 3945 loss=0.034266 error=0.003372\n",
      "downhill: Adam 3946 loss=0.034263 error=0.003371\n",
      "downhill: Adam 3947 loss=0.034259 error=0.003369\n",
      "downhill: Adam 3948 loss=0.034256 error=0.003368\n",
      "downhill: Adam 3949 loss=0.034252 error=0.003366\n",
      "downhill: Adam 3950 loss=0.034249 error=0.003365\n",
      "downhill: validation 395 loss=0.034245 error=0.003364\n",
      "downhill: Adam 3951 loss=0.034245 error=0.003364\n",
      "downhill: Adam 3952 loss=0.034242 error=0.003363\n",
      "downhill: Adam 3953 loss=0.034238 error=0.003361\n",
      "downhill: Adam 3954 loss=0.034235 error=0.003360\n",
      "downhill: Adam 3955 loss=0.034231 error=0.003358\n",
      "downhill: Adam 3956 loss=0.034228 error=0.003357\n",
      "downhill: Adam 3957 loss=0.034224 error=0.003355\n",
      "downhill: Adam 3958 loss=0.034221 error=0.003355\n",
      "downhill: Adam 3959 loss=0.034217 error=0.003353\n",
      "downhill: Adam 3960 loss=0.034214 error=0.003353\n",
      "downhill: validation 396 loss=0.034210 error=0.003350\n",
      "downhill: Adam 3961 loss=0.034210 error=0.003350\n",
      "downhill: Adam 3962 loss=0.034207 error=0.003350\n",
      "downhill: Adam 3963 loss=0.034203 error=0.003347\n",
      "downhill: Adam 3964 loss=0.034200 error=0.003347\n",
      "downhill: Adam 3965 loss=0.034196 error=0.003345\n",
      "downhill: Adam 3966 loss=0.034193 error=0.003344\n",
      "downhill: Adam 3967 loss=0.034190 error=0.003343\n",
      "downhill: Adam 3968 loss=0.034186 error=0.003340\n",
      "downhill: Adam 3969 loss=0.034183 error=0.003340\n",
      "downhill: Adam 3970 loss=0.034179 error=0.003338\n",
      "downhill: validation 397 loss=0.034176 error=0.003337 *\n",
      "downhill: Adam 3971 loss=0.034176 error=0.003337\n",
      "downhill: Adam 3972 loss=0.034172 error=0.003336\n",
      "downhill: Adam 3973 loss=0.034169 error=0.003334\n",
      "downhill: Adam 3974 loss=0.034165 error=0.003333\n",
      "downhill: Adam 3975 loss=0.034162 error=0.003331\n",
      "downhill: Adam 3976 loss=0.034159 error=0.003330\n",
      "downhill: Adam 3977 loss=0.034155 error=0.003329\n",
      "downhill: Adam 3978 loss=0.034152 error=0.003327\n",
      "downhill: Adam 3979 loss=0.034148 error=0.003327\n",
      "downhill: Adam 3980 loss=0.034145 error=0.003324\n",
      "downhill: validation 398 loss=0.034142 error=0.003324\n",
      "downhill: Adam 3981 loss=0.034142 error=0.003324\n",
      "downhill: Adam 3982 loss=0.034138 error=0.003322\n",
      "downhill: Adam 3983 loss=0.034135 error=0.003320\n",
      "downhill: Adam 3984 loss=0.034131 error=0.003320\n",
      "downhill: Adam 3985 loss=0.034128 error=0.003317\n",
      "downhill: Adam 3986 loss=0.034125 error=0.003317\n",
      "downhill: Adam 3987 loss=0.034121 error=0.003315\n",
      "downhill: Adam 3988 loss=0.034118 error=0.003314\n",
      "downhill: Adam 3989 loss=0.034114 error=0.003312\n",
      "downhill: Adam 3990 loss=0.034111 error=0.003311\n",
      "downhill: validation 399 loss=0.034108 error=0.003310\n",
      "downhill: Adam 3991 loss=0.034108 error=0.003310\n",
      "downhill: Adam 3992 loss=0.034104 error=0.003308\n",
      "downhill: Adam 3993 loss=0.034101 error=0.003307\n",
      "downhill: Adam 3994 loss=0.034098 error=0.003305\n",
      "downhill: Adam 3995 loss=0.034094 error=0.003304\n",
      "downhill: Adam 3996 loss=0.034091 error=0.003303\n",
      "downhill: Adam 3997 loss=0.034088 error=0.003301\n",
      "downhill: Adam 3998 loss=0.034084 error=0.003300\n",
      "downhill: Adam 3999 loss=0.034081 error=0.003297\n",
      "downhill: Adam 4000 loss=0.034078 error=0.003298\n",
      "downhill: validation 400 loss=0.034074 error=0.003294\n",
      "downhill: Adam 4001 loss=0.034074 error=0.003294\n",
      "downhill: Adam 4002 loss=0.034071 error=0.003295\n",
      "downhill: Adam 4003 loss=0.034068 error=0.003292\n",
      "downhill: Adam 4004 loss=0.034064 error=0.003291\n",
      "downhill: Adam 4005 loss=0.034061 error=0.003289\n",
      "downhill: Adam 4006 loss=0.034058 error=0.003288\n",
      "downhill: Adam 4007 loss=0.034054 error=0.003287\n",
      "downhill: Adam 4008 loss=0.034051 error=0.003285\n",
      "downhill: Adam 4009 loss=0.034048 error=0.003283\n",
      "downhill: Adam 4010 loss=0.034044 error=0.003282\n",
      "downhill: validation 401 loss=0.034041 error=0.003281\n",
      "downhill: Adam 4011 loss=0.034041 error=0.003281\n",
      "downhill: Adam 4012 loss=0.034038 error=0.003279\n",
      "downhill: Adam 4013 loss=0.034034 error=0.003278\n",
      "downhill: Adam 4014 loss=0.034031 error=0.003276\n",
      "downhill: Adam 4015 loss=0.034028 error=0.003275\n",
      "downhill: Adam 4016 loss=0.034024 error=0.003273\n",
      "downhill: Adam 4017 loss=0.034021 error=0.003272\n",
      "downhill: Adam 4018 loss=0.034018 error=0.003270\n",
      "downhill: Adam 4019 loss=0.034014 error=0.003268\n",
      "downhill: Adam 4020 loss=0.034011 error=0.003267\n",
      "downhill: validation 402 loss=0.034008 error=0.003265\n",
      "downhill: Adam 4021 loss=0.034008 error=0.003265\n",
      "downhill: Adam 4022 loss=0.034004 error=0.003264\n",
      "downhill: Adam 4023 loss=0.034001 error=0.003263\n",
      "downhill: Adam 4024 loss=0.033998 error=0.003261\n",
      "downhill: Adam 4025 loss=0.033995 error=0.003260\n",
      "downhill: Adam 4026 loss=0.033991 error=0.003258\n",
      "downhill: Adam 4027 loss=0.033988 error=0.003257\n",
      "downhill: Adam 4028 loss=0.033985 error=0.003255\n",
      "downhill: Adam 4029 loss=0.033981 error=0.003253\n",
      "downhill: Adam 4030 loss=0.033978 error=0.003252\n",
      "downhill: validation 403 loss=0.033975 error=0.003250 *\n",
      "downhill: Adam 4031 loss=0.033975 error=0.003250\n",
      "downhill: Adam 4032 loss=0.033971 error=0.003249\n",
      "downhill: Adam 4033 loss=0.033968 error=0.003246\n",
      "downhill: Adam 4034 loss=0.033965 error=0.003246\n",
      "downhill: Adam 4035 loss=0.033962 error=0.003243\n",
      "downhill: Adam 4036 loss=0.033958 error=0.003244\n",
      "downhill: Adam 4037 loss=0.033955 error=0.003239\n",
      "downhill: Adam 4038 loss=0.033952 error=0.003240\n",
      "downhill: Adam 4039 loss=0.033949 error=0.003237\n",
      "downhill: Adam 4040 loss=0.033945 error=0.003236\n",
      "downhill: validation 404 loss=0.033942 error=0.003235\n",
      "downhill: Adam 4041 loss=0.033942 error=0.003235\n",
      "downhill: Adam 4042 loss=0.033939 error=0.003232\n",
      "downhill: Adam 4043 loss=0.033936 error=0.003232\n",
      "downhill: Adam 4044 loss=0.033932 error=0.003229\n",
      "downhill: Adam 4045 loss=0.033929 error=0.003228\n",
      "downhill: Adam 4046 loss=0.033926 error=0.003227\n",
      "downhill: Adam 4047 loss=0.033922 error=0.003224\n",
      "downhill: Adam 4048 loss=0.033919 error=0.003223\n",
      "downhill: Adam 4049 loss=0.033916 error=0.003221\n",
      "downhill: Adam 4050 loss=0.033913 error=0.003219\n",
      "downhill: validation 405 loss=0.033909 error=0.003218\n",
      "downhill: Adam 4051 loss=0.033909 error=0.003218\n",
      "downhill: Adam 4052 loss=0.033906 error=0.003216\n",
      "downhill: Adam 4053 loss=0.033903 error=0.003215\n",
      "downhill: Adam 4054 loss=0.033900 error=0.003213\n",
      "downhill: Adam 4055 loss=0.033896 error=0.003211\n",
      "downhill: Adam 4056 loss=0.033893 error=0.003210\n",
      "downhill: Adam 4057 loss=0.033890 error=0.003207\n",
      "downhill: Adam 4058 loss=0.033887 error=0.003206\n",
      "downhill: Adam 4059 loss=0.033884 error=0.003204\n",
      "downhill: Adam 4060 loss=0.033880 error=0.003202\n",
      "downhill: validation 406 loss=0.033877 error=0.003201\n",
      "downhill: Adam 4061 loss=0.033877 error=0.003201\n",
      "downhill: Adam 4062 loss=0.033874 error=0.003199\n",
      "downhill: Adam 4063 loss=0.033871 error=0.003198\n",
      "downhill: Adam 4064 loss=0.033867 error=0.003195\n",
      "downhill: Adam 4065 loss=0.033864 error=0.003194\n",
      "downhill: Adam 4066 loss=0.033861 error=0.003192\n",
      "downhill: Adam 4067 loss=0.033858 error=0.003190\n",
      "downhill: Adam 4068 loss=0.033854 error=0.003189\n",
      "downhill: Adam 4069 loss=0.033851 error=0.003187\n",
      "downhill: Adam 4070 loss=0.033848 error=0.003185\n",
      "downhill: validation 407 loss=0.033845 error=0.003183\n",
      "downhill: Adam 4071 loss=0.033845 error=0.003183\n",
      "downhill: Adam 4072 loss=0.033841 error=0.003181\n",
      "downhill: Adam 4073 loss=0.033838 error=0.003180\n",
      "downhill: Adam 4074 loss=0.033835 error=0.003178\n",
      "downhill: Adam 4075 loss=0.033832 error=0.003176\n",
      "downhill: Adam 4076 loss=0.033828 error=0.003174\n",
      "downhill: Adam 4077 loss=0.033825 error=0.003173\n",
      "downhill: Adam 4078 loss=0.033822 error=0.003170\n",
      "downhill: Adam 4079 loss=0.033819 error=0.003169\n",
      "downhill: Adam 4080 loss=0.033815 error=0.003166\n",
      "downhill: validation 408 loss=0.033812 error=0.003165\n",
      "downhill: Adam 4081 loss=0.033812 error=0.003165\n",
      "downhill: Adam 4082 loss=0.033809 error=0.003163\n",
      "downhill: Adam 4083 loss=0.033806 error=0.003161\n",
      "downhill: Adam 4084 loss=0.033803 error=0.003159\n",
      "downhill: Adam 4085 loss=0.033799 error=0.003158\n",
      "downhill: Adam 4086 loss=0.033796 error=0.003155\n",
      "downhill: Adam 4087 loss=0.033793 error=0.003154\n",
      "downhill: Adam 4088 loss=0.033790 error=0.003152\n",
      "downhill: Adam 4089 loss=0.033786 error=0.003149\n",
      "downhill: Adam 4090 loss=0.033783 error=0.003148\n",
      "downhill: validation 409 loss=0.033780 error=0.003145 *\n",
      "downhill: Adam 4091 loss=0.033780 error=0.003145\n",
      "downhill: Adam 4092 loss=0.033777 error=0.003144\n",
      "downhill: Adam 4093 loss=0.033773 error=0.003142\n",
      "downhill: Adam 4094 loss=0.033770 error=0.003139\n",
      "downhill: Adam 4095 loss=0.033767 error=0.003138\n",
      "downhill: Adam 4096 loss=0.033764 error=0.003136\n",
      "downhill: Adam 4097 loss=0.033761 error=0.003133\n",
      "downhill: Adam 4098 loss=0.033757 error=0.003132\n",
      "downhill: Adam 4099 loss=0.033754 error=0.003130\n",
      "downhill: Adam 4100 loss=0.033751 error=0.003127\n",
      "downhill: validation 410 loss=0.033748 error=0.003126\n",
      "downhill: Adam 4101 loss=0.033748 error=0.003126\n",
      "downhill: Adam 4102 loss=0.033744 error=0.003123\n",
      "downhill: Adam 4103 loss=0.033741 error=0.003121\n",
      "downhill: Adam 4104 loss=0.033738 error=0.003119\n",
      "downhill: Adam 4105 loss=0.033735 error=0.003117\n",
      "downhill: Adam 4106 loss=0.033731 error=0.003115\n",
      "downhill: Adam 4107 loss=0.033728 error=0.003114\n",
      "downhill: Adam 4108 loss=0.033725 error=0.003110\n",
      "downhill: Adam 4109 loss=0.033722 error=0.003110\n",
      "downhill: Adam 4110 loss=0.033718 error=0.003106\n",
      "downhill: validation 411 loss=0.033715 error=0.003105\n",
      "downhill: Adam 4111 loss=0.033715 error=0.003105\n",
      "downhill: Adam 4112 loss=0.033712 error=0.003102\n",
      "downhill: Adam 4113 loss=0.033709 error=0.003101\n",
      "downhill: Adam 4114 loss=0.033705 error=0.003097\n",
      "downhill: Adam 4115 loss=0.033702 error=0.003096\n",
      "downhill: Adam 4116 loss=0.033699 error=0.003094\n",
      "downhill: Adam 4117 loss=0.033696 error=0.003091\n",
      "downhill: Adam 4118 loss=0.033693 error=0.003090\n",
      "downhill: Adam 4119 loss=0.033689 error=0.003086\n",
      "downhill: Adam 4120 loss=0.033686 error=0.003085\n",
      "downhill: validation 412 loss=0.033683 error=0.003082\n",
      "downhill: Adam 4121 loss=0.033683 error=0.003082\n",
      "downhill: Adam 4122 loss=0.033680 error=0.003080\n",
      "downhill: Adam 4123 loss=0.033676 error=0.003078\n",
      "downhill: Adam 4124 loss=0.033673 error=0.003075\n",
      "downhill: Adam 4125 loss=0.033670 error=0.003073\n",
      "downhill: Adam 4126 loss=0.033667 error=0.003071\n",
      "downhill: Adam 4127 loss=0.033663 error=0.003069\n",
      "downhill: Adam 4128 loss=0.033660 error=0.003066\n",
      "downhill: Adam 4129 loss=0.033657 error=0.003064\n",
      "downhill: Adam 4130 loss=0.033654 error=0.003061\n",
      "downhill: validation 413 loss=0.033650 error=0.003060\n",
      "downhill: Adam 4131 loss=0.033650 error=0.003060\n",
      "downhill: Adam 4132 loss=0.033647 error=0.003057\n",
      "downhill: Adam 4133 loss=0.033644 error=0.003055\n",
      "downhill: Adam 4134 loss=0.033641 error=0.003052\n",
      "downhill: Adam 4135 loss=0.033637 error=0.003050\n",
      "downhill: Adam 4136 loss=0.033634 error=0.003047\n",
      "downhill: Adam 4137 loss=0.033631 error=0.003045\n",
      "downhill: Adam 4138 loss=0.033627 error=0.003043\n",
      "downhill: Adam 4139 loss=0.033624 error=0.003040\n",
      "downhill: Adam 4140 loss=0.033621 error=0.003038\n",
      "downhill: validation 414 loss=0.033618 error=0.003035\n",
      "downhill: Adam 4141 loss=0.033618 error=0.003035\n",
      "downhill: Adam 4142 loss=0.033614 error=0.003033\n",
      "downhill: Adam 4143 loss=0.033611 error=0.003030\n",
      "downhill: Adam 4144 loss=0.033608 error=0.003028\n",
      "downhill: Adam 4145 loss=0.033604 error=0.003024\n",
      "downhill: Adam 4146 loss=0.033601 error=0.003023\n",
      "downhill: Adam 4147 loss=0.033598 error=0.003019\n",
      "downhill: Adam 4148 loss=0.033595 error=0.003018\n",
      "downhill: Adam 4149 loss=0.033591 error=0.003014\n",
      "downhill: Adam 4150 loss=0.033588 error=0.003013\n",
      "downhill: validation 415 loss=0.033585 error=0.003009 *\n",
      "downhill: Adam 4151 loss=0.033585 error=0.003009\n",
      "downhill: Adam 4152 loss=0.033581 error=0.003007\n",
      "downhill: Adam 4153 loss=0.033578 error=0.003004\n",
      "downhill: Adam 4154 loss=0.033575 error=0.003001\n",
      "downhill: Adam 4155 loss=0.033571 error=0.002999\n",
      "downhill: Adam 4156 loss=0.033568 error=0.002996\n",
      "downhill: Adam 4157 loss=0.033565 error=0.002994\n",
      "downhill: Adam 4158 loss=0.033561 error=0.002990\n",
      "downhill: Adam 4159 loss=0.033558 error=0.002989\n",
      "downhill: Adam 4160 loss=0.033555 error=0.002985\n",
      "downhill: validation 416 loss=0.033551 error=0.002983\n",
      "downhill: Adam 4161 loss=0.033551 error=0.002983\n",
      "downhill: Adam 4162 loss=0.033548 error=0.002980\n",
      "downhill: Adam 4163 loss=0.033545 error=0.002977\n",
      "downhill: Adam 4164 loss=0.033541 error=0.002975\n",
      "downhill: Adam 4165 loss=0.033538 error=0.002972\n",
      "downhill: Adam 4166 loss=0.033534 error=0.002970\n",
      "downhill: Adam 4167 loss=0.033531 error=0.002966\n",
      "downhill: Adam 4168 loss=0.033528 error=0.002964\n",
      "downhill: Adam 4169 loss=0.033524 error=0.002961\n",
      "downhill: Adam 4170 loss=0.033521 error=0.002958\n",
      "downhill: validation 417 loss=0.033518 error=0.002955\n",
      "downhill: Adam 4171 loss=0.033518 error=0.002955\n",
      "downhill: Adam 4172 loss=0.033514 error=0.002952\n",
      "downhill: Adam 4173 loss=0.033511 error=0.002950\n",
      "downhill: Adam 4174 loss=0.033507 error=0.002946\n",
      "downhill: Adam 4175 loss=0.033504 error=0.002944\n",
      "downhill: Adam 4176 loss=0.033501 error=0.002941\n",
      "downhill: Adam 4177 loss=0.033497 error=0.002938\n",
      "downhill: Adam 4178 loss=0.033494 error=0.002935\n",
      "downhill: Adam 4179 loss=0.033490 error=0.002932\n",
      "downhill: Adam 4180 loss=0.033487 error=0.002929\n",
      "downhill: validation 418 loss=0.033484 error=0.002927\n",
      "downhill: Adam 4181 loss=0.033484 error=0.002927\n",
      "downhill: Adam 4182 loss=0.033480 error=0.002923\n",
      "downhill: Adam 4183 loss=0.033477 error=0.002921\n",
      "downhill: Adam 4184 loss=0.033473 error=0.002916\n",
      "downhill: Adam 4185 loss=0.033470 error=0.002916\n",
      "downhill: Adam 4186 loss=0.033467 error=0.002910\n",
      "downhill: Adam 4187 loss=0.033463 error=0.002910\n",
      "downhill: Adam 4188 loss=0.033460 error=0.002904\n",
      "downhill: Adam 4189 loss=0.033456 error=0.002903\n",
      "downhill: Adam 4190 loss=0.033453 error=0.002899\n",
      "downhill: validation 419 loss=0.033449 error=0.002895\n",
      "downhill: Adam 4191 loss=0.033449 error=0.002895\n",
      "downhill: Adam 4192 loss=0.033446 error=0.002894\n",
      "downhill: Adam 4193 loss=0.033443 error=0.002889\n",
      "downhill: Adam 4194 loss=0.033439 error=0.002888\n",
      "downhill: Adam 4195 loss=0.033436 error=0.002884\n",
      "downhill: Adam 4196 loss=0.033432 error=0.002880\n",
      "downhill: Adam 4197 loss=0.033429 error=0.002879\n",
      "downhill: Adam 4198 loss=0.033425 error=0.002874\n",
      "downhill: Adam 4199 loss=0.033422 error=0.002872\n",
      "downhill: Adam 4200 loss=0.033419 error=0.002869\n",
      "downhill: validation 420 loss=0.033415 error=0.002865 *\n",
      "downhill: Adam 4201 loss=0.033415 error=0.002865\n",
      "downhill: Adam 4202 loss=0.033412 error=0.002863\n",
      "downhill: Adam 4203 loss=0.033408 error=0.002859\n",
      "downhill: Adam 4204 loss=0.033405 error=0.002856\n",
      "downhill: Adam 4205 loss=0.033401 error=0.002853\n",
      "downhill: Adam 4206 loss=0.033398 error=0.002850\n",
      "downhill: Adam 4207 loss=0.033395 error=0.002847\n",
      "downhill: Adam 4208 loss=0.033391 error=0.002844\n",
      "downhill: Adam 4209 loss=0.033388 error=0.002840\n",
      "downhill: Adam 4210 loss=0.033384 error=0.002837\n",
      "downhill: validation 421 loss=0.033381 error=0.002834\n",
      "downhill: Adam 4211 loss=0.033381 error=0.002834\n",
      "downhill: Adam 4212 loss=0.033378 error=0.002831\n",
      "downhill: Adam 4213 loss=0.033374 error=0.002828\n",
      "downhill: Adam 4214 loss=0.033371 error=0.002825\n",
      "downhill: Adam 4215 loss=0.033367 error=0.002822\n",
      "downhill: Adam 4216 loss=0.033364 error=0.002818\n",
      "downhill: Adam 4217 loss=0.033360 error=0.002815\n",
      "downhill: Adam 4218 loss=0.033357 error=0.002812\n",
      "downhill: Adam 4219 loss=0.033354 error=0.002809\n",
      "downhill: Adam 4220 loss=0.033350 error=0.002806\n",
      "downhill: validation 422 loss=0.033347 error=0.002803\n",
      "downhill: Adam 4221 loss=0.033347 error=0.002803\n",
      "downhill: Adam 4222 loss=0.033343 error=0.002800\n",
      "downhill: Adam 4223 loss=0.033340 error=0.002796\n",
      "downhill: Adam 4224 loss=0.033337 error=0.002793\n",
      "downhill: Adam 4225 loss=0.033333 error=0.002790\n",
      "downhill: Adam 4226 loss=0.033330 error=0.002787\n",
      "downhill: Adam 4227 loss=0.033326 error=0.002784\n",
      "downhill: Adam 4228 loss=0.033323 error=0.002780\n",
      "downhill: Adam 4229 loss=0.033320 error=0.002777\n",
      "downhill: Adam 4230 loss=0.033316 error=0.002774\n",
      "downhill: validation 423 loss=0.033313 error=0.002771\n",
      "downhill: Adam 4231 loss=0.033313 error=0.002771\n",
      "downhill: Adam 4232 loss=0.033309 error=0.002768\n",
      "downhill: Adam 4233 loss=0.033306 error=0.002764\n",
      "downhill: Adam 4234 loss=0.033303 error=0.002762\n",
      "downhill: Adam 4235 loss=0.033299 error=0.002758\n",
      "downhill: Adam 4236 loss=0.033296 error=0.002756\n",
      "downhill: Adam 4237 loss=0.033292 error=0.002751\n",
      "downhill: Adam 4238 loss=0.033289 error=0.002750\n",
      "downhill: Adam 4239 loss=0.033286 error=0.002745\n",
      "downhill: Adam 4240 loss=0.033282 error=0.002743\n",
      "downhill: validation 424 loss=0.033279 error=0.002739\n",
      "downhill: Adam 4241 loss=0.033279 error=0.002739\n",
      "downhill: Adam 4242 loss=0.033276 error=0.002736\n",
      "downhill: Adam 4243 loss=0.033272 error=0.002733\n",
      "downhill: Adam 4244 loss=0.033269 error=0.002729\n",
      "downhill: Adam 4245 loss=0.033266 error=0.002727\n",
      "downhill: Adam 4246 loss=0.033262 error=0.002724\n",
      "downhill: Adam 4247 loss=0.033259 error=0.002720\n",
      "downhill: Adam 4248 loss=0.033256 error=0.002717\n",
      "downhill: Adam 4249 loss=0.033252 error=0.002714\n",
      "downhill: Adam 4250 loss=0.033249 error=0.002711\n",
      "downhill: validation 425 loss=0.033246 error=0.002708 *\n",
      "downhill: Adam 4251 loss=0.033246 error=0.002708\n",
      "downhill: Adam 4252 loss=0.033242 error=0.002704\n",
      "downhill: Adam 4253 loss=0.033239 error=0.002702\n",
      "downhill: Adam 4254 loss=0.033236 error=0.002698\n",
      "downhill: Adam 4255 loss=0.033232 error=0.002695\n",
      "downhill: Adam 4256 loss=0.033229 error=0.002692\n",
      "downhill: Adam 4257 loss=0.033226 error=0.002689\n",
      "downhill: Adam 4258 loss=0.033222 error=0.002686\n",
      "downhill: Adam 4259 loss=0.033219 error=0.002683\n",
      "downhill: Adam 4260 loss=0.033216 error=0.002680\n",
      "downhill: validation 426 loss=0.033212 error=0.002677\n",
      "downhill: Adam 4261 loss=0.033212 error=0.002677\n",
      "downhill: Adam 4262 loss=0.033209 error=0.002674\n",
      "downhill: Adam 4263 loss=0.033206 error=0.002671\n",
      "downhill: Adam 4264 loss=0.033203 error=0.002668\n",
      "downhill: Adam 4265 loss=0.033199 error=0.002664\n",
      "downhill: Adam 4266 loss=0.033196 error=0.002662\n",
      "downhill: Adam 4267 loss=0.033193 error=0.002658\n",
      "downhill: Adam 4268 loss=0.033190 error=0.002656\n",
      "downhill: Adam 4269 loss=0.033186 error=0.002652\n",
      "downhill: Adam 4270 loss=0.033183 error=0.002650\n",
      "downhill: validation 427 loss=0.033180 error=0.002646\n",
      "downhill: Adam 4271 loss=0.033180 error=0.002646\n",
      "downhill: Adam 4272 loss=0.033177 error=0.002644\n",
      "downhill: Adam 4273 loss=0.033173 error=0.002640\n",
      "downhill: Adam 4274 loss=0.033170 error=0.002638\n",
      "downhill: Adam 4275 loss=0.033167 error=0.002635\n",
      "downhill: Adam 4276 loss=0.033164 error=0.002632\n",
      "downhill: Adam 4277 loss=0.033160 error=0.002629\n",
      "downhill: Adam 4278 loss=0.033157 error=0.002626\n",
      "downhill: Adam 4279 loss=0.033154 error=0.002622\n",
      "downhill: Adam 4280 loss=0.033151 error=0.002621\n",
      "downhill: validation 428 loss=0.033148 error=0.002616\n",
      "downhill: Adam 4281 loss=0.033148 error=0.002616\n",
      "downhill: Adam 4282 loss=0.033144 error=0.002615\n",
      "downhill: Adam 4283 loss=0.033141 error=0.002611\n",
      "downhill: Adam 4284 loss=0.033138 error=0.002609\n",
      "downhill: Adam 4285 loss=0.033135 error=0.002605\n",
      "downhill: Adam 4286 loss=0.033132 error=0.002603\n",
      "downhill: Adam 4287 loss=0.033128 error=0.002600\n",
      "downhill: Adam 4288 loss=0.033125 error=0.002596\n",
      "downhill: Adam 4289 loss=0.033122 error=0.002595\n",
      "downhill: Adam 4290 loss=0.033119 error=0.002591\n",
      "downhill: validation 429 loss=0.033116 error=0.002589\n",
      "downhill: Adam 4291 loss=0.033116 error=0.002589\n",
      "downhill: Adam 4292 loss=0.033113 error=0.002586\n",
      "downhill: Adam 4293 loss=0.033109 error=0.002583\n",
      "downhill: Adam 4294 loss=0.033106 error=0.002581\n",
      "downhill: Adam 4295 loss=0.033103 error=0.002577\n",
      "downhill: Adam 4296 loss=0.033100 error=0.002575\n",
      "downhill: Adam 4297 loss=0.033097 error=0.002572\n",
      "downhill: Adam 4298 loss=0.033094 error=0.002570\n",
      "downhill: Adam 4299 loss=0.033091 error=0.002567\n",
      "downhill: Adam 4300 loss=0.033088 error=0.002564\n",
      "downhill: validation 430 loss=0.033084 error=0.002562\n",
      "downhill: Adam 4301 loss=0.033084 error=0.002562\n",
      "downhill: Adam 4302 loss=0.033081 error=0.002559\n",
      "downhill: Adam 4303 loss=0.033078 error=0.002556\n",
      "downhill: Adam 4304 loss=0.033075 error=0.002554\n",
      "downhill: Adam 4305 loss=0.033072 error=0.002551\n",
      "downhill: Adam 4306 loss=0.033069 error=0.002548\n",
      "downhill: Adam 4307 loss=0.033066 error=0.002546\n",
      "downhill: Adam 4308 loss=0.033063 error=0.002543\n",
      "downhill: Adam 4309 loss=0.033060 error=0.002541\n",
      "downhill: Adam 4310 loss=0.033057 error=0.002538\n",
      "downhill: validation 431 loss=0.033054 error=0.002536 *\n",
      "downhill: Adam 4311 loss=0.033054 error=0.002536\n",
      "downhill: Adam 4312 loss=0.033051 error=0.002533\n",
      "downhill: Adam 4313 loss=0.033048 error=0.002531\n",
      "downhill: Adam 4314 loss=0.033045 error=0.002528\n",
      "downhill: Adam 4315 loss=0.033041 error=0.002526\n",
      "downhill: Adam 4316 loss=0.033038 error=0.002523\n",
      "downhill: Adam 4317 loss=0.033035 error=0.002521\n",
      "downhill: Adam 4318 loss=0.033032 error=0.002519\n",
      "downhill: Adam 4319 loss=0.033029 error=0.002516\n",
      "downhill: Adam 4320 loss=0.033026 error=0.002514\n",
      "downhill: validation 432 loss=0.033023 error=0.002511\n",
      "downhill: Adam 4321 loss=0.033023 error=0.002511\n",
      "downhill: Adam 4322 loss=0.033020 error=0.002510\n",
      "downhill: Adam 4323 loss=0.033017 error=0.002506\n",
      "downhill: Adam 4324 loss=0.033014 error=0.002505\n",
      "downhill: Adam 4325 loss=0.033011 error=0.002501\n",
      "downhill: Adam 4326 loss=0.033008 error=0.002501\n",
      "downhill: Adam 4327 loss=0.033005 error=0.002496\n",
      "downhill: Adam 4328 loss=0.033002 error=0.002495\n",
      "downhill: Adam 4329 loss=0.032999 error=0.002492\n",
      "downhill: Adam 4330 loss=0.032996 error=0.002490\n",
      "downhill: validation 433 loss=0.032993 error=0.002488\n",
      "downhill: Adam 4331 loss=0.032993 error=0.002488\n",
      "downhill: Adam 4332 loss=0.032990 error=0.002485\n",
      "downhill: Adam 4333 loss=0.032988 error=0.002484\n",
      "downhill: Adam 4334 loss=0.032985 error=0.002481\n",
      "downhill: Adam 4335 loss=0.032982 error=0.002479\n",
      "downhill: Adam 4336 loss=0.032979 error=0.002477\n",
      "downhill: Adam 4337 loss=0.032976 error=0.002474\n",
      "downhill: Adam 4338 loss=0.032973 error=0.002473\n",
      "downhill: Adam 4339 loss=0.032970 error=0.002470\n",
      "downhill: Adam 4340 loss=0.032967 error=0.002468\n",
      "downhill: validation 434 loss=0.032964 error=0.002466\n",
      "downhill: Adam 4341 loss=0.032964 error=0.002466\n",
      "downhill: Adam 4342 loss=0.032961 error=0.002463\n",
      "downhill: Adam 4343 loss=0.032958 error=0.002462\n",
      "downhill: Adam 4344 loss=0.032955 error=0.002459\n",
      "downhill: Adam 4345 loss=0.032952 error=0.002457\n",
      "downhill: Adam 4346 loss=0.032950 error=0.002455\n",
      "downhill: Adam 4347 loss=0.032947 error=0.002453\n",
      "downhill: Adam 4348 loss=0.032944 error=0.002451\n",
      "downhill: Adam 4349 loss=0.032941 error=0.002449\n",
      "downhill: Adam 4350 loss=0.032938 error=0.002447\n",
      "downhill: validation 435 loss=0.032935 error=0.002445\n",
      "downhill: Adam 4351 loss=0.032935 error=0.002445\n",
      "downhill: Adam 4352 loss=0.032932 error=0.002443\n",
      "downhill: Adam 4353 loss=0.032929 error=0.002441\n",
      "downhill: Adam 4354 loss=0.032927 error=0.002439\n",
      "downhill: Adam 4355 loss=0.032924 error=0.002437\n",
      "downhill: Adam 4356 loss=0.032921 error=0.002435\n",
      "downhill: Adam 4357 loss=0.032918 error=0.002433\n",
      "downhill: Adam 4358 loss=0.032915 error=0.002431\n",
      "downhill: Adam 4359 loss=0.032912 error=0.002429\n",
      "downhill: Adam 4360 loss=0.032910 error=0.002427\n",
      "downhill: validation 436 loss=0.032907 error=0.002425\n",
      "downhill: Adam 4361 loss=0.032907 error=0.002425\n",
      "downhill: Adam 4362 loss=0.032904 error=0.002423\n",
      "downhill: Adam 4363 loss=0.032901 error=0.002422\n",
      "downhill: Adam 4364 loss=0.032898 error=0.002419\n",
      "downhill: Adam 4365 loss=0.032896 error=0.002418\n",
      "downhill: Adam 4366 loss=0.032893 error=0.002415\n",
      "downhill: Adam 4367 loss=0.032890 error=0.002414\n",
      "downhill: Adam 4368 loss=0.032887 error=0.002412\n",
      "downhill: Adam 4369 loss=0.032884 error=0.002410\n",
      "downhill: Adam 4370 loss=0.032882 error=0.002409\n",
      "downhill: validation 437 loss=0.032879 error=0.002406 *\n",
      "downhill: Adam 4371 loss=0.032879 error=0.002406\n",
      "downhill: Adam 4372 loss=0.032876 error=0.002406\n",
      "downhill: Adam 4373 loss=0.032873 error=0.002402\n",
      "downhill: Adam 4374 loss=0.032871 error=0.002402\n",
      "downhill: Adam 4375 loss=0.032868 error=0.002399\n",
      "downhill: Adam 4376 loss=0.032865 error=0.002399\n",
      "downhill: Adam 4377 loss=0.032862 error=0.002396\n",
      "downhill: Adam 4378 loss=0.032860 error=0.002395\n",
      "downhill: Adam 4379 loss=0.032857 error=0.002393\n",
      "downhill: Adam 4380 loss=0.032854 error=0.002391\n",
      "downhill: validation 438 loss=0.032852 error=0.002390\n",
      "downhill: Adam 4381 loss=0.032852 error=0.002390\n",
      "downhill: Adam 4382 loss=0.032849 error=0.002387\n",
      "downhill: Adam 4383 loss=0.032846 error=0.002387\n",
      "downhill: Adam 4384 loss=0.032844 error=0.002384\n",
      "downhill: Adam 4385 loss=0.032841 error=0.002383\n",
      "downhill: Adam 4386 loss=0.032838 error=0.002381\n",
      "downhill: Adam 4387 loss=0.032835 error=0.002379\n",
      "downhill: Adam 4388 loss=0.032833 error=0.002378\n",
      "downhill: Adam 4389 loss=0.032830 error=0.002376\n",
      "downhill: Adam 4390 loss=0.032827 error=0.002375\n",
      "downhill: validation 439 loss=0.032825 error=0.002373\n",
      "downhill: Adam 4391 loss=0.032825 error=0.002373\n",
      "downhill: Adam 4392 loss=0.032822 error=0.002372\n",
      "downhill: Adam 4393 loss=0.032819 error=0.002370\n",
      "downhill: Adam 4394 loss=0.032817 error=0.002369\n",
      "downhill: Adam 4395 loss=0.032814 error=0.002367\n",
      "downhill: Adam 4396 loss=0.032812 error=0.002366\n",
      "downhill: Adam 4397 loss=0.032809 error=0.002364\n",
      "downhill: Adam 4398 loss=0.032806 error=0.002362\n",
      "downhill: Adam 4399 loss=0.032804 error=0.002362\n",
      "downhill: Adam 4400 loss=0.032801 error=0.002359\n",
      "downhill: validation 440 loss=0.032798 error=0.002359\n",
      "downhill: Adam 4401 loss=0.032798 error=0.002359\n",
      "downhill: Adam 4402 loss=0.032796 error=0.002356\n",
      "downhill: Adam 4403 loss=0.032793 error=0.002356\n",
      "downhill: Adam 4404 loss=0.032791 error=0.002353\n",
      "downhill: Adam 4405 loss=0.032788 error=0.002353\n",
      "downhill: Adam 4406 loss=0.032785 error=0.002350\n",
      "downhill: Adam 4407 loss=0.032783 error=0.002350\n",
      "downhill: Adam 4408 loss=0.032780 error=0.002348\n",
      "downhill: Adam 4409 loss=0.032778 error=0.002346\n",
      "downhill: Adam 4410 loss=0.032775 error=0.002346\n",
      "downhill: validation 441 loss=0.032773 error=0.002343\n",
      "downhill: Adam 4411 loss=0.032773 error=0.002343\n",
      "downhill: Adam 4412 loss=0.032770 error=0.002343\n",
      "downhill: Adam 4413 loss=0.032768 error=0.002340\n",
      "downhill: Adam 4414 loss=0.032765 error=0.002340\n",
      "downhill: Adam 4415 loss=0.032762 error=0.002338\n",
      "downhill: Adam 4416 loss=0.032760 error=0.002337\n",
      "downhill: Adam 4417 loss=0.032757 error=0.002335\n",
      "downhill: Adam 4418 loss=0.032755 error=0.002334\n",
      "downhill: Adam 4419 loss=0.032752 error=0.002333\n",
      "downhill: Adam 4420 loss=0.032750 error=0.002332\n",
      "downhill: validation 442 loss=0.032747 error=0.002331\n",
      "downhill: Adam 4421 loss=0.032747 error=0.002331\n",
      "downhill: Adam 4422 loss=0.032745 error=0.002329\n",
      "downhill: Adam 4423 loss=0.032742 error=0.002328\n",
      "downhill: Adam 4424 loss=0.032740 error=0.002326\n",
      "downhill: Adam 4425 loss=0.032737 error=0.002325\n",
      "downhill: Adam 4426 loss=0.032735 error=0.002324\n",
      "downhill: Adam 4427 loss=0.032732 error=0.002323\n",
      "downhill: Adam 4428 loss=0.032730 error=0.002321\n",
      "downhill: Adam 4429 loss=0.032727 error=0.002321\n",
      "downhill: Adam 4430 loss=0.032725 error=0.002318\n",
      "downhill: validation 443 loss=0.032723 error=0.002319\n",
      "downhill: patience elapsed!\n"
     ]
    }
   ],
   "source": [
    "# %time function doesn't work. only times first iteration\n",
    "mf_result = ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", mf_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 887144.37798303901, 'rmse': 1922065.7263672766}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f3d683d05685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Throws error. missing an argument?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfancy_imputer_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpute_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"total_lbs_proppant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnm_imputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jameshelfrich/bin/impute_eval.pyc\u001b[0m in \u001b[0;36mfancy_imputer_eval\u001b[0;34m(df, drop_col, imputer, impute_percent, seed)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdrops_normed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrops_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mX_filled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrops_normed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mX_filled_unnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mimputer_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_filled_unnormed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrop_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_col_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0many\u001b[0m \u001b[0mNaNs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mimputations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_imputations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimputations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36mmultiple_imputations\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mGenerate\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mimputations\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mincomplete\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_imputations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36msingle_imputation\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     type(X_filled)))\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mX_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/fancyimpute/nuclear_norm_minimization.pyc\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, X, missing_mask)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# SCS solver is known to be faster but less exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             solver=cvxpy.SCS if self.fast_but_approximate else None)\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/problem.pyc\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/problem.pyc\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, ignore_dcp, warm_start, verbose, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m             results_dict = solver.solve(objective, constraints,\n\u001b[1;32m    330\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                                         kwargs)\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;31m# Presolve determined problem was unbounded or infeasible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/solvers/scs_intf.pyc\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, objective, constraints, cached_data, warm_start, verbose, solver_opts)\u001b[0m\n\u001b[1;32m     94\u001b[0m         data = self.get_problem_data(objective,\n\u001b[1;32m     95\u001b[0m                                      \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                                      cached_data)\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Set the options to be VERBOSE plus any user-specific options.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0msolver_opts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/solvers/solver.pyc\u001b[0m in \u001b[0;36mget_problem_data\u001b[0;34m(self, objective, constraints, cached_data)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0msym_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sym_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         matrix_data = self.get_matrix_data(objective, constraints,\n\u001b[0;32m--> 248\u001b[0;31m                                            cached_data)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOFFSET\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/solvers/solver.pyc\u001b[0m in \u001b[0;36mget_matrix_data\u001b[0;34m(self, objective, constraints, cached_data)\u001b[0m\n\u001b[1;32m    224\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_intf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                                                self.nonlin_constr())\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/problem_data/matrix_data.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sym_data, matrix_intf, vec_intf, solver, nonlin)\u001b[0m\n\u001b[1;32m     84\u001b[0m         self.eq_cache = self._init_matrix_cache(eq_constr,\n\u001b[1;32m     85\u001b[0m                                                 self.sym_data.x_length)\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lin_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Inequality constraints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         self.ineq_cache = self._init_matrix_cache(ineq_constr,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/cvxpy/problems/problem_data/matrix_data.pyc\u001b[0m in \u001b[0;36m_lin_matrix\u001b[0;34m(self, mat_cache, caching)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mactive_constr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msym_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mconstr_offsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             )\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# Convert the constant offset to the correct data type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/canonInterface.pyc\u001b[0m in \u001b[0;36mget_problem_matrix\u001b[0;34m(constrs, id_to_col, constr_offsets)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mconstr_offsets_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         problemData = CVXcanon.build_matrix(lin_vec, id_to_col_C,\n\u001b[0;32m---> 64\u001b[0;31m                                             constr_offsets_C)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Unpacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Throws error. missing an argument?\n",
    "ie.fancy_imputer_eval(impute_test_df, \"total_lbs_proppant\", nnm_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test on all numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on all features, one at a time.\n",
    "*Pseudocode*:\n",
    "\n",
    "```python\n",
    "for each (numeric) column in dataframe: \n",
    "    replace 10% of the observations in one column with None  \n",
    "    for each imputation method in dict:\n",
    "        fill missing values\n",
    "        compute error score for each combination of feature/imputation method\n",
    "rollup results into a df\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapted from code in documentation for fancyimpute library  https://pypi.python.org/pypi/fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now imputing values for column GRElev with imputer soft_imputer\n",
      "now imputing values for column GRElev with imputer sf_median\n",
      "now imputing values for column GRElev with imputer mice_imputer\n",
      "now imputing values for column GRElev with imputer sf_mean\n",
      "now imputing values for column GRElev with imputer knn_imputer\n",
      "now imputing values for column KBElev with imputer soft_imputer\n",
      "now imputing values for column KBElev with imputer sf_median\n",
      "now imputing values for column KBElev with imputer mice_imputer\n",
      "now imputing values for column KBElev with imputer sf_mean\n",
      "now imputing values for column KBElev with imputer knn_imputer\n",
      "now imputing values for column TD with imputer soft_imputer\n",
      "now imputing values for column TD with imputer sf_median\n",
      "now imputing values for column TD with imputer mice_imputer\n",
      "now imputing values for column TD with imputer sf_mean\n",
      "now imputing values for column TD with imputer knn_imputer\n",
      "now imputing values for column bh_lat with imputer soft_imputer\n",
      "now imputing values for column bh_lat with imputer sf_median\n",
      "now imputing values for column bh_lat with imputer mice_imputer\n",
      "now imputing values for column bh_lat with imputer sf_mean\n",
      "now imputing values for column bh_lat with imputer knn_imputer\n",
      "now imputing values for column bh_lng with imputer soft_imputer\n",
      "now imputing values for column bh_lng with imputer sf_median\n",
      "now imputing values for column bh_lng with imputer mice_imputer\n",
      "now imputing values for column bh_lng with imputer sf_mean\n",
      "now imputing values for column bh_lng with imputer knn_imputer\n",
      "now imputing values for column legs with imputer soft_imputer\n",
      "now imputing values for column legs with imputer sf_median\n",
      "now imputing values for column legs with imputer mice_imputer\n",
      "now imputing values for column legs with imputer sf_mean\n",
      "now imputing values for column legs with imputer knn_imputer\n",
      "now imputing values for column max_tvd with imputer soft_imputer\n",
      "now imputing values for column max_tvd with imputer sf_median\n",
      "now imputing values for column max_tvd with imputer mice_imputer\n",
      "now imputing values for column max_tvd with imputer sf_mean\n",
      "now imputing values for column max_tvd with imputer knn_imputer\n",
      "now imputing values for column mean_tvd with imputer soft_imputer\n",
      "now imputing values for column mean_tvd with imputer sf_median\n",
      "now imputing values for column mean_tvd with imputer mice_imputer\n",
      "now imputing values for column mean_tvd with imputer sf_mean\n",
      "now imputing values for column mean_tvd with imputer knn_imputer\n",
      "now imputing values for column min_tvd with imputer soft_imputer\n",
      "now imputing values for column min_tvd with imputer sf_median\n",
      "now imputing values for column min_tvd with imputer mice_imputer\n",
      "now imputing values for column min_tvd with imputer sf_mean\n",
      "now imputing values for column min_tvd with imputer knn_imputer\n",
      "now imputing values for column num_pools_produced with imputer soft_imputer\n",
      "now imputing values for column num_pools_produced with imputer sf_median\n",
      "now imputing values for column num_pools_produced with imputer mice_imputer\n",
      "now imputing values for column num_pools_produced with imputer sf_mean\n",
      "now imputing values for column num_pools_produced with imputer knn_imputer\n",
      "now imputing values for column std_tvd with imputer soft_imputer\n",
      "now imputing values for column std_tvd with imputer sf_median\n",
      "now imputing values for column std_tvd with imputer mice_imputer\n",
      "now imputing values for column std_tvd with imputer sf_mean\n",
      "now imputing values for column std_tvd with imputer knn_imputer\n",
      "now imputing values for column surface_lat with imputer soft_imputer\n",
      "now imputing values for column surface_lat with imputer sf_median\n",
      "now imputing values for column surface_lat with imputer mice_imputer\n",
      "now imputing values for column surface_lat with imputer sf_mean\n",
      "now imputing values for column surface_lat with imputer knn_imputer\n",
      "now imputing values for column surface_lng with imputer soft_imputer\n",
      "now imputing values for column surface_lng with imputer sf_median\n",
      "now imputing values for column surface_lng with imputer mice_imputer\n",
      "now imputing values for column surface_lng with imputer sf_mean\n",
      "now imputing values for column surface_lng with imputer knn_imputer\n",
      "now imputing values for column total_lbs_proppant with imputer soft_imputer\n",
      "now imputing values for column total_lbs_proppant with imputer sf_median\n",
      "now imputing values for column total_lbs_proppant with imputer mice_imputer\n",
      "now imputing values for column total_lbs_proppant with imputer sf_mean\n",
      "now imputing values for column total_lbs_proppant with imputer knn_imputer\n",
      "now imputing values for column total_volume_bbls with imputer soft_imputer\n",
      "now imputing values for column total_volume_bbls with imputer sf_median\n",
      "now imputing values for column total_volume_bbls with imputer mice_imputer\n",
      "now imputing values for column total_volume_bbls with imputer sf_mean\n",
      "now imputing values for column total_volume_bbls with imputer knn_imputer\n",
      "now imputing values for column tvd with imputer soft_imputer\n",
      "now imputing values for column tvd with imputer sf_median\n",
      "now imputing values for column tvd with imputer mice_imputer\n",
      "now imputing values for column tvd with imputer sf_mean\n",
      "now imputing values for column tvd with imputer knn_imputer\n"
     ]
    }
   ],
   "source": [
    "impute_results_df = ie.imputers_eval(impute_test_df, imputers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn_imputer</th>\n",
       "      <th>mice_imputer</th>\n",
       "      <th>sf_mean</th>\n",
       "      <th>sf_median</th>\n",
       "      <th>soft_imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRElev</th>\n",
       "      <td>32.937391</td>\n",
       "      <td>43.859176</td>\n",
       "      <td>131.739782</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>53.662910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBElev</th>\n",
       "      <td>33.656877</td>\n",
       "      <td>47.500630</td>\n",
       "      <td>133.791984</td>\n",
       "      <td>132.403685</td>\n",
       "      <td>56.721286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>731.560670</td>\n",
       "      <td>1057.801104</td>\n",
       "      <td>1232.811161</td>\n",
       "      <td>1125.918760</td>\n",
       "      <td>924.276236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lat</th>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.145272</td>\n",
       "      <td>0.343438</td>\n",
       "      <td>0.343322</td>\n",
       "      <td>0.202749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lng</th>\n",
       "      <td>0.150667</td>\n",
       "      <td>0.125485</td>\n",
       "      <td>0.394108</td>\n",
       "      <td>0.393342</td>\n",
       "      <td>0.177855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>0.337165</td>\n",
       "      <td>0.814652</td>\n",
       "      <td>0.351858</td>\n",
       "      <td>0.219430</td>\n",
       "      <td>0.693342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tvd</th>\n",
       "      <td>74.487098</td>\n",
       "      <td>62.991736</td>\n",
       "      <td>612.034433</td>\n",
       "      <td>574.316759</td>\n",
       "      <td>84.225039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_tvd</th>\n",
       "      <td>77.304638</td>\n",
       "      <td>69.511239</td>\n",
       "      <td>619.554369</td>\n",
       "      <td>581.414754</td>\n",
       "      <td>96.100281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_tvd</th>\n",
       "      <td>84.795253</td>\n",
       "      <td>135.695898</td>\n",
       "      <td>632.089117</td>\n",
       "      <td>596.919481</td>\n",
       "      <td>164.440233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pools_produced</th>\n",
       "      <td>0.159680</td>\n",
       "      <td>0.573178</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_tvd</th>\n",
       "      <td>21.535965</td>\n",
       "      <td>23.470933</td>\n",
       "      <td>30.108830</td>\n",
       "      <td>28.328596</td>\n",
       "      <td>24.962371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lat</th>\n",
       "      <td>0.148624</td>\n",
       "      <td>0.148184</td>\n",
       "      <td>0.344715</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.205988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lng</th>\n",
       "      <td>0.150847</td>\n",
       "      <td>0.125954</td>\n",
       "      <td>0.394367</td>\n",
       "      <td>0.393438</td>\n",
       "      <td>0.178330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_lbs_proppant</th>\n",
       "      <td>581601.693076</td>\n",
       "      <td>882792.572311</td>\n",
       "      <td>978028.075325</td>\n",
       "      <td>954991.417085</td>\n",
       "      <td>839883.003831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_volume_bbls</th>\n",
       "      <td>17458.836494</td>\n",
       "      <td>24323.185556</td>\n",
       "      <td>27376.457111</td>\n",
       "      <td>26117.531826</td>\n",
       "      <td>22544.086976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvd</th>\n",
       "      <td>79.981103</td>\n",
       "      <td>85.809230</td>\n",
       "      <td>621.561970</td>\n",
       "      <td>583.332471</td>\n",
       "      <td>116.618307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      knn_imputer   mice_imputer        sf_mean  \\\n",
       "GRElev                  32.937391      43.859176     131.739782   \n",
       "KBElev                  33.656877      47.500630     133.791984   \n",
       "TD                     731.560670    1057.801104    1232.811161   \n",
       "bh_lat                   0.144739       0.145272       0.343438   \n",
       "bh_lng                   0.150667       0.125485       0.394108   \n",
       "legs                     0.337165       0.814652       0.351858   \n",
       "max_tvd                 74.487098      62.991736     612.034433   \n",
       "mean_tvd                77.304638      69.511239     619.554369   \n",
       "min_tvd                 84.795253     135.695898     632.089117   \n",
       "num_pools_produced       0.159680       0.573178       0.000366   \n",
       "std_tvd                 21.535965      23.470933      30.108830   \n",
       "surface_lat              0.148624       0.148184       0.344715   \n",
       "surface_lng              0.150847       0.125954       0.394367   \n",
       "total_lbs_proppant  581601.693076  882792.572311  978028.075325   \n",
       "total_volume_bbls    17458.836494   24323.185556   27376.457111   \n",
       "tvd                     79.981103      85.809230     621.561970   \n",
       "\n",
       "                        sf_median   soft_imputer  \n",
       "GRElev                 132.000000      53.662910  \n",
       "KBElev                 132.403685      56.721286  \n",
       "TD                    1125.918760     924.276236  \n",
       "bh_lat                   0.343322       0.202749  \n",
       "bh_lng                   0.393342       0.177855  \n",
       "legs                     0.219430       0.693342  \n",
       "max_tvd                574.316759      84.225039  \n",
       "mean_tvd               581.414754      96.100281  \n",
       "min_tvd                596.919481     164.440233  \n",
       "num_pools_produced       0.000000       0.475580  \n",
       "std_tvd                 28.328596      24.962371  \n",
       "surface_lat              0.344595       0.205988  \n",
       "surface_lng              0.393438       0.178330  \n",
       "total_lbs_proppant  954991.417085  839883.003831  \n",
       "total_volume_bbls    26117.531826   22544.086976  \n",
       "tvd                    583.332471     116.618307  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Check each imputer at different proportions of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing error for filling column: GRElev\n",
      "computing error for filling column: KBElev\n",
      "computing error for filling column: TD\n",
      "computing error for filling column: bh_lat\n",
      "computing error for filling column: bh_lng\n",
      "computing error for filling column: legs\n",
      "computing error for filling column: max_tvd\n",
      "computing error for filling column: mean_tvd\n",
      "computing error for filling column: min_tvd\n",
      "computing error for filling column: num_pools_produced\n",
      "computing error for filling column: std_tvd\n",
      "computing error for filling column: surface_lat\n",
      "computing error for filling column: surface_lng\n",
      "computing error for filling column: total_lbs_proppant\n",
      "computing error for filling column: total_volume_bbls\n",
      "computing error for filling column: tvd\n"
     ]
    }
   ],
   "source": [
    "knn_impute_test = ie.imputers_percent_eval(impute_test_df, knn_imputer, impute_percents = range(10, 71, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing error for filling column: GRElev\n",
      "computing error for filling column: KBElev\n",
      "computing error for filling column: TD\n",
      "computing error for filling column: bh_lat\n",
      "computing error for filling column: bh_lng\n",
      "computing error for filling column: legs\n",
      "computing error for filling column: max_tvd\n",
      "computing error for filling column: mean_tvd\n",
      "computing error for filling column: min_tvd\n",
      "computing error for filling column: num_pools_produced\n",
      "computing error for filling column: std_tvd\n",
      "computing error for filling column: surface_lat\n",
      "computing error for filling column: surface_lng\n",
      "computing error for filling column: total_lbs_proppant\n",
      "computing error for filling column: total_volume_bbls\n",
      "computing error for filling column: tvd\n"
     ]
    }
   ],
   "source": [
    "mice_impute_test = ie.imputers_percent_eval(impute_test_df, mice_imputer, impute_percents = range(10, 71, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing error for filling column: GRElev\n",
      "computing error for filling column: KBElev\n",
      "computing error for filling column: TD\n",
      "computing error for filling column: bh_lat\n",
      "computing error for filling column: bh_lng\n",
      "computing error for filling column: legs\n",
      "computing error for filling column: max_tvd\n",
      "computing error for filling column: mean_tvd\n",
      "computing error for filling column: min_tvd\n",
      "computing error for filling column: num_pools_produced\n",
      "computing error for filling column: std_tvd\n",
      "computing error for filling column: surface_lat\n",
      "computing error for filling column: surface_lng\n",
      "computing error for filling column: total_lbs_proppant\n",
      "computing error for filling column: total_volume_bbls\n",
      "computing error for filling column: tvd\n"
     ]
    }
   ],
   "source": [
    "soft_impute_test = ie.imputers_percent_eval(impute_test_df, soft_imputer, impute_percents = range(10, 71, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRElev</th>\n",
       "      <td>43.859176</td>\n",
       "      <td>47.292672</td>\n",
       "      <td>59.909084</td>\n",
       "      <td>59.729627</td>\n",
       "      <td>75.589308</td>\n",
       "      <td>74.440601</td>\n",
       "      <td>78.867309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBElev</th>\n",
       "      <td>47.500630</td>\n",
       "      <td>51.509411</td>\n",
       "      <td>60.822847</td>\n",
       "      <td>62.552212</td>\n",
       "      <td>72.295283</td>\n",
       "      <td>73.082798</td>\n",
       "      <td>77.132953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>1057.801104</td>\n",
       "      <td>1036.720348</td>\n",
       "      <td>1038.295411</td>\n",
       "      <td>1048.888312</td>\n",
       "      <td>1034.768220</td>\n",
       "      <td>1047.915393</td>\n",
       "      <td>1039.206656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lat</th>\n",
       "      <td>0.145272</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.166705</td>\n",
       "      <td>0.178471</td>\n",
       "      <td>0.193264</td>\n",
       "      <td>0.214844</td>\n",
       "      <td>0.242051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lng</th>\n",
       "      <td>0.125485</td>\n",
       "      <td>0.132641</td>\n",
       "      <td>0.144727</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>0.170531</td>\n",
       "      <td>0.189089</td>\n",
       "      <td>0.218686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>0.814652</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>0.838261</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0.928876</td>\n",
       "      <td>0.987293</td>\n",
       "      <td>1.043671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tvd</th>\n",
       "      <td>62.991736</td>\n",
       "      <td>62.463248</td>\n",
       "      <td>62.755925</td>\n",
       "      <td>63.655153</td>\n",
       "      <td>62.812946</td>\n",
       "      <td>63.144791</td>\n",
       "      <td>62.294902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_tvd</th>\n",
       "      <td>69.511239</td>\n",
       "      <td>70.508470</td>\n",
       "      <td>71.397284</td>\n",
       "      <td>71.402724</td>\n",
       "      <td>70.585173</td>\n",
       "      <td>71.256478</td>\n",
       "      <td>70.602198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_tvd</th>\n",
       "      <td>135.695898</td>\n",
       "      <td>138.108530</td>\n",
       "      <td>138.204045</td>\n",
       "      <td>140.157413</td>\n",
       "      <td>138.114178</td>\n",
       "      <td>138.614207</td>\n",
       "      <td>137.669464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pools_produced</th>\n",
       "      <td>0.573178</td>\n",
       "      <td>0.569356</td>\n",
       "      <td>0.584489</td>\n",
       "      <td>0.599762</td>\n",
       "      <td>0.604379</td>\n",
       "      <td>0.615715</td>\n",
       "      <td>0.590880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_tvd</th>\n",
       "      <td>23.470933</td>\n",
       "      <td>24.489153</td>\n",
       "      <td>23.731199</td>\n",
       "      <td>23.873371</td>\n",
       "      <td>24.777392</td>\n",
       "      <td>24.699391</td>\n",
       "      <td>25.228741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lat</th>\n",
       "      <td>0.148184</td>\n",
       "      <td>0.155849</td>\n",
       "      <td>0.167234</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>0.195647</td>\n",
       "      <td>0.217941</td>\n",
       "      <td>0.245733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lng</th>\n",
       "      <td>0.125954</td>\n",
       "      <td>0.132862</td>\n",
       "      <td>0.144391</td>\n",
       "      <td>0.155676</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>0.189722</td>\n",
       "      <td>0.221336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_lbs_proppant</th>\n",
       "      <td>882792.572311</td>\n",
       "      <td>924028.776382</td>\n",
       "      <td>915712.735151</td>\n",
       "      <td>909168.363217</td>\n",
       "      <td>895066.341689</td>\n",
       "      <td>982309.417519</td>\n",
       "      <td>977353.627103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_volume_bbls</th>\n",
       "      <td>24323.185556</td>\n",
       "      <td>22602.232594</td>\n",
       "      <td>22614.995608</td>\n",
       "      <td>23635.846601</td>\n",
       "      <td>23564.365785</td>\n",
       "      <td>23771.392152</td>\n",
       "      <td>23663.597175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvd</th>\n",
       "      <td>85.809230</td>\n",
       "      <td>84.505830</td>\n",
       "      <td>84.135337</td>\n",
       "      <td>83.834271</td>\n",
       "      <td>83.191729</td>\n",
       "      <td>81.476803</td>\n",
       "      <td>81.273826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               10             20             30  \\\n",
       "GRElev                  43.859176      47.292672      59.909084   \n",
       "KBElev                  47.500630      51.509411      60.822847   \n",
       "TD                    1057.801104    1036.720348    1038.295411   \n",
       "bh_lat                   0.145272       0.154930       0.166705   \n",
       "bh_lng                   0.125485       0.132641       0.144727   \n",
       "legs                     0.814652       0.799094       0.838261   \n",
       "max_tvd                 62.991736      62.463248      62.755925   \n",
       "mean_tvd                69.511239      70.508470      71.397284   \n",
       "min_tvd                135.695898     138.108530     138.204045   \n",
       "num_pools_produced       0.573178       0.569356       0.584489   \n",
       "std_tvd                 23.470933      24.489153      23.731199   \n",
       "surface_lat              0.148184       0.155849       0.167234   \n",
       "surface_lng              0.125954       0.132862       0.144391   \n",
       "total_lbs_proppant  882792.572311  924028.776382  915712.735151   \n",
       "total_volume_bbls    24323.185556   22602.232594   22614.995608   \n",
       "tvd                     85.809230      84.505830      84.135337   \n",
       "\n",
       "                               40             50             60             70  \n",
       "GRElev                  59.729627      75.589308      74.440601      78.867309  \n",
       "KBElev                  62.552212      72.295283      73.082798      77.132953  \n",
       "TD                    1048.888312    1034.768220    1047.915393    1039.206656  \n",
       "bh_lat                   0.178471       0.193264       0.214844       0.242051  \n",
       "bh_lng                   0.154933       0.170531       0.189089       0.218686  \n",
       "legs                     0.881418       0.928876       0.987293       1.043671  \n",
       "max_tvd                 63.655153      62.812946      63.144791      62.294902  \n",
       "mean_tvd                71.402724      70.585173      71.256478      70.602198  \n",
       "min_tvd                140.157413     138.114178     138.614207     137.669464  \n",
       "num_pools_produced       0.599762       0.604379       0.615715       0.590880  \n",
       "std_tvd                 23.873371      24.777392      24.699391      25.228741  \n",
       "surface_lat              0.179512       0.195647       0.217941       0.245733  \n",
       "surface_lng              0.155676       0.170670       0.189722       0.221336  \n",
       "total_lbs_proppant  909168.363217  895066.341689  982309.417519  977353.627103  \n",
       "total_volume_bbls    23635.846601   23564.365785   23771.392152   23663.597175  \n",
       "tvd                     83.834271      83.191729      81.476803      81.273826  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice_impute_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRElev</th>\n",
       "      <td>53.662910</td>\n",
       "      <td>60.101196</td>\n",
       "      <td>75.039792</td>\n",
       "      <td>76.488958</td>\n",
       "      <td>96.819509</td>\n",
       "      <td>98.381316</td>\n",
       "      <td>107.502043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBElev</th>\n",
       "      <td>56.721286</td>\n",
       "      <td>63.234985</td>\n",
       "      <td>73.215926</td>\n",
       "      <td>75.978631</td>\n",
       "      <td>86.914250</td>\n",
       "      <td>89.570082</td>\n",
       "      <td>96.047288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>924.276236</td>\n",
       "      <td>905.342988</td>\n",
       "      <td>904.621032</td>\n",
       "      <td>913.504730</td>\n",
       "      <td>899.793599</td>\n",
       "      <td>911.519611</td>\n",
       "      <td>904.016817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lat</th>\n",
       "      <td>0.202749</td>\n",
       "      <td>0.251365</td>\n",
       "      <td>0.298682</td>\n",
       "      <td>0.351815</td>\n",
       "      <td>0.417336</td>\n",
       "      <td>0.510591</td>\n",
       "      <td>0.641181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lng</th>\n",
       "      <td>0.177855</td>\n",
       "      <td>0.219036</td>\n",
       "      <td>0.265541</td>\n",
       "      <td>0.313749</td>\n",
       "      <td>0.378710</td>\n",
       "      <td>0.462107</td>\n",
       "      <td>0.597047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>0.693342</td>\n",
       "      <td>0.668174</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.726686</td>\n",
       "      <td>0.766882</td>\n",
       "      <td>0.817012</td>\n",
       "      <td>0.881650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tvd</th>\n",
       "      <td>84.225039</td>\n",
       "      <td>96.001773</td>\n",
       "      <td>105.872527</td>\n",
       "      <td>119.340362</td>\n",
       "      <td>127.495856</td>\n",
       "      <td>142.744705</td>\n",
       "      <td>166.822836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_tvd</th>\n",
       "      <td>96.100281</td>\n",
       "      <td>108.202927</td>\n",
       "      <td>118.261842</td>\n",
       "      <td>130.328760</td>\n",
       "      <td>137.921487</td>\n",
       "      <td>153.001467</td>\n",
       "      <td>176.820877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_tvd</th>\n",
       "      <td>164.440233</td>\n",
       "      <td>177.045295</td>\n",
       "      <td>180.836927</td>\n",
       "      <td>190.494253</td>\n",
       "      <td>193.773154</td>\n",
       "      <td>205.496777</td>\n",
       "      <td>224.428765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pools_produced</th>\n",
       "      <td>0.475580</td>\n",
       "      <td>0.482245</td>\n",
       "      <td>0.497710</td>\n",
       "      <td>0.521565</td>\n",
       "      <td>0.557318</td>\n",
       "      <td>0.611382</td>\n",
       "      <td>0.669655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_tvd</th>\n",
       "      <td>24.962371</td>\n",
       "      <td>26.351067</td>\n",
       "      <td>25.628790</td>\n",
       "      <td>26.027455</td>\n",
       "      <td>27.346575</td>\n",
       "      <td>27.535424</td>\n",
       "      <td>28.331107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lat</th>\n",
       "      <td>0.205988</td>\n",
       "      <td>0.253078</td>\n",
       "      <td>0.300234</td>\n",
       "      <td>0.353817</td>\n",
       "      <td>0.420327</td>\n",
       "      <td>0.514050</td>\n",
       "      <td>0.644282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lng</th>\n",
       "      <td>0.178330</td>\n",
       "      <td>0.219457</td>\n",
       "      <td>0.265495</td>\n",
       "      <td>0.314491</td>\n",
       "      <td>0.379013</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>0.598164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_lbs_proppant</th>\n",
       "      <td>839883.003831</td>\n",
       "      <td>875714.206922</td>\n",
       "      <td>866341.600146</td>\n",
       "      <td>863143.836555</td>\n",
       "      <td>846290.674372</td>\n",
       "      <td>933707.676342</td>\n",
       "      <td>927782.229988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_volume_bbls</th>\n",
       "      <td>22544.086976</td>\n",
       "      <td>20834.405519</td>\n",
       "      <td>20783.922285</td>\n",
       "      <td>21818.262756</td>\n",
       "      <td>21731.032276</td>\n",
       "      <td>22099.061382</td>\n",
       "      <td>22013.480528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvd</th>\n",
       "      <td>116.618307</td>\n",
       "      <td>123.523457</td>\n",
       "      <td>129.132595</td>\n",
       "      <td>138.411380</td>\n",
       "      <td>144.063442</td>\n",
       "      <td>156.216991</td>\n",
       "      <td>178.434729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               10             20             30  \\\n",
       "GRElev                  53.662910      60.101196      75.039792   \n",
       "KBElev                  56.721286      63.234985      73.215926   \n",
       "TD                     924.276236     905.342988     904.621032   \n",
       "bh_lat                   0.202749       0.251365       0.298682   \n",
       "bh_lng                   0.177855       0.219036       0.265541   \n",
       "legs                     0.693342       0.668174       0.693918   \n",
       "max_tvd                 84.225039      96.001773     105.872527   \n",
       "mean_tvd                96.100281     108.202927     118.261842   \n",
       "min_tvd                164.440233     177.045295     180.836927   \n",
       "num_pools_produced       0.475580       0.482245       0.497710   \n",
       "std_tvd                 24.962371      26.351067      25.628790   \n",
       "surface_lat              0.205988       0.253078       0.300234   \n",
       "surface_lng              0.178330       0.219457       0.265495   \n",
       "total_lbs_proppant  839883.003831  875714.206922  866341.600146   \n",
       "total_volume_bbls    22544.086976   20834.405519   20783.922285   \n",
       "tvd                    116.618307     123.523457     129.132595   \n",
       "\n",
       "                               40             50             60             70  \n",
       "GRElev                  76.488958      96.819509      98.381316     107.502043  \n",
       "KBElev                  75.978631      86.914250      89.570082      96.047288  \n",
       "TD                     913.504730     899.793599     911.519611     904.016817  \n",
       "bh_lat                   0.351815       0.417336       0.510591       0.641181  \n",
       "bh_lng                   0.313749       0.378710       0.462107       0.597047  \n",
       "legs                     0.726686       0.766882       0.817012       0.881650  \n",
       "max_tvd                119.340362     127.495856     142.744705     166.822836  \n",
       "mean_tvd               130.328760     137.921487     153.001467     176.820877  \n",
       "min_tvd                190.494253     193.773154     205.496777     224.428765  \n",
       "num_pools_produced       0.521565       0.557318       0.611382       0.669655  \n",
       "std_tvd                 26.027455      27.346575      27.535424      28.331107  \n",
       "surface_lat              0.353817       0.420327       0.514050       0.644282  \n",
       "surface_lng              0.314491       0.379013       0.462658       0.598164  \n",
       "total_lbs_proppant  863143.836555  846290.674372  933707.676342  927782.229988  \n",
       "total_volume_bbls    21818.262756   21731.032276   22099.061382   22013.480528  \n",
       "tvd                    138.411380     144.063442     156.216991     178.434729  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_impute_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing error for filling column: GRElev\n",
      "computing error for filling column: KBElev\n",
      "computing error for filling column: TD\n",
      "computing error for filling column: bh_lat\n",
      "computing error for filling column: bh_lng\n",
      "computing error for filling column: legs\n",
      "computing error for filling column: max_tvd\n",
      "computing error for filling column: mean_tvd\n",
      "computing error for filling column: min_tvd\n",
      "computing error for filling column: num_pools_produced\n",
      "computing error for filling column: std_tvd\n",
      "computing error for filling column: surface_lat\n",
      "computing error for filling column: surface_lng\n",
      "computing error for filling column: total_lbs_proppant\n",
      "computing error for filling column: total_volume_bbls\n",
      "computing error for filling column: tvd\n"
     ]
    }
   ],
   "source": [
    "median_impute_test = ie.imputers_percent_eval(impute_test_df, sf_median, impute_percents = range(10, 71, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRElev</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>137.066556</td>\n",
       "      <td>149.398880</td>\n",
       "      <td>147.864671</td>\n",
       "      <td>164.645455</td>\n",
       "      <td>1.604661e+02</td>\n",
       "      <td>1.622120e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBElev</th>\n",
       "      <td>132.403685</td>\n",
       "      <td>136.673045</td>\n",
       "      <td>137.715966</td>\n",
       "      <td>138.477234</td>\n",
       "      <td>138.171380</td>\n",
       "      <td>1.378322e+02</td>\n",
       "      <td>1.378958e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>1125.918760</td>\n",
       "      <td>1104.428453</td>\n",
       "      <td>1108.306723</td>\n",
       "      <td>1122.128162</td>\n",
       "      <td>1104.415152</td>\n",
       "      <td>1.119278e+03</td>\n",
       "      <td>1.111232e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lat</th>\n",
       "      <td>0.343322</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.350008</td>\n",
       "      <td>0.351345</td>\n",
       "      <td>0.347306</td>\n",
       "      <td>3.504301e-01</td>\n",
       "      <td>3.482546e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_lng</th>\n",
       "      <td>0.393342</td>\n",
       "      <td>0.381522</td>\n",
       "      <td>0.379197</td>\n",
       "      <td>0.379873</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>3.828222e-01</td>\n",
       "      <td>3.845364e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legs</th>\n",
       "      <td>0.219430</td>\n",
       "      <td>0.202995</td>\n",
       "      <td>0.204482</td>\n",
       "      <td>0.206577</td>\n",
       "      <td>0.202694</td>\n",
       "      <td>2.050633e-01</td>\n",
       "      <td>2.059595e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_tvd</th>\n",
       "      <td>574.316759</td>\n",
       "      <td>569.065408</td>\n",
       "      <td>567.167289</td>\n",
       "      <td>568.935919</td>\n",
       "      <td>554.926283</td>\n",
       "      <td>5.583169e+02</td>\n",
       "      <td>5.558980e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_tvd</th>\n",
       "      <td>581.414754</td>\n",
       "      <td>578.330105</td>\n",
       "      <td>577.214216</td>\n",
       "      <td>578.200146</td>\n",
       "      <td>564.057762</td>\n",
       "      <td>5.670143e+02</td>\n",
       "      <td>5.648621e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_tvd</th>\n",
       "      <td>596.919481</td>\n",
       "      <td>598.801897</td>\n",
       "      <td>595.914532</td>\n",
       "      <td>599.123988</td>\n",
       "      <td>588.276572</td>\n",
       "      <td>5.910490e+02</td>\n",
       "      <td>5.885211e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pools_produced</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_tvd</th>\n",
       "      <td>28.328596</td>\n",
       "      <td>29.843561</td>\n",
       "      <td>28.891223</td>\n",
       "      <td>29.150321</td>\n",
       "      <td>30.189663</td>\n",
       "      <td>3.008945e+01</td>\n",
       "      <td>3.037430e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lat</th>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.351703</td>\n",
       "      <td>0.350755</td>\n",
       "      <td>0.352088</td>\n",
       "      <td>0.347674</td>\n",
       "      <td>3.506385e-01</td>\n",
       "      <td>3.481180e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface_lng</th>\n",
       "      <td>0.393438</td>\n",
       "      <td>0.381608</td>\n",
       "      <td>0.379103</td>\n",
       "      <td>0.379942</td>\n",
       "      <td>0.380458</td>\n",
       "      <td>3.826804e-01</td>\n",
       "      <td>3.842672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_lbs_proppant</th>\n",
       "      <td>954991.417085</td>\n",
       "      <td>996855.542429</td>\n",
       "      <td>989498.374510</td>\n",
       "      <td>982034.416526</td>\n",
       "      <td>964221.903367</td>\n",
       "      <td>1.053524e+06</td>\n",
       "      <td>1.046434e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_volume_bbls</th>\n",
       "      <td>26117.531826</td>\n",
       "      <td>24218.909318</td>\n",
       "      <td>24244.732773</td>\n",
       "      <td>25244.505481</td>\n",
       "      <td>25092.640404</td>\n",
       "      <td>2.510654e+04</td>\n",
       "      <td>2.498512e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvd</th>\n",
       "      <td>583.332471</td>\n",
       "      <td>578.115632</td>\n",
       "      <td>575.619076</td>\n",
       "      <td>577.304979</td>\n",
       "      <td>563.258842</td>\n",
       "      <td>5.665082e+02</td>\n",
       "      <td>5.641451e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               10             20             30  \\\n",
       "GRElev                 132.000000     137.066556     149.398880   \n",
       "KBElev                 132.403685     136.673045     137.715966   \n",
       "TD                    1125.918760    1104.428453    1108.306723   \n",
       "bh_lat                   0.343322       0.351014       0.350008   \n",
       "bh_lng                   0.393342       0.381522       0.379197   \n",
       "legs                     0.219430       0.202995       0.204482   \n",
       "max_tvd                574.316759     569.065408     567.167289   \n",
       "mean_tvd               581.414754     578.330105     577.214216   \n",
       "min_tvd                596.919481     598.801897     595.914532   \n",
       "num_pools_produced       0.000000       0.000000       0.000000   \n",
       "std_tvd                 28.328596      29.843561      28.891223   \n",
       "surface_lat              0.344595       0.351703       0.350755   \n",
       "surface_lng              0.393438       0.381608       0.379103   \n",
       "total_lbs_proppant  954991.417085  996855.542429  989498.374510   \n",
       "total_volume_bbls    26117.531826   24218.909318   24244.732773   \n",
       "tvd                    583.332471     578.115632     575.619076   \n",
       "\n",
       "                               40             50            60            70  \n",
       "GRElev                 147.864671     164.645455  1.604661e+02  1.622120e+02  \n",
       "KBElev                 138.477234     138.171380  1.378322e+02  1.378958e+02  \n",
       "TD                    1122.128162    1104.415152  1.119278e+03  1.111232e+03  \n",
       "bh_lat                   0.351345       0.347306  3.504301e-01  3.482546e-01  \n",
       "bh_lng                   0.379873       0.380585  3.828222e-01  3.845364e-01  \n",
       "legs                     0.206577       0.202694  2.050633e-01  2.059595e-01  \n",
       "max_tvd                568.935919     554.926283  5.583169e+02  5.558980e+02  \n",
       "mean_tvd               578.200146     564.057762  5.670143e+02  5.648621e+02  \n",
       "min_tvd                599.123988     588.276572  5.910490e+02  5.885211e+02  \n",
       "num_pools_produced       0.000000       0.000000  0.000000e+00  0.000000e+00  \n",
       "std_tvd                 29.150321      30.189663  3.008945e+01  3.037430e+01  \n",
       "surface_lat              0.352088       0.347674  3.506385e-01  3.481180e-01  \n",
       "surface_lng              0.379942       0.380458  3.826804e-01  3.842672e-01  \n",
       "total_lbs_proppant  982034.416526  964221.903367  1.053524e+06  1.046434e+06  \n",
       "total_volume_bbls    25244.505481   25092.640404  2.510654e+04  2.498512e+04  \n",
       "tvd                    577.304979     563.258842  5.665082e+02  5.641451e+02  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_impute_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing error for filling column: GRElev\n",
      "computing error for filling column: KBElev\n",
      "computing error for filling column: TD\n",
      "computing error for filling column: bh_lat\n",
      "computing error for filling column: bh_lng\n",
      "computing error for filling column: legs\n",
      "computing error for filling column: max_tvd\n",
      "computing error for filling column: mean_tvd\n",
      "computing error for filling column: min_tvd\n",
      "computing error for filling column: num_pools_produced\n",
      "computing error for filling column: std_tvd\n",
      "computing error for filling column: surface_lat\n",
      "computing error for filling column: surface_lng\n",
      "computing error for filling column: total_lbs_proppant\n",
      "computing error for filling column: total_volume_bbls\n",
      "computing error for filling column: tvd\n"
     ]
    }
   ],
   "source": [
    "mean_impute_test = ie.imputers_percent_eval(impute_test_df, sf_mean, impute_percents = range(10, 71, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_imp = mean_impute_test.unstack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_imp.columns=[\"perc_imputed\", \"feature\", \"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_imp[\"imputer\"] = \"Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_imputed</th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "      <th>imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.317398e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.337920e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.232811e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.434379e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.941079e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.518579e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>6.120344e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>6.195544e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.320891e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>3.664346e-04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.010883e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.447152e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.943666e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.780281e+05</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.737646e+04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>tvd</td>\n",
       "      <td>6.215620e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.368112e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.380880e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.209122e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.510638e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.829272e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.421305e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>6.047258e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>6.127742e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.297414e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>4.121162e-04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.111384e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.517387e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.831228e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.013204e+06</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>60</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.196239e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.504025e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.853571e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>60</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.457408e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>60</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.883363e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>60</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.969396e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>60</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.188846e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>60</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>8.000000e-04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>60</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.150738e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.507302e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.852725e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>60</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.074971e+06</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.657391e+04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>60</td>\n",
       "      <td>tvd</td>\n",
       "      <td>5.969790e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>70</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.632541e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>70</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.386726e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>70</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.187720e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.478070e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.875788e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>70</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.452836e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>70</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.831849e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>70</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.919364e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>70</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.145938e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>70</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>1.075269e-03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.166374e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.478562e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.873957e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>70</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.067818e+06</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>70</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.656769e+04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>70</td>\n",
       "      <td>tvd</td>\n",
       "      <td>5.919814e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     perc_imputed             feature           mae imputer\n",
       "0              10              GRElev  1.317398e+02    Mean\n",
       "1              10              KBElev  1.337920e+02    Mean\n",
       "2              10                  TD  1.232811e+03    Mean\n",
       "3              10              bh_lat  3.434379e-01    Mean\n",
       "4              10              bh_lng  3.941079e-01    Mean\n",
       "5              10                legs  3.518579e-01    Mean\n",
       "6              10             max_tvd  6.120344e+02    Mean\n",
       "7              10            mean_tvd  6.195544e+02    Mean\n",
       "8              10             min_tvd  6.320891e+02    Mean\n",
       "9              10  num_pools_produced  3.664346e-04    Mean\n",
       "10             10             std_tvd  3.010883e+01    Mean\n",
       "11             10         surface_lat  3.447152e-01    Mean\n",
       "12             10         surface_lng  3.943666e-01    Mean\n",
       "13             10  total_lbs_proppant  9.780281e+05    Mean\n",
       "14             10   total_volume_bbls  2.737646e+04    Mean\n",
       "15             10                 tvd  6.215620e+02    Mean\n",
       "16             20              GRElev  1.368112e+02    Mean\n",
       "17             20              KBElev  1.380880e+02    Mean\n",
       "18             20                  TD  1.209122e+03    Mean\n",
       "19             20              bh_lat  3.510638e-01    Mean\n",
       "20             20              bh_lng  3.829272e-01    Mean\n",
       "21             20                legs  3.421305e-01    Mean\n",
       "22             20             max_tvd  6.047258e+02    Mean\n",
       "23             20            mean_tvd  6.127742e+02    Mean\n",
       "24             20             min_tvd  6.297414e+02    Mean\n",
       "25             20  num_pools_produced  4.121162e-04    Mean\n",
       "26             20             std_tvd  3.111384e+01    Mean\n",
       "27             20         surface_lat  3.517387e-01    Mean\n",
       "28             20         surface_lng  3.831228e-01    Mean\n",
       "29             20  total_lbs_proppant  1.013204e+06    Mean\n",
       "..            ...                 ...           ...     ...\n",
       "82             60                  TD  1.196239e+03    Mean\n",
       "83             60              bh_lat  3.504025e-01    Mean\n",
       "84             60              bh_lng  3.853571e-01    Mean\n",
       "85             60                legs  3.457408e-01    Mean\n",
       "86             60             max_tvd  5.883363e+02    Mean\n",
       "87             60            mean_tvd  5.969396e+02    Mean\n",
       "88             60             min_tvd  6.188846e+02    Mean\n",
       "89             60  num_pools_produced  8.000000e-04    Mean\n",
       "90             60             std_tvd  3.150738e+01    Mean\n",
       "91             60         surface_lat  3.507302e-01    Mean\n",
       "92             60         surface_lng  3.852725e-01    Mean\n",
       "93             60  total_lbs_proppant  1.074971e+06    Mean\n",
       "94             60   total_volume_bbls  2.657391e+04    Mean\n",
       "95             60                 tvd  5.969790e+02    Mean\n",
       "96             70              GRElev  1.632541e+02    Mean\n",
       "97             70              KBElev  1.386726e+02    Mean\n",
       "98             70                  TD  1.187720e+03    Mean\n",
       "99             70              bh_lat  3.478070e-01    Mean\n",
       "100            70              bh_lng  3.875788e-01    Mean\n",
       "101            70                legs  3.452836e-01    Mean\n",
       "102            70             max_tvd  5.831849e+02    Mean\n",
       "103            70            mean_tvd  5.919364e+02    Mean\n",
       "104            70             min_tvd  6.145938e+02    Mean\n",
       "105            70  num_pools_produced  1.075269e-03    Mean\n",
       "106            70             std_tvd  3.166374e+01    Mean\n",
       "107            70         surface_lat  3.478562e-01    Mean\n",
       "108            70         surface_lng  3.873957e-01    Mean\n",
       "109            70  total_lbs_proppant  1.067818e+06    Mean\n",
       "110            70   total_volume_bbls  2.656769e+04    Mean\n",
       "111            70                 tvd  5.919814e+02    Mean\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_imputed</th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "      <th>imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>53.662910</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>56.721286</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>TD</td>\n",
       "      <td>924.276236</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>0.202749</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>0.177855</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>legs</td>\n",
       "      <td>0.693342</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>84.225039</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>96.100281</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>164.440233</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.475580</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>24.962371</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>0.205988</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>0.178330</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>839883.003831</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>22544.086976</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>tvd</td>\n",
       "      <td>116.618307</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>60.101196</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>63.234985</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>TD</td>\n",
       "      <td>905.342988</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>0.251365</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>0.219036</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>legs</td>\n",
       "      <td>0.668174</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>96.001773</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>108.202927</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>177.045295</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.482245</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>26.351067</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>0.253078</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>0.219457</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>875714.206922</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>60</td>\n",
       "      <td>TD</td>\n",
       "      <td>911.519611</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>0.510591</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>0.462107</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>60</td>\n",
       "      <td>legs</td>\n",
       "      <td>0.817012</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>60</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>142.744705</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>60</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>153.001467</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>60</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>205.496777</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>60</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.611382</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>60</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>27.535424</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>0.514050</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>60</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>933707.676342</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>22099.061382</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>60</td>\n",
       "      <td>tvd</td>\n",
       "      <td>156.216991</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>70</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>107.502043</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>70</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>96.047288</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>70</td>\n",
       "      <td>TD</td>\n",
       "      <td>904.016817</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>0.641181</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>0.597047</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>70</td>\n",
       "      <td>legs</td>\n",
       "      <td>0.881650</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>70</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>166.822836</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>70</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>176.820877</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>70</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>224.428765</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>70</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.669655</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>28.331107</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>0.644282</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>0.598164</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>70</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>927782.229988</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>70</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>22013.480528</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>70</td>\n",
       "      <td>tvd</td>\n",
       "      <td>178.434729</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     perc_imputed             feature            mae  imputer\n",
       "0              10              GRElev      53.662910  SoftMax\n",
       "1              10              KBElev      56.721286  SoftMax\n",
       "2              10                  TD     924.276236  SoftMax\n",
       "3              10              bh_lat       0.202749  SoftMax\n",
       "4              10              bh_lng       0.177855  SoftMax\n",
       "5              10                legs       0.693342  SoftMax\n",
       "6              10             max_tvd      84.225039  SoftMax\n",
       "7              10            mean_tvd      96.100281  SoftMax\n",
       "8              10             min_tvd     164.440233  SoftMax\n",
       "9              10  num_pools_produced       0.475580  SoftMax\n",
       "10             10             std_tvd      24.962371  SoftMax\n",
       "11             10         surface_lat       0.205988  SoftMax\n",
       "12             10         surface_lng       0.178330  SoftMax\n",
       "13             10  total_lbs_proppant  839883.003831  SoftMax\n",
       "14             10   total_volume_bbls   22544.086976  SoftMax\n",
       "15             10                 tvd     116.618307  SoftMax\n",
       "16             20              GRElev      60.101196  SoftMax\n",
       "17             20              KBElev      63.234985  SoftMax\n",
       "18             20                  TD     905.342988  SoftMax\n",
       "19             20              bh_lat       0.251365  SoftMax\n",
       "20             20              bh_lng       0.219036  SoftMax\n",
       "21             20                legs       0.668174  SoftMax\n",
       "22             20             max_tvd      96.001773  SoftMax\n",
       "23             20            mean_tvd     108.202927  SoftMax\n",
       "24             20             min_tvd     177.045295  SoftMax\n",
       "25             20  num_pools_produced       0.482245  SoftMax\n",
       "26             20             std_tvd      26.351067  SoftMax\n",
       "27             20         surface_lat       0.253078  SoftMax\n",
       "28             20         surface_lng       0.219457  SoftMax\n",
       "29             20  total_lbs_proppant  875714.206922  SoftMax\n",
       "..            ...                 ...            ...      ...\n",
       "82             60                  TD     911.519611  SoftMax\n",
       "83             60              bh_lat       0.510591  SoftMax\n",
       "84             60              bh_lng       0.462107  SoftMax\n",
       "85             60                legs       0.817012  SoftMax\n",
       "86             60             max_tvd     142.744705  SoftMax\n",
       "87             60            mean_tvd     153.001467  SoftMax\n",
       "88             60             min_tvd     205.496777  SoftMax\n",
       "89             60  num_pools_produced       0.611382  SoftMax\n",
       "90             60             std_tvd      27.535424  SoftMax\n",
       "91             60         surface_lat       0.514050  SoftMax\n",
       "92             60         surface_lng       0.462658  SoftMax\n",
       "93             60  total_lbs_proppant  933707.676342  SoftMax\n",
       "94             60   total_volume_bbls   22099.061382  SoftMax\n",
       "95             60                 tvd     156.216991  SoftMax\n",
       "96             70              GRElev     107.502043  SoftMax\n",
       "97             70              KBElev      96.047288  SoftMax\n",
       "98             70                  TD     904.016817  SoftMax\n",
       "99             70              bh_lat       0.641181  SoftMax\n",
       "100            70              bh_lng       0.597047  SoftMax\n",
       "101            70                legs       0.881650  SoftMax\n",
       "102            70             max_tvd     166.822836  SoftMax\n",
       "103            70            mean_tvd     176.820877  SoftMax\n",
       "104            70             min_tvd     224.428765  SoftMax\n",
       "105            70  num_pools_produced       0.669655  SoftMax\n",
       "106            70             std_tvd      28.331107  SoftMax\n",
       "107            70         surface_lat       0.644282  SoftMax\n",
       "108            70         surface_lng       0.598164  SoftMax\n",
       "109            70  total_lbs_proppant  927782.229988  SoftMax\n",
       "110            70   total_volume_bbls   22013.480528  SoftMax\n",
       "111            70                 tvd     178.434729  SoftMax\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_imp = soft_impute_test.unstack().reset_index()\n",
    "soft_imp.columns=[\"perc_imputed\", \"feature\", \"mae\"]\n",
    "soft_imp[\"imputer\"] = \"SoftMax\"\n",
    "soft_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice_imp = mice_impute_test.unstack().reset_index()\n",
    "mice_imp.columns=[\"perc_imputed\", \"feature\", \"mae\"]\n",
    "mice_imp[\"imputer\"] = \"MICE\"\n",
    "mice_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_imputed</th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "      <th>imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.324037e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.125919e+03</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.433218e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.933416e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>legs</td>\n",
       "      <td>2.194305e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.743168e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.814148e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>5.969195e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>2.832860e+01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.445955e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.934383e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.549914e+05</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.611753e+04</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>tvd</td>\n",
       "      <td>5.833325e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.370666e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.366730e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.104428e+03</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.510142e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.815223e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>legs</td>\n",
       "      <td>2.029950e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.690654e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.783301e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>5.988019e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>2.984356e+01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.517030e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.816084e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.968555e+05</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>60</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.119278e+03</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.504301e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.828222e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>60</td>\n",
       "      <td>legs</td>\n",
       "      <td>2.050633e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>60</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.583169e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>60</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.670143e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>60</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>5.910490e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>60</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>60</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.008945e+01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.506385e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.826804e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>60</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.053524e+06</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.510654e+04</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>60</td>\n",
       "      <td>tvd</td>\n",
       "      <td>5.665082e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>70</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.622120e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>70</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.378958e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>70</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.111232e+03</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.482546e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.845364e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>70</td>\n",
       "      <td>legs</td>\n",
       "      <td>2.059595e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>70</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>5.558980e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>70</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>5.648621e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>70</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>5.885211e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>70</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.037430e+01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.481180e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.842672e-01</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>70</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.046434e+06</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>70</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.498512e+04</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>70</td>\n",
       "      <td>tvd</td>\n",
       "      <td>5.641451e+02</td>\n",
       "      <td>Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     perc_imputed             feature           mae imputer\n",
       "0              10              GRElev  1.320000e+02  Median\n",
       "1              10              KBElev  1.324037e+02  Median\n",
       "2              10                  TD  1.125919e+03  Median\n",
       "3              10              bh_lat  3.433218e-01  Median\n",
       "4              10              bh_lng  3.933416e-01  Median\n",
       "5              10                legs  2.194305e-01  Median\n",
       "6              10             max_tvd  5.743168e+02  Median\n",
       "7              10            mean_tvd  5.814148e+02  Median\n",
       "8              10             min_tvd  5.969195e+02  Median\n",
       "9              10  num_pools_produced  0.000000e+00  Median\n",
       "10             10             std_tvd  2.832860e+01  Median\n",
       "11             10         surface_lat  3.445955e-01  Median\n",
       "12             10         surface_lng  3.934383e-01  Median\n",
       "13             10  total_lbs_proppant  9.549914e+05  Median\n",
       "14             10   total_volume_bbls  2.611753e+04  Median\n",
       "15             10                 tvd  5.833325e+02  Median\n",
       "16             20              GRElev  1.370666e+02  Median\n",
       "17             20              KBElev  1.366730e+02  Median\n",
       "18             20                  TD  1.104428e+03  Median\n",
       "19             20              bh_lat  3.510142e-01  Median\n",
       "20             20              bh_lng  3.815223e-01  Median\n",
       "21             20                legs  2.029950e-01  Median\n",
       "22             20             max_tvd  5.690654e+02  Median\n",
       "23             20            mean_tvd  5.783301e+02  Median\n",
       "24             20             min_tvd  5.988019e+02  Median\n",
       "25             20  num_pools_produced  0.000000e+00  Median\n",
       "26             20             std_tvd  2.984356e+01  Median\n",
       "27             20         surface_lat  3.517030e-01  Median\n",
       "28             20         surface_lng  3.816084e-01  Median\n",
       "29             20  total_lbs_proppant  9.968555e+05  Median\n",
       "..            ...                 ...           ...     ...\n",
       "82             60                  TD  1.119278e+03  Median\n",
       "83             60              bh_lat  3.504301e-01  Median\n",
       "84             60              bh_lng  3.828222e-01  Median\n",
       "85             60                legs  2.050633e-01  Median\n",
       "86             60             max_tvd  5.583169e+02  Median\n",
       "87             60            mean_tvd  5.670143e+02  Median\n",
       "88             60             min_tvd  5.910490e+02  Median\n",
       "89             60  num_pools_produced  0.000000e+00  Median\n",
       "90             60             std_tvd  3.008945e+01  Median\n",
       "91             60         surface_lat  3.506385e-01  Median\n",
       "92             60         surface_lng  3.826804e-01  Median\n",
       "93             60  total_lbs_proppant  1.053524e+06  Median\n",
       "94             60   total_volume_bbls  2.510654e+04  Median\n",
       "95             60                 tvd  5.665082e+02  Median\n",
       "96             70              GRElev  1.622120e+02  Median\n",
       "97             70              KBElev  1.378958e+02  Median\n",
       "98             70                  TD  1.111232e+03  Median\n",
       "99             70              bh_lat  3.482546e-01  Median\n",
       "100            70              bh_lng  3.845364e-01  Median\n",
       "101            70                legs  2.059595e-01  Median\n",
       "102            70             max_tvd  5.558980e+02  Median\n",
       "103            70            mean_tvd  5.648621e+02  Median\n",
       "104            70             min_tvd  5.885211e+02  Median\n",
       "105            70  num_pools_produced  0.000000e+00  Median\n",
       "106            70             std_tvd  3.037430e+01  Median\n",
       "107            70         surface_lat  3.481180e-01  Median\n",
       "108            70         surface_lng  3.842672e-01  Median\n",
       "109            70  total_lbs_proppant  1.046434e+06  Median\n",
       "110            70   total_volume_bbls  2.498512e+04  Median\n",
       "111            70                 tvd  5.641451e+02  Median\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_imp = median_impute_test.unstack().reset_index()\n",
    "median_imp.columns=[\"perc_imputed\", \"feature\", \"mae\"]\n",
    "median_imp[\"imputer\"] = \"Median\"\n",
    "median_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_imputation_results = pd.concat([mean_imp, median_imp, knn_imp, mice_imp, soft_imp]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_imputation_results.to_csv(\"percent_imputation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_imputed</th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "      <th>imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.317398e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.337920e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.232811e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.434379e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.941079e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.518579e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>6.120344e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>6.195544e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.320891e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>3.664346e-04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.010883e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.447152e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.943666e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.780281e+05</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.737646e+04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>tvd</td>\n",
       "      <td>6.215620e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.368112e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>1.380880e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>TD</td>\n",
       "      <td>1.209122e+03</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>3.510638e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>3.829272e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>legs</td>\n",
       "      <td>3.421305e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>6.047258e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>6.127742e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>6.297414e+02</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>4.121162e-04</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>3.111384e+01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>3.517387e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>3.831228e-01</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>1.013204e+06</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>60</td>\n",
       "      <td>TD</td>\n",
       "      <td>9.115196e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>5.105912e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>60</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>4.621073e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>60</td>\n",
       "      <td>legs</td>\n",
       "      <td>8.170124e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>60</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>1.427447e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>60</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>1.530015e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>60</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>2.054968e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>60</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>6.113823e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>60</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>2.753542e+01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>5.140497e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>60</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>4.626583e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>60</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.337077e+05</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>60</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.209906e+04</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>60</td>\n",
       "      <td>tvd</td>\n",
       "      <td>1.562170e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>70</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>1.075020e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>70</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>9.604729e+01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>70</td>\n",
       "      <td>TD</td>\n",
       "      <td>9.040168e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>6.411812e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>70</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>5.970471e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>70</td>\n",
       "      <td>legs</td>\n",
       "      <td>8.816502e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>70</td>\n",
       "      <td>max_tvd</td>\n",
       "      <td>1.668228e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>70</td>\n",
       "      <td>mean_tvd</td>\n",
       "      <td>1.768209e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>70</td>\n",
       "      <td>min_tvd</td>\n",
       "      <td>2.244288e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>70</td>\n",
       "      <td>num_pools_produced</td>\n",
       "      <td>6.696545e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>70</td>\n",
       "      <td>std_tvd</td>\n",
       "      <td>2.833111e+01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lat</td>\n",
       "      <td>6.442816e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>70</td>\n",
       "      <td>surface_lng</td>\n",
       "      <td>5.981642e-01</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>70</td>\n",
       "      <td>total_lbs_proppant</td>\n",
       "      <td>9.277822e+05</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>70</td>\n",
       "      <td>total_volume_bbls</td>\n",
       "      <td>2.201348e+04</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>70</td>\n",
       "      <td>tvd</td>\n",
       "      <td>1.784347e+02</td>\n",
       "      <td>SoftMax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     perc_imputed             feature           mae  imputer\n",
       "0              10              GRElev  1.317398e+02     Mean\n",
       "1              10              KBElev  1.337920e+02     Mean\n",
       "2              10                  TD  1.232811e+03     Mean\n",
       "3              10              bh_lat  3.434379e-01     Mean\n",
       "4              10              bh_lng  3.941079e-01     Mean\n",
       "5              10                legs  3.518579e-01     Mean\n",
       "6              10             max_tvd  6.120344e+02     Mean\n",
       "7              10            mean_tvd  6.195544e+02     Mean\n",
       "8              10             min_tvd  6.320891e+02     Mean\n",
       "9              10  num_pools_produced  3.664346e-04     Mean\n",
       "10             10             std_tvd  3.010883e+01     Mean\n",
       "11             10         surface_lat  3.447152e-01     Mean\n",
       "12             10         surface_lng  3.943666e-01     Mean\n",
       "13             10  total_lbs_proppant  9.780281e+05     Mean\n",
       "14             10   total_volume_bbls  2.737646e+04     Mean\n",
       "15             10                 tvd  6.215620e+02     Mean\n",
       "16             20              GRElev  1.368112e+02     Mean\n",
       "17             20              KBElev  1.380880e+02     Mean\n",
       "18             20                  TD  1.209122e+03     Mean\n",
       "19             20              bh_lat  3.510638e-01     Mean\n",
       "20             20              bh_lng  3.829272e-01     Mean\n",
       "21             20                legs  3.421305e-01     Mean\n",
       "22             20             max_tvd  6.047258e+02     Mean\n",
       "23             20            mean_tvd  6.127742e+02     Mean\n",
       "24             20             min_tvd  6.297414e+02     Mean\n",
       "25             20  num_pools_produced  4.121162e-04     Mean\n",
       "26             20             std_tvd  3.111384e+01     Mean\n",
       "27             20         surface_lat  3.517387e-01     Mean\n",
       "28             20         surface_lng  3.831228e-01     Mean\n",
       "29             20  total_lbs_proppant  1.013204e+06     Mean\n",
       "..            ...                 ...           ...      ...\n",
       "530            60                  TD  9.115196e+02  SoftMax\n",
       "531            60              bh_lat  5.105912e-01  SoftMax\n",
       "532            60              bh_lng  4.621073e-01  SoftMax\n",
       "533            60                legs  8.170124e-01  SoftMax\n",
       "534            60             max_tvd  1.427447e+02  SoftMax\n",
       "535            60            mean_tvd  1.530015e+02  SoftMax\n",
       "536            60             min_tvd  2.054968e+02  SoftMax\n",
       "537            60  num_pools_produced  6.113823e-01  SoftMax\n",
       "538            60             std_tvd  2.753542e+01  SoftMax\n",
       "539            60         surface_lat  5.140497e-01  SoftMax\n",
       "540            60         surface_lng  4.626583e-01  SoftMax\n",
       "541            60  total_lbs_proppant  9.337077e+05  SoftMax\n",
       "542            60   total_volume_bbls  2.209906e+04  SoftMax\n",
       "543            60                 tvd  1.562170e+02  SoftMax\n",
       "544            70              GRElev  1.075020e+02  SoftMax\n",
       "545            70              KBElev  9.604729e+01  SoftMax\n",
       "546            70                  TD  9.040168e+02  SoftMax\n",
       "547            70              bh_lat  6.411812e-01  SoftMax\n",
       "548            70              bh_lng  5.970471e-01  SoftMax\n",
       "549            70                legs  8.816502e-01  SoftMax\n",
       "550            70             max_tvd  1.668228e+02  SoftMax\n",
       "551            70            mean_tvd  1.768209e+02  SoftMax\n",
       "552            70             min_tvd  2.244288e+02  SoftMax\n",
       "553            70  num_pools_produced  6.696545e-01  SoftMax\n",
       "554            70             std_tvd  2.833111e+01  SoftMax\n",
       "555            70         surface_lat  6.442816e-01  SoftMax\n",
       "556            70         surface_lng  5.981642e-01  SoftMax\n",
       "557            70  total_lbs_proppant  9.277822e+05  SoftMax\n",
       "558            70   total_volume_bbls  2.201348e+04  SoftMax\n",
       "559            70                 tvd  1.784347e+02  SoftMax\n",
       "\n",
       "[560 rows x 4 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_imputation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_imputation_results = pd.read_csv(\"percent_imputation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_imputation_results.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_imputed</th>\n",
       "      <th>feature</th>\n",
       "      <th>mae</th>\n",
       "      <th>imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>GRElev</td>\n",
       "      <td>131.739782</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>KBElev</td>\n",
       "      <td>133.791984</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>TD</td>\n",
       "      <td>1232.811161</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lat</td>\n",
       "      <td>0.343438</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>bh_lng</td>\n",
       "      <td>0.394108</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perc_imputed feature          mae imputer\n",
       "0            10  GRElev   131.739782    Mean\n",
       "1            10  KBElev   133.791984    Mean\n",
       "2            10      TD  1232.811161    Mean\n",
       "3            10  bh_lat     0.343438    Mean\n",
       "4            10  bh_lng     0.394108    Mean"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_imputation_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_imputation_results['imputer'].replace(\"SoftMax\", \"Soft Impute\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Soft Impute    112\n",
       "Mean           112\n",
       "MICE           112\n",
       "Median         112\n",
       "KNN            112\n",
       "Name: imputer, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_imputation_results.imputer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224    32.937391\n",
       "240    36.085411\n",
       "256    49.428849\n",
       "272    49.671205\n",
       "288    68.243090\n",
       "304    66.453972\n",
       "320    71.387988\n",
       "Name: mae, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"KNN\") & (percent_imputation_results[\"feature\"] == \"GRElev\")][\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Font size issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_errors(feature):\n",
    "    current = feature\n",
    "    N = 10\n",
    "    x_axis = np.linspace(10, 100, 10)\n",
    "#     svd_y = svd_impute_test.loc[current].values\n",
    "    knn_y = percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"KNN\") & (percent_imputation_results[\"feature\"] == current)][\"mae\"]\n",
    "    mice_y = percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"MICE\") & (percent_imputation_results[\"feature\"] == current)][\"mae\"]\n",
    "    soft_y = percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"Soft Impute\") & (percent_imputation_results[\"feature\"] == current)][\"mae\"]\n",
    "    mean_y = percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"Mean\") & (percent_imputation_results[\"feature\"] == current)][\"mae\"]\n",
    "    median_y = percent_imputation_results[(percent_imputation_results[\"imputer\"] == \"Median\") & (percent_imputation_results[\"feature\"] == current)][\"mae\"]\n",
    "\n",
    "    # Create traces\n",
    "    trace0 = go.Scatter(\n",
    "        x =  x_axis,\n",
    "        y = knn_y,\n",
    "        mode = 'lines+markers',\n",
    "        name = 'KNN Imputer'\n",
    "    )\n",
    "    trace1 = go.Scatter(\n",
    "        x =  x_axis,\n",
    "        y = median_y,\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Median Imputer'\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter(\n",
    "        x = x_axis,\n",
    "        y = mean_y,\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Mean Imputer'\n",
    "    )\n",
    "    trace3 = go.Scatter(\n",
    "        x = x_axis,\n",
    "        y = mice_y,\n",
    "        mode = 'lines+markers',\n",
    "        name = 'MICE Imputer'\n",
    "    )\n",
    "    trace4 = go.Scatter(\n",
    "        x = x_axis,\n",
    "        y = soft_y,\n",
    "        mode = 'lines+markers',\n",
    "        name = 'Softmax Imputer'\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    data = [trace0, trace1, trace4]\n",
    "\n",
    "\n",
    "    layout = dict(title = current,\n",
    "                  xaxis = dict(title = 'Percent of data imputed'),\n",
    "                 yaxis = dict(title = 'Mean Absolute Error'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "\n",
    "    return py.iplot(fig, filename='line-mode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some top features:\n",
    "### 'surface_lat', 'bh_lat', 'total_lbs_proppant', 'total_volume_bbls', 'mean_tvd', 'max_tvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~noproblem-james/17.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_errors(\"surface_lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~noproblem-james/17.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_errors(\"total_lbs_proppant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~noproblem-james/17.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_errors(\"total_volume_bbls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~noproblem-james/17.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_errors(\"mean_tvd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~noproblem-james/17.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_errors(\"legs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
